{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP4_Phase1_Assignment_4_ver2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharathbolla/EIP4/blob/assignment_4/EIP4_Phase1_Assignment_4_ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM3rsMO8MW4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkcoQkuyB_ie",
        "colab_type": "code",
        "outputId": "e1faea47-5307-44a6-9789-c065ac48c568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "import keras\n",
        "#print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ugjgIjNG8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "18872144-aa04-4385-f748-9d14bda9342d"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=dfeffdb6b22bf746305aca28bd0ee8feaa1383de5d6552c037fceaf1ae22f903\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eBKXPP63NJUv",
        "colab": {}
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KXmkhhkNKNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8202ce37-7dd2-48ac-a852-ec5793c1f1e3"
      },
      "source": [
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.7 GB  | Proc size: 345.9 MB\n",
            "GPU RAM Free: 7611MB | Used: 0MB | Util   0% | Total 7611MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5LL43lfNS4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "da4dcfde-48c0-40f7-82a5-37e3946ba5ec"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Dec  8 11:11:56 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4630fq9QNWXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, Dropout\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnZ1HmPnNiT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8HKVCAxTa05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKZVoFEbTd8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWCSt6QmNkb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c5e4044c-da67-4b0a-81a8-cc5821d253ce"
      },
      "source": [
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hoos8Q6nNqD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXgONoxUNw5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_wVrtnjOVa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_D0NsYROkfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b47f03e-e523-4628-fe32-953516330bfc"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 128),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 16)   0           activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 16)   2320        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 16)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 16)   0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 16)   2320        dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 16)   0           dropout_11[0][0]                 \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 16)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 16)   2320        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 16)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 16)   0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 16)   2320        dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 32, 16)   0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 16)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 16)   2320        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 16)   64          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 16)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 16)   0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 16)   2320        dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 16)   64          conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 32, 32, 16)   0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 16)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 32)   4640        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 16, 16, 32)   0           activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 32)   9248        dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 32)   544         activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 16, 16, 32)   0           conv2d_31[0][0]                  \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 32)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 16, 16, 32)   0           activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 32)   0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 32)   0           activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 32)   9248        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 16, 16, 32)   0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 64)     18496       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 8, 8, 64)     0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 64)     36928       dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 64)     2112        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 64)     0           conv2d_38[0][0]                  \n",
            "                                                                 batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 64)     0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 8, 8, 64)     0           activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 64)     0           activation_34[0][0]              \n",
            "                                                                 batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 8, 8, 64)     0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 64)     36928       dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 8, 8, 64)     0           activation_36[0][0]              \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 64)     0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           650         flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 35s 91ms/step - loss: 1.5843 - acc: 0.4816 - val_loss: 1.7563 - val_acc: 0.4602\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 1.1316 - acc: 0.6522 - val_loss: 1.2580 - val_acc: 0.6245\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.9452 - acc: 0.7246 - val_loss: 1.0646 - val_acc: 0.6948\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.8362 - acc: 0.7624 - val_loss: 1.2706 - val_acc: 0.6464\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.7555 - acc: 0.7911 - val_loss: 0.9306 - val_acc: 0.7314\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.6973 - acc: 0.8115 - val_loss: 0.9276 - val_acc: 0.7391\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.6405 - acc: 0.8309 - val_loss: 0.7978 - val_acc: 0.7851\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.5991 - acc: 0.8444 - val_loss: 0.7948 - val_acc: 0.7867\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.5616 - acc: 0.8575 - val_loss: 0.7552 - val_acc: 0.7978\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.5253 - acc: 0.8701 - val_loss: 0.7357 - val_acc: 0.8048\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.4968 - acc: 0.8778 - val_loss: 0.8004 - val_acc: 0.7910\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.4716 - acc: 0.8856 - val_loss: 0.7378 - val_acc: 0.8042\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.4448 - acc: 0.8941 - val_loss: 0.7565 - val_acc: 0.8102\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.4238 - acc: 0.9030 - val_loss: 0.7591 - val_acc: 0.8159\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.4011 - acc: 0.9091 - val_loss: 0.7369 - val_acc: 0.8171\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.3860 - acc: 0.9135 - val_loss: 0.7363 - val_acc: 0.8191\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.3642 - acc: 0.9227 - val_loss: 0.7273 - val_acc: 0.8180\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.3454 - acc: 0.9270 - val_loss: 0.7626 - val_acc: 0.8202\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.3350 - acc: 0.9306 - val_loss: 0.7524 - val_acc: 0.8182\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.3227 - acc: 0.9353 - val_loss: 0.7439 - val_acc: 0.8256\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.3100 - acc: 0.9390 - val_loss: 0.7349 - val_acc: 0.8279\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2978 - acc: 0.9433 - val_loss: 0.7337 - val_acc: 0.8289\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2862 - acc: 0.9476 - val_loss: 0.7730 - val_acc: 0.8280\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2784 - acc: 0.9496 - val_loss: 0.7424 - val_acc: 0.8269\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2688 - acc: 0.9527 - val_loss: 0.7600 - val_acc: 0.8317\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2662 - acc: 0.9531 - val_loss: 0.8577 - val_acc: 0.8116\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2540 - acc: 0.9582 - val_loss: 0.7584 - val_acc: 0.8358\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2476 - acc: 0.9592 - val_loss: 0.8168 - val_acc: 0.8209\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2412 - acc: 0.9609 - val_loss: 0.8027 - val_acc: 0.8218\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2388 - acc: 0.9622 - val_loss: 0.7690 - val_acc: 0.8354\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2297 - acc: 0.9648 - val_loss: 0.7909 - val_acc: 0.8310\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 27s 68ms/step - loss: 0.2284 - acc: 0.9653 - val_loss: 0.8395 - val_acc: 0.8242\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 27s 69ms/step - loss: 0.2210 - acc: 0.9680 - val_loss: 0.7829 - val_acc: 0.8319\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.2172 - acc: 0.9691 - val_loss: 0.7707 - val_acc: 0.8370\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2127 - acc: 0.9697 - val_loss: 0.8589 - val_acc: 0.8217\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.2090 - acc: 0.9712 - val_loss: 0.8250 - val_acc: 0.8305\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2094 - acc: 0.9712 - val_loss: 0.8198 - val_acc: 0.8313\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.2020 - acc: 0.9733 - val_loss: 0.8029 - val_acc: 0.8353\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2008 - acc: 0.9731 - val_loss: 0.8397 - val_acc: 0.8315\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1983 - acc: 0.9738 - val_loss: 0.8059 - val_acc: 0.8353\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1951 - acc: 0.9751 - val_loss: 0.8261 - val_acc: 0.8329\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1912 - acc: 0.9763 - val_loss: 0.8243 - val_acc: 0.8335\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.1871 - acc: 0.9765 - val_loss: 0.8216 - val_acc: 0.8358\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1846 - acc: 0.9774 - val_loss: 0.8284 - val_acc: 0.8329\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.1841 - acc: 0.9775 - val_loss: 0.8523 - val_acc: 0.8314\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.1830 - acc: 0.9784 - val_loss: 0.8187 - val_acc: 0.8379\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1795 - acc: 0.9794 - val_loss: 0.8709 - val_acc: 0.8285\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.1766 - acc: 0.9795 - val_loss: 0.8331 - val_acc: 0.8384\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1739 - acc: 0.9812 - val_loss: 0.8567 - val_acc: 0.8402\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1718 - acc: 0.9811 - val_loss: 0.8880 - val_acc: 0.8327\n",
            "Model took 1325.63 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGKEET0REREREJEYowRMREREREYkR/w8LRcpJjI+7WgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSBl1YMdTidg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUtVZiCvZCYa",
        "colab_type": "text"
      },
      "source": [
        "## Droput increased validation accuracy to 84%\n",
        "### Adding more droput layers as train accuracy is hitting 98%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2ySlaGbZVx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sombfSNSZZ8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b09dc7d7-86c7-480d-d622-ba370c71ba51"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 128),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 16)   448         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 32, 32, 16)   64          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 32, 32, 16)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 32, 32, 16)   0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 16)   2320        dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 16)   64          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 16)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 32, 32, 16)   0           activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 32, 32, 16)   2320        dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 16)   64          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 32, 32, 16)   0           dropout_21[0][0]                 \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 16)   0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 32, 32, 16)   2320        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 16)   64          conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 16)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 32, 32, 16)   0           activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 32, 32, 16)   2320        dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 32, 32, 16)   64          conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 32, 32, 16)   0           activation_41[0][0]              \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 16)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 32, 32, 16)   2320        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 32, 32, 16)   64          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 32, 32, 16)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 32, 32, 16)   0           activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 32, 32, 16)   2320        dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 32, 32, 16)   64          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 32, 32, 16)   0           activation_43[0][0]              \n",
            "                                                                 batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 32, 32, 16)   0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 32)   4640        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 32)   128         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 32)   0           activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 32)   9248        dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 32)   544         activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 16, 16, 32)   0           conv2d_52[0][0]                  \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 32)   0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 32)   9248        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 16, 16, 32)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 32)   9248        dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 32)   128         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 16, 16, 32)   0           activation_47[0][0]              \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 32)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 32)   9248        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 32)   128         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 16, 16, 32)   0           activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 32)   9248        dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 32)   128         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 16, 16, 32)   0           activation_49[0][0]              \n",
            "                                                                 batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 32)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 8, 8, 64)     18496       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 8, 8, 64)     0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 8, 8, 64)     36928       dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 8, 8, 64)     2112        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 8, 8, 64)     0           conv2d_59[0][0]                  \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 8, 8, 64)     36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 8, 8, 64)     0           activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 8, 8, 64)     36928       dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 8, 8, 64)     36928       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 8, 8, 64)     256         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 8, 8, 64)     0           activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 8, 8, 64)     36928       dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 8, 8, 64)     0           activation_55[0][0]              \n",
            "                                                                 batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 8, 8, 64)     0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 64)     0           activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 64)           0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           650         flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 34s 86ms/step - loss: 1.5561 - acc: 0.4963 - val_loss: 1.7761 - val_acc: 0.4675\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 27s 68ms/step - loss: 1.1131 - acc: 0.6599 - val_loss: 1.6111 - val_acc: 0.5470\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.9344 - acc: 0.7254 - val_loss: 1.0869 - val_acc: 0.6865\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 27s 68ms/step - loss: 0.8266 - acc: 0.7651 - val_loss: 0.9628 - val_acc: 0.7209\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 27s 68ms/step - loss: 0.7465 - acc: 0.7934 - val_loss: 0.8976 - val_acc: 0.7452\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.6880 - acc: 0.8133 - val_loss: 0.8154 - val_acc: 0.7716\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.6396 - acc: 0.8306 - val_loss: 1.0714 - val_acc: 0.7121\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.5935 - acc: 0.8446 - val_loss: 0.7431 - val_acc: 0.7990\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.5570 - acc: 0.8562 - val_loss: 0.7921 - val_acc: 0.7833\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.5216 - acc: 0.8712 - val_loss: 0.7517 - val_acc: 0.8033\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 27s 69ms/step - loss: 0.4955 - acc: 0.8769 - val_loss: 0.9313 - val_acc: 0.7611\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.4660 - acc: 0.8874 - val_loss: 0.7424 - val_acc: 0.8112\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.4396 - acc: 0.8966 - val_loss: 0.7222 - val_acc: 0.8113\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.4174 - acc: 0.9032 - val_loss: 0.7129 - val_acc: 0.8203\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.3949 - acc: 0.9101 - val_loss: 0.8099 - val_acc: 0.7978\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 27s 68ms/step - loss: 0.3765 - acc: 0.9175 - val_loss: 0.7294 - val_acc: 0.8169\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.3625 - acc: 0.9220 - val_loss: 0.7787 - val_acc: 0.8117\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.3490 - acc: 0.9250 - val_loss: 0.7354 - val_acc: 0.8219\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 27s 68ms/step - loss: 0.3291 - acc: 0.9337 - val_loss: 0.7639 - val_acc: 0.8224\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.3179 - acc: 0.9369 - val_loss: 0.7834 - val_acc: 0.8207\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.3069 - acc: 0.9391 - val_loss: 0.7625 - val_acc: 0.8249\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 27s 68ms/step - loss: 0.2955 - acc: 0.9433 - val_loss: 0.7559 - val_acc: 0.8226\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.2831 - acc: 0.9474 - val_loss: 0.8016 - val_acc: 0.8097\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 26s 68ms/step - loss: 0.2752 - acc: 0.9495 - val_loss: 0.7379 - val_acc: 0.8330\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2652 - acc: 0.9535 - val_loss: 0.7332 - val_acc: 0.8292\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2582 - acc: 0.9557 - val_loss: 0.7464 - val_acc: 0.8316\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2529 - acc: 0.9569 - val_loss: 0.7465 - val_acc: 0.8333\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2444 - acc: 0.9594 - val_loss: 0.7493 - val_acc: 0.8359\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2405 - acc: 0.9602 - val_loss: 0.7537 - val_acc: 0.8364\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2346 - acc: 0.9627 - val_loss: 0.8000 - val_acc: 0.8263\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2312 - acc: 0.9636 - val_loss: 0.7585 - val_acc: 0.8339\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2230 - acc: 0.9660 - val_loss: 0.7787 - val_acc: 0.8300\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2167 - acc: 0.9674 - val_loss: 0.7946 - val_acc: 0.8303\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2126 - acc: 0.9696 - val_loss: 0.7857 - val_acc: 0.8363\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2125 - acc: 0.9691 - val_loss: 0.7937 - val_acc: 0.8394\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2056 - acc: 0.9708 - val_loss: 0.7803 - val_acc: 0.8369\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2029 - acc: 0.9720 - val_loss: 0.8851 - val_acc: 0.8183\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.2029 - acc: 0.9718 - val_loss: 0.7926 - val_acc: 0.8321\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 26s 66ms/step - loss: 0.1981 - acc: 0.9728 - val_loss: 0.8143 - val_acc: 0.8292\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1938 - acc: 0.9744 - val_loss: 0.7871 - val_acc: 0.8365\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1926 - acc: 0.9751 - val_loss: 0.8294 - val_acc: 0.8305\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 26s 66ms/step - loss: 0.1872 - acc: 0.9769 - val_loss: 0.8212 - val_acc: 0.8327\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1844 - acc: 0.9775 - val_loss: 0.7989 - val_acc: 0.8358\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 26s 66ms/step - loss: 0.1811 - acc: 0.9785 - val_loss: 0.8340 - val_acc: 0.8351\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1784 - acc: 0.9789 - val_loss: 0.8562 - val_acc: 0.8289\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.1794 - acc: 0.9788 - val_loss: 0.8199 - val_acc: 0.8383\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 26s 66ms/step - loss: 0.1750 - acc: 0.9800 - val_loss: 0.8028 - val_acc: 0.8413\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 26s 66ms/step - loss: 0.1746 - acc: 0.9794 - val_loss: 0.8374 - val_acc: 0.8358\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 26s 66ms/step - loss: 0.1717 - acc: 0.9805 - val_loss: 0.8067 - val_acc: 0.8386\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 26s 66ms/step - loss: 0.1703 - acc: 0.9806 - val_loss: 0.8229 - val_acc: 0.8357\n",
            "Model took 1323.87 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/D8LTArvJtXEFAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iBJ-l1ZZfmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldvXOKLijicT",
        "colab_type": "text"
      },
      "source": [
        "## Increasing number of filters to 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO00Cfamjnwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=32,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxHDg_KIjsjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "version = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtIQcBAsjujx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 32\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D8V7GIXj0hi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5122d95-d1a9-4c24-bd38-a18b59e4fa28"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 128),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 32, 32, 32)   896         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 32, 32, 32)   128         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 32, 32, 32)   0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 32, 32, 32)   0           activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 32, 32, 32)   1056        dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 32, 32, 32)   128         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 32, 32, 32)   0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 32, 32, 32)   0           activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 32, 32, 32)   9248        dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 32, 32, 32)   128         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 32, 32, 32)   0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 32, 32, 32)   0           activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 32, 32, 128)  4224        dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 32, 32, 128)  4224        dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 32, 32, 128)  0           conv2d_90[0][0]                  \n",
            "                                                                 conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 32, 32, 128)  512         add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 32, 32, 128)  0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 32, 32, 128)  0           activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 32, 32, 32)   4128        dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 32, 32, 32)   128         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 32, 32, 32)   0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 32, 32, 32)   0           activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 32, 32, 32)   9248        dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 32, 32, 32)   128         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 32, 32, 32)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 32, 32, 32)   0           activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 32, 32, 128)  4224        dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 32, 32, 128)  0           add_34[0][0]                     \n",
            "                                                                 conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 32, 32, 128)  512         add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 32, 32, 128)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 32, 32, 128)  0           activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 16, 16, 128)  16512       dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 16, 16, 128)  512         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 16, 16, 128)  0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 16, 16, 128)  0           activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 16, 16, 128)  147584      dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 16, 16, 128)  512         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 16, 16, 128)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 16, 16, 128)  0           activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 16, 16, 256)  33024       add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 16, 16, 256)  33024       dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 16, 16, 256)  0           conv2d_97[0][0]                  \n",
            "                                                                 conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 16, 16, 256)  1024        add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 16, 16, 256)  0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 16, 16, 256)  0           activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 16, 16, 128)  32896       dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 16, 16, 128)  512         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 16, 16, 128)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 16, 16, 128)  0           activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 128)  147584      dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 16, 16, 128)  512         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 16, 16, 128)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 16, 16, 128)  0           activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 256)  33024       dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 16, 16, 256)  0           add_36[0][0]                     \n",
            "                                                                 conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 16, 16, 256)  1024        add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 16, 16, 256)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 16, 16, 256)  0           activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 8, 8, 256)    65792       dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 256)    1024        conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 256)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 8, 8, 256)    0           activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 8, 8, 256)    590080      dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 256)    1024        conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 256)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 8, 8, 256)    0           activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 8, 8, 512)    131584      add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 8, 8, 512)    131584      dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 8, 8, 512)    0           conv2d_104[0][0]                 \n",
            "                                                                 conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 512)    2048        add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 512)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 8, 8, 512)    0           activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 8, 8, 256)    131328      dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 256)    1024        conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 256)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 8, 8, 256)    0           activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 8, 8, 256)    590080      dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 256)    1024        conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 256)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 8, 8, 256)    0           activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 8, 8, 512)    131584      dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 8, 8, 512)    0           add_38[0][0]                     \n",
            "                                                                 conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 512)    2048        add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 512)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 1, 1, 512)    0           activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 512)          0           average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           5130        flatten_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,272,010\n",
            "Trainable params: 2,265,034\n",
            "Non-trainable params: 6,976\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 105s 269ms/step - loss: 1.8757 - acc: 0.4996 - val_loss: 1.7545 - val_acc: 0.4984\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 92s 235ms/step - loss: 1.2987 - acc: 0.6423 - val_loss: 1.3403 - val_acc: 0.6222\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 92s 235ms/step - loss: 1.1271 - acc: 0.6942 - val_loss: 1.3560 - val_acc: 0.6119\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 92s 235ms/step - loss: 1.0074 - acc: 0.7341 - val_loss: 1.2724 - val_acc: 0.6487\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 92s 235ms/step - loss: 0.9209 - acc: 0.7641 - val_loss: 0.9875 - val_acc: 0.7437\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.8519 - acc: 0.7854 - val_loss: 0.9605 - val_acc: 0.7537\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 92s 235ms/step - loss: 0.7972 - acc: 0.8031 - val_loss: 0.8641 - val_acc: 0.7734\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 92s 235ms/step - loss: 0.7446 - acc: 0.8191 - val_loss: 0.9005 - val_acc: 0.7638\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 92s 235ms/step - loss: 0.7083 - acc: 0.8309 - val_loss: 0.8675 - val_acc: 0.7868\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.6692 - acc: 0.8421 - val_loss: 0.9306 - val_acc: 0.7635\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 92s 237ms/step - loss: 0.6389 - acc: 0.8515 - val_loss: 0.8056 - val_acc: 0.7986\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.6067 - acc: 0.8620 - val_loss: 0.7989 - val_acc: 0.8006\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 92s 237ms/step - loss: 0.5776 - acc: 0.8701 - val_loss: 0.7291 - val_acc: 0.8186\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.5461 - acc: 0.8803 - val_loss: 0.8054 - val_acc: 0.8060\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.5256 - acc: 0.8876 - val_loss: 0.6953 - val_acc: 0.8367\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.5024 - acc: 0.8949 - val_loss: 0.7777 - val_acc: 0.8110\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.4845 - acc: 0.9011 - val_loss: 0.6967 - val_acc: 0.8372\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.4657 - acc: 0.9058 - val_loss: 0.7349 - val_acc: 0.8278\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.4503 - acc: 0.9090 - val_loss: 0.6738 - val_acc: 0.8461\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.4290 - acc: 0.9171 - val_loss: 0.8184 - val_acc: 0.8101\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.4126 - acc: 0.9230 - val_loss: 0.7289 - val_acc: 0.8405\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 92s 235ms/step - loss: 0.3968 - acc: 0.9273 - val_loss: 0.7070 - val_acc: 0.8424\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.3841 - acc: 0.9316 - val_loss: 0.6842 - val_acc: 0.8496\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.3727 - acc: 0.9345 - val_loss: 0.6669 - val_acc: 0.8637\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.3617 - acc: 0.9379 - val_loss: 0.7052 - val_acc: 0.8546\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.3522 - acc: 0.9410 - val_loss: 0.7165 - val_acc: 0.8531\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.3383 - acc: 0.9460 - val_loss: 0.6382 - val_acc: 0.8646\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.3318 - acc: 0.9473 - val_loss: 0.6505 - val_acc: 0.8686\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.3222 - acc: 0.9501 - val_loss: 0.6880 - val_acc: 0.8537\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.3141 - acc: 0.9529 - val_loss: 0.6840 - val_acc: 0.8612\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.3067 - acc: 0.9544 - val_loss: 0.6813 - val_acc: 0.8574\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.2981 - acc: 0.9569 - val_loss: 0.7161 - val_acc: 0.8571\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.2882 - acc: 0.9612 - val_loss: 0.6692 - val_acc: 0.8662\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.2838 - acc: 0.9616 - val_loss: 0.6879 - val_acc: 0.8597\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 0.2808 - acc: 0.9616 - val_loss: 0.6647 - val_acc: 0.8658\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2701 - acc: 0.9657 - val_loss: 0.7158 - val_acc: 0.8650\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2691 - acc: 0.9653 - val_loss: 0.7091 - val_acc: 0.8633\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2611 - acc: 0.9686 - val_loss: 0.7110 - val_acc: 0.8652\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 0.2616 - acc: 0.9667 - val_loss: 0.6724 - val_acc: 0.8686\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2519 - acc: 0.9701 - val_loss: 0.7667 - val_acc: 0.8490\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2517 - acc: 0.9702 - val_loss: 0.6639 - val_acc: 0.8694\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2390 - acc: 0.9747 - val_loss: 0.6846 - val_acc: 0.8701\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2379 - acc: 0.9743 - val_loss: 0.7771 - val_acc: 0.8578\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2412 - acc: 0.9726 - val_loss: 0.6757 - val_acc: 0.8687\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2320 - acc: 0.9756 - val_loss: 0.6587 - val_acc: 0.8764\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2304 - acc: 0.9756 - val_loss: 0.6515 - val_acc: 0.8747\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2257 - acc: 0.9769 - val_loss: 0.6886 - val_acc: 0.8693\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2241 - acc: 0.9764 - val_loss: 0.6907 - val_acc: 0.8679\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2197 - acc: 0.9786 - val_loss: 0.7416 - val_acc: 0.8649\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2189 - acc: 0.9785 - val_loss: 0.6612 - val_acc: 0.8766\n",
            "Model took 4625.54 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPAAAgElo8AAAACbxC6HoODne1dc/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqdhvjU8j4YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvliMr154YVt",
        "colab_type": "text"
      },
      "source": [
        "## The max validation accuracy is 87.66 and the max train accuracy is 97.85. So there is still room to cross 88.0 accuracy in validation.\n",
        "## Now trying with batch size = 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnbcH8-14-AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 64  # orig paper trained all networks with batch_size=128\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR9VrrSr5HEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fae1eb02-df2d-49a2-8dd8-32dc7211d8c5"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 128),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 32)   896         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 32, 32, 32)   128         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 32, 32, 32)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 32, 32, 32)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 32)   1056        dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 32, 32, 32)   128         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 32, 32, 32)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 32, 32, 32)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 32)   9248        dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 32, 32, 32)   128         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 32, 32, 32)   0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 32, 32, 32)   0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 128)  4224        dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 128)  4224        dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 32, 32, 128)  0           conv2d_112[0][0]                 \n",
            "                                                                 conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 32, 32, 128)  512         add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 32, 32, 128)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 32, 32, 128)  0           activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 32)   4128        dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 32, 32, 32)   128         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 32, 32, 32)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 32, 32, 32)   0           activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 32)   9248        dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 32, 32, 32)   128         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 32, 32, 32)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 32, 32, 32)   0           activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 128)  4224        dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 32, 32, 128)  0           add_40[0][0]                     \n",
            "                                                                 conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 32, 32, 128)  512         add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 32, 32, 128)  0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 32, 32, 128)  0           activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 128)  16512       dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 128)  512         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 128)  0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 16, 16, 128)  0           activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 128)  147584      dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 128)  512         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 128)  0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 16, 16, 128)  0           activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 256)  33024       add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 256)  33024       dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 16, 16, 256)  0           conv2d_119[0][0]                 \n",
            "                                                                 conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 256)  1024        add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 256)  0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 16, 16, 256)  0           activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 16, 16, 128)  32896       dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 128)  512         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 128)  0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 16, 16, 128)  0           activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 128)  147584      dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 128)  512         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 128)  0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 16, 16, 128)  0           activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 256)  33024       dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 16, 16, 256)  0           add_42[0][0]                     \n",
            "                                                                 conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 256)  1024        add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 256)  0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 16, 16, 256)  0           activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 8, 8, 256)    65792       dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 8, 8, 256)    1024        conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 8, 8, 256)    0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 8, 8, 256)    0           activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 8, 8, 256)    590080      dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 8, 8, 256)    1024        conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 8, 8, 256)    0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, 8, 8, 256)    0           activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 8, 8, 512)    131584      add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 8, 8, 512)    131584      dropout_81[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 8, 8, 512)    0           conv2d_126[0][0]                 \n",
            "                                                                 conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 8, 8, 512)    2048        add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 8, 8, 512)    0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, 8, 8, 512)    0           activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 8, 8, 256)    131328      dropout_82[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 8, 8, 256)    1024        conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 8, 8, 256)    0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_83 (Dropout)            (None, 8, 8, 256)    0           activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 8, 8, 256)    590080      dropout_83[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 8, 8, 256)    1024        conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 8, 8, 256)    0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 8, 8, 256)    0           activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 8, 8, 512)    131584      dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 8, 8, 512)    0           add_44[0][0]                     \n",
            "                                                                 conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 8, 8, 512)    2048        add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 8, 8, 512)    0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 1, 1, 512)    0           activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 512)          0           average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 10)           5130        flatten_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,272,010\n",
            "Trainable params: 2,265,034\n",
            "Non-trainable params: 6,976\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 108s 277ms/step - loss: 1.8594 - acc: 0.5034 - val_loss: 3.0558 - val_acc: 0.3392\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.2886 - acc: 0.6467 - val_loss: 1.3678 - val_acc: 0.6230\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 1.1214 - acc: 0.6944 - val_loss: 1.2488 - val_acc: 0.6522\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 1.0017 - acc: 0.7316 - val_loss: 1.3183 - val_acc: 0.6483\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 0.9199 - acc: 0.7628 - val_loss: 1.0835 - val_acc: 0.7047\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 0.8495 - acc: 0.7837 - val_loss: 0.9873 - val_acc: 0.7324\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 0.7995 - acc: 0.8002 - val_loss: 0.8839 - val_acc: 0.7713\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.7522 - acc: 0.8130 - val_loss: 0.8476 - val_acc: 0.7813\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 0.7063 - acc: 0.8304 - val_loss: 0.9460 - val_acc: 0.7489\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.6707 - acc: 0.8394 - val_loss: 0.8115 - val_acc: 0.7924\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 0.6404 - acc: 0.8501 - val_loss: 0.8369 - val_acc: 0.7890\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.6090 - acc: 0.8606 - val_loss: 0.8473 - val_acc: 0.7876\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 0.5821 - acc: 0.8679 - val_loss: 0.8629 - val_acc: 0.7835\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.5567 - acc: 0.8760 - val_loss: 0.7712 - val_acc: 0.8033\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.5285 - acc: 0.8849 - val_loss: 0.7747 - val_acc: 0.8143\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.5089 - acc: 0.8892 - val_loss: 0.7363 - val_acc: 0.8259\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.4921 - acc: 0.8960 - val_loss: 0.7178 - val_acc: 0.8274\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.4700 - acc: 0.9033 - val_loss: 0.7669 - val_acc: 0.8121\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.4553 - acc: 0.9088 - val_loss: 0.6939 - val_acc: 0.8412\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.4321 - acc: 0.9152 - val_loss: 0.7409 - val_acc: 0.8267\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.4202 - acc: 0.9179 - val_loss: 0.6558 - val_acc: 0.8489\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.4024 - acc: 0.9250 - val_loss: 0.7077 - val_acc: 0.8416\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.3910 - acc: 0.9292 - val_loss: 0.6781 - val_acc: 0.8436\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.3782 - acc: 0.9319 - val_loss: 0.8922 - val_acc: 0.8032\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.3662 - acc: 0.9359 - val_loss: 0.6579 - val_acc: 0.8550\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.3585 - acc: 0.9367 - val_loss: 0.7951 - val_acc: 0.8306\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.3437 - acc: 0.9431 - val_loss: 0.6289 - val_acc: 0.8671\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3340 - acc: 0.9455 - val_loss: 0.6862 - val_acc: 0.8595\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3259 - acc: 0.9484 - val_loss: 0.7012 - val_acc: 0.8482\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.3198 - acc: 0.9504 - val_loss: 0.6919 - val_acc: 0.8550\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.3060 - acc: 0.9542 - val_loss: 0.9013 - val_acc: 0.8250\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.3015 - acc: 0.9546 - val_loss: 0.6520 - val_acc: 0.8618\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2956 - acc: 0.9578 - val_loss: 0.8253 - val_acc: 0.8306\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2910 - acc: 0.9575 - val_loss: 0.6615 - val_acc: 0.8618\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2882 - acc: 0.9590 - val_loss: 0.6957 - val_acc: 0.8606\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2722 - acc: 0.9645 - val_loss: 0.6914 - val_acc: 0.8555\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2705 - acc: 0.9653 - val_loss: 0.7013 - val_acc: 0.8609\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2640 - acc: 0.9666 - val_loss: 0.7078 - val_acc: 0.8617\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2649 - acc: 0.9663 - val_loss: 0.8086 - val_acc: 0.8395\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2554 - acc: 0.9685 - val_loss: 0.7382 - val_acc: 0.8604\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2538 - acc: 0.9698 - val_loss: 0.7524 - val_acc: 0.8498\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2460 - acc: 0.9722 - val_loss: 0.6767 - val_acc: 0.8634\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2442 - acc: 0.9714 - val_loss: 0.7570 - val_acc: 0.8547\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2402 - acc: 0.9725 - val_loss: 0.8045 - val_acc: 0.8444\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2346 - acc: 0.9745 - val_loss: 0.6830 - val_acc: 0.8683\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2325 - acc: 0.9744 - val_loss: 0.7496 - val_acc: 0.8550\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2309 - acc: 0.9748 - val_loss: 0.7350 - val_acc: 0.8609\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2242 - acc: 0.9779 - val_loss: 0.6601 - val_acc: 0.8748\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2250 - acc: 0.9762 - val_loss: 0.6558 - val_acc: 0.8692\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2175 - acc: 0.9789 - val_loss: 0.6926 - val_acc: 0.8692\n",
            "Model took 4661.91 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnOJR8bS5EQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzyZK92G5fXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvGdrATALf-4",
        "colab_type": "text"
      },
      "source": [
        "## Max validation accuracy is 87.48\n",
        "## Changing batch size from 128 to 64 has no big effect.\n",
        "## Increasing filters from 32 to 48\n",
        "## Rsnet20V1 with 5.0 million parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iGExYPhGmF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "version = 2\n",
        "#n = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUMYPLGrM9G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xLEYH4WPGZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=32,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf8MNNkfPQoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 48\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6aEtKzBNFG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21d3ca50-f773-4eea-aaaf-2d2fdec1af7d"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 128),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 32, 32, 48)   1344        input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 32, 32, 48)   192         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 32, 32, 48)   0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 32, 32, 48)   0           activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 32, 32, 48)   2352        dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 32, 32, 48)   192         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 32, 32, 48)   0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 32, 32, 48)   0           activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 32, 32, 48)   20784       dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 32, 32, 48)   192         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 32, 32, 48)   0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 32, 32, 48)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 32, 32, 192)  9408        dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 32, 32, 192)  9408        dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 32, 32, 192)  0           conv2d_171[0][0]                 \n",
            "                                                                 conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 32, 32, 192)  768         add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 32, 32, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, 32, 32, 192)  0           activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 32, 32, 48)   9264        dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 32, 32, 48)   192         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 32, 32, 48)   0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, 32, 32, 48)   0           activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 32, 32, 48)   20784       dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 32, 32, 48)   192         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 32, 32, 48)   0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, 32, 32, 48)   0           activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 32, 32, 192)  9408        dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 32, 32, 192)  0           add_57[0][0]                     \n",
            "                                                                 conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 32, 32, 192)  768         add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 32, 32, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 32, 32, 192)  0           activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 16, 16, 192)  37056       dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 16, 16, 192)  768         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 16, 16, 192)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 16, 16, 192)  0           activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 16, 16, 192)  331968      dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 16, 16, 192)  768         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 16, 16, 192)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 16, 16, 192)  0           activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 16, 16, 384)  74112       add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 16, 16, 384)  74112       dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 16, 16, 384)  0           conv2d_178[0][0]                 \n",
            "                                                                 conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 16, 16, 384)  1536        add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 16, 16, 384)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 16, 16, 384)  0           activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 16, 16, 192)  73920       dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 16, 16, 192)  768         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 16, 16, 192)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 16, 16, 192)  0           activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 16, 16, 192)  331968      dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 16, 16, 192)  768         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 16, 16, 192)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 16, 16, 192)  0           activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 16, 16, 384)  74112       dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 16, 16, 384)  0           add_59[0][0]                     \n",
            "                                                                 conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 16, 16, 384)  1536        add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 16, 16, 384)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 16, 16, 384)  0           activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 384)    147840      dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 8, 8, 384)    1536        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 8, 8, 384)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 8, 8, 384)    0           activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 384)    1327488     dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 8, 8, 384)    1536        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 8, 8, 384)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 8, 8, 384)    0           activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 768)    295680      add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 768)    295680      dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 8, 8, 768)    0           conv2d_185[0][0]                 \n",
            "                                                                 conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 8, 8, 768)    3072        add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 8, 8, 768)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 8, 8, 768)    0           activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 384)    295296      dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 384)    1536        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 8, 8, 384)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 8, 8, 384)    0           activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 384)    1327488     dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 8, 8, 384)    1536        conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 8, 8, 384)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 8, 8, 384)    0           activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 8, 8, 768)    295680      dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 8, 8, 768)    0           add_61[0][0]                     \n",
            "                                                                 conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 8, 8, 768)    3072        add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 8, 8, 768)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 1, 1, 768)    0           activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 768)          0           average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 10)           7690        flatten_8[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 5,093,770\n",
            "Trainable params: 5,083,306\n",
            "Non-trainable params: 10,464\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 171s 440ms/step - loss: 2.0194 - acc: 0.4905 - val_loss: 2.5240 - val_acc: 0.4207\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 1.3447 - acc: 0.6321 - val_loss: 2.3266 - val_acc: 0.3966\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 1.1700 - acc: 0.6798 - val_loss: 1.4686 - val_acc: 0.5822\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 1.0654 - acc: 0.7142 - val_loss: 1.5676 - val_acc: 0.5259\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.9685 - acc: 0.7459 - val_loss: 1.2627 - val_acc: 0.6599\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.8933 - acc: 0.7738 - val_loss: 1.0629 - val_acc: 0.7151\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.8329 - acc: 0.7923 - val_loss: 1.0909 - val_acc: 0.7049\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.7809 - acc: 0.8094 - val_loss: 0.9355 - val_acc: 0.7552\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.7375 - acc: 0.8246 - val_loss: 0.8316 - val_acc: 0.7910\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.6952 - acc: 0.8370 - val_loss: 1.0838 - val_acc: 0.7297\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.6568 - acc: 0.8481 - val_loss: 1.0576 - val_acc: 0.7356\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.6269 - acc: 0.8586 - val_loss: 0.8343 - val_acc: 0.8004\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.5940 - acc: 0.8669 - val_loss: 0.7985 - val_acc: 0.8077\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.5628 - acc: 0.8791 - val_loss: 0.8565 - val_acc: 0.7947\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 150s 383ms/step - loss: 0.5429 - acc: 0.8845 - val_loss: 0.7745 - val_acc: 0.8211\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.5155 - acc: 0.8908 - val_loss: 0.8098 - val_acc: 0.8104\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.4919 - acc: 0.9000 - val_loss: 0.7893 - val_acc: 0.8086\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.4724 - acc: 0.9068 - val_loss: 0.8459 - val_acc: 0.8015\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.4534 - acc: 0.9138 - val_loss: 0.7155 - val_acc: 0.8334\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.4311 - acc: 0.9204 - val_loss: 0.8847 - val_acc: 0.7983\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.4191 - acc: 0.9238 - val_loss: 0.7458 - val_acc: 0.8315\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.4040 - acc: 0.9275 - val_loss: 0.7208 - val_acc: 0.8427\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.3812 - acc: 0.9350 - val_loss: 0.7070 - val_acc: 0.8455\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.3672 - acc: 0.9397 - val_loss: 0.6761 - val_acc: 0.8544\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.3570 - acc: 0.9422 - val_loss: 0.8302 - val_acc: 0.8295\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.3486 - acc: 0.9445 - val_loss: 0.7439 - val_acc: 0.8469\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.3409 - acc: 0.9465 - val_loss: 0.7632 - val_acc: 0.8418\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.3242 - acc: 0.9539 - val_loss: 0.7126 - val_acc: 0.8555\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 150s 383ms/step - loss: 0.3187 - acc: 0.9552 - val_loss: 0.8602 - val_acc: 0.8159\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 150s 384ms/step - loss: 0.3117 - acc: 0.9568 - val_loss: 0.9004 - val_acc: 0.8199\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 150s 383ms/step - loss: 0.2983 - acc: 0.9600 - val_loss: 0.7822 - val_acc: 0.8479\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2929 - acc: 0.9614 - val_loss: 0.8005 - val_acc: 0.8480\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2872 - acc: 0.9632 - val_loss: 0.7638 - val_acc: 0.8502\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2793 - acc: 0.9667 - val_loss: 0.8397 - val_acc: 0.8436\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2760 - acc: 0.9661 - val_loss: 0.7879 - val_acc: 0.8462\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 150s 383ms/step - loss: 0.2642 - acc: 0.9707 - val_loss: 0.8543 - val_acc: 0.8383\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 150s 383ms/step - loss: 0.2616 - acc: 0.9705 - val_loss: 0.8001 - val_acc: 0.8436\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2590 - acc: 0.9704 - val_loss: 0.7635 - val_acc: 0.8535\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2541 - acc: 0.9723 - val_loss: 0.6894 - val_acc: 0.8671\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 150s 383ms/step - loss: 0.2485 - acc: 0.9735 - val_loss: 0.8085 - val_acc: 0.8499\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2451 - acc: 0.9742 - val_loss: 0.7438 - val_acc: 0.8573\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2399 - acc: 0.9756 - val_loss: 0.7002 - val_acc: 0.8638\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 150s 384ms/step - loss: 0.2384 - acc: 0.9763 - val_loss: 0.7750 - val_acc: 0.8543\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2324 - acc: 0.9777 - val_loss: 0.7941 - val_acc: 0.8613\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2278 - acc: 0.9782 - val_loss: 0.7521 - val_acc: 0.8606\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2273 - acc: 0.9788 - val_loss: 0.8033 - val_acc: 0.8559\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2225 - acc: 0.9799 - val_loss: 0.8120 - val_acc: 0.8568\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 150s 383ms/step - loss: 0.2229 - acc: 0.9791 - val_loss: 0.7700 - val_acc: 0.8611\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2165 - acc: 0.9804 - val_loss: 0.8862 - val_acc: 0.8407\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.2139 - acc: 0.9820 - val_loss: 0.7330 - val_acc: 0.8606\n",
            "Model took 7490.48 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5kox+7RNmgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ogp78FWNLg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm6d7Dp-t57K",
        "colab_type": "text"
      },
      "source": [
        "## Increasing parameters has negative effect. The desired ibcrease in validation was not acheived as the highest validation accuracy was 86\n",
        "## Instead of increasing parameters it is better to go deep with same number of parameters\n",
        "## ResNet26V1 with 32 filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlY5PrHRuE4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a0381858-cca0-4ad1-a26b-a50482a7d256"
      },
      "source": [
        "n = 4\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUru3B8Ju25a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 32\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBzv9UPHvsUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f9a04a7-4689-442e-cecc-f757f866d901"
      },
      "source": [
        "print(depth)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax6CQ8oBvH46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36f0d80c-4d3e-47dc-be58-0f4517ffc95f"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 128),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 32, 32, 32)   896         input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 32, 32, 32)   128         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 32, 32, 32)   0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 32, 32, 32)   0           activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 32, 32, 32)   9248        dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 32, 32, 32)   128         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 32, 32, 32)   0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 32, 32, 32)   0           activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 32, 32, 32)   9248        dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 32, 32, 32)   128         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 32, 32, 32)   0           dropout_133[0][0]                \n",
            "                                                                 batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 32, 32, 32)   0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 32, 32, 32)   9248        activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 32, 32, 32)   128         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 32, 32, 32)   0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 32, 32, 32)   0           activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 32, 32, 32)   9248        dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 32, 32, 32)   128         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 32, 32, 32)   0           activation_167[0][0]             \n",
            "                                                                 batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 32, 32, 32)   0           add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 32, 32, 32)   9248        activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 32, 32, 32)   128         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 32, 32, 32)   0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 32, 32, 32)   0           activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 32, 32, 32)   9248        dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 32, 32, 32)   128         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 32, 32, 32)   0           activation_169[0][0]             \n",
            "                                                                 batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 32, 32, 32)   0           add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 32, 32, 32)   9248        activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 32, 32, 32)   128         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 32, 32, 32)   0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 32, 32, 32)   0           activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 32, 32, 32)   9248        dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 32, 32, 32)   128         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 32, 32, 32)   0           activation_171[0][0]             \n",
            "                                                                 batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 32, 32, 32)   0           add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 16, 16, 64)   18496       activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 16, 16, 64)   256         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 16, 16, 64)   0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 16, 16, 64)   0           activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 16, 16, 64)   36928       dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 16, 16, 64)   2112        activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 16, 16, 64)   256         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 16, 16, 64)   0           conv2d_203[0][0]                 \n",
            "                                                                 batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 16, 16, 64)   0           add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 16, 16, 64)   36928       activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 16, 16, 64)   256         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 16, 16, 64)   0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 16, 16, 64)   0           activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 16, 16, 64)   36928       dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 16, 16, 64)   256         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 16, 16, 64)   0           activation_175[0][0]             \n",
            "                                                                 batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 16, 16, 64)   0           add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 16, 16, 64)   36928       activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 16, 16, 64)   256         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 16, 16, 64)   0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 16, 16, 64)   0           activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 16, 16, 64)   36928       dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 16, 16, 64)   256         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 16, 16, 64)   0           activation_177[0][0]             \n",
            "                                                                 batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 16, 16, 64)   0           add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 16, 16, 64)   36928       activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 16, 16, 64)   256         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 16, 16, 64)   0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 16, 16, 64)   0           activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 16, 16, 64)   36928       dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 16, 16, 64)   256         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 16, 16, 64)   0           activation_179[0][0]             \n",
            "                                                                 batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 16, 16, 64)   0           add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 8, 8, 128)    73856       activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 8, 8, 128)    512         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 128)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 8, 8, 128)    0           activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 8, 8, 128)    147584      dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 8, 8, 128)    8320        activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 8, 8, 128)    512         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_72 (Add)                    (None, 8, 8, 128)    0           conv2d_212[0][0]                 \n",
            "                                                                 batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 128)    0           add_72[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 8, 8, 128)    147584      activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 8, 8, 128)    512         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 128)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 8, 8, 128)    0           activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 8, 8, 128)    147584      dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 8, 8, 128)    512         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_73 (Add)                    (None, 8, 8, 128)    0           activation_183[0][0]             \n",
            "                                                                 batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 128)    0           add_73[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 8, 8, 128)    147584      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 8, 8, 128)    512         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 128)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 8, 8, 128)    0           activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 8, 8, 128)    147584      dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 8, 8, 128)    512         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_74 (Add)                    (None, 8, 8, 128)    0           activation_185[0][0]             \n",
            "                                                                 batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 128)    0           add_74[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 8, 8, 128)    147584      activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 8, 8, 128)    512         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 8, 8, 128)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_145 (Dropout)           (None, 8, 8, 128)    0           activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 8, 8, 128)    147584      dropout_145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 8, 8, 128)    512         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 8, 8, 128)    0           activation_187[0][0]             \n",
            "                                                                 batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 8, 8, 128)    0           add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 1, 1, 128)    0           activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 128)          0           average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 10)           1290        flatten_9[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,477,834\n",
            "Trainable params: 1,474,186\n",
            "Non-trainable params: 3,648\n",
            "__________________________________________________________________________________________________\n",
            "ResNet26v1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 83s 212ms/step - loss: 1.8088 - acc: 0.4995 - val_loss: 2.0024 - val_acc: 0.4751\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 1.1963 - acc: 0.6897 - val_loss: 1.5587 - val_acc: 0.5992\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.9855 - acc: 0.7597 - val_loss: 1.0376 - val_acc: 0.7455\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.8607 - acc: 0.7972 - val_loss: 1.2169 - val_acc: 0.6986\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.7652 - acc: 0.8293 - val_loss: 1.2575 - val_acc: 0.6942\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.7021 - acc: 0.8453 - val_loss: 0.9017 - val_acc: 0.7853\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.6322 - acc: 0.8712 - val_loss: 0.8607 - val_acc: 0.8027\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.5875 - acc: 0.8836 - val_loss: 1.0392 - val_acc: 0.7567\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.5389 - acc: 0.9013 - val_loss: 0.8617 - val_acc: 0.8140\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.4915 - acc: 0.9172 - val_loss: 0.8014 - val_acc: 0.8270\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.4522 - acc: 0.9296 - val_loss: 0.8925 - val_acc: 0.8105\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.4228 - acc: 0.9391 - val_loss: 0.9723 - val_acc: 0.8010\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.3956 - acc: 0.9472 - val_loss: 0.9579 - val_acc: 0.7929\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.3683 - acc: 0.9556 - val_loss: 0.9663 - val_acc: 0.8122\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.3473 - acc: 0.9612 - val_loss: 0.8254 - val_acc: 0.8338\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.3275 - acc: 0.9674 - val_loss: 0.9172 - val_acc: 0.8341\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.3098 - acc: 0.9720 - val_loss: 0.9103 - val_acc: 0.8337\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 58s 150ms/step - loss: 0.3010 - acc: 0.9733 - val_loss: 0.9964 - val_acc: 0.8224\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2850 - acc: 0.9778 - val_loss: 1.1492 - val_acc: 0.7918\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2816 - acc: 0.9772 - val_loss: 0.8244 - val_acc: 0.8443\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2712 - acc: 0.9793 - val_loss: 0.8940 - val_acc: 0.8488\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 57s 147ms/step - loss: 0.2616 - acc: 0.9821 - val_loss: 0.9236 - val_acc: 0.8347\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 57s 147ms/step - loss: 0.2513 - acc: 0.9841 - val_loss: 0.8297 - val_acc: 0.8481\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2501 - acc: 0.9839 - val_loss: 0.9987 - val_acc: 0.8240\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 57s 147ms/step - loss: 0.2370 - acc: 0.9865 - val_loss: 1.0309 - val_acc: 0.8275\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 57s 147ms/step - loss: 0.2369 - acc: 0.9850 - val_loss: 0.9852 - val_acc: 0.8304\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 58s 147ms/step - loss: 0.2269 - acc: 0.9880 - val_loss: 0.8803 - val_acc: 0.8539\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2233 - acc: 0.9880 - val_loss: 1.0613 - val_acc: 0.8255\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2217 - acc: 0.9878 - val_loss: 1.0035 - val_acc: 0.8304\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2140 - acc: 0.9895 - val_loss: 0.8787 - val_acc: 0.8505\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2072 - acc: 0.9907 - val_loss: 1.0006 - val_acc: 0.8350\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2088 - acc: 0.9887 - val_loss: 0.8172 - val_acc: 0.8552\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.2026 - acc: 0.9904 - val_loss: 0.8451 - val_acc: 0.8516\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 58s 147ms/step - loss: 0.1982 - acc: 0.9908 - val_loss: 0.8860 - val_acc: 0.8519\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1935 - acc: 0.9914 - val_loss: 0.9655 - val_acc: 0.8453\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1918 - acc: 0.9914 - val_loss: 1.0159 - val_acc: 0.8321\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1908 - acc: 0.9913 - val_loss: 0.8409 - val_acc: 0.8591\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1863 - acc: 0.9913 - val_loss: 0.8366 - val_acc: 0.8571\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1814 - acc: 0.9932 - val_loss: 0.8324 - val_acc: 0.8558\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1764 - acc: 0.9935 - val_loss: 1.1370 - val_acc: 0.8307\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1755 - acc: 0.9928 - val_loss: 0.9095 - val_acc: 0.8528\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1721 - acc: 0.9937 - val_loss: 0.9004 - val_acc: 0.8551\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1727 - acc: 0.9929 - val_loss: 0.8566 - val_acc: 0.8565\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.1684 - acc: 0.9936 - val_loss: 0.8021 - val_acc: 0.8621\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1681 - acc: 0.9930 - val_loss: 0.9096 - val_acc: 0.8570\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1619 - acc: 0.9948 - val_loss: 0.8519 - val_acc: 0.8578\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1613 - acc: 0.9940 - val_loss: 0.8253 - val_acc: 0.8608\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 58s 147ms/step - loss: 0.1588 - acc: 0.9944 - val_loss: 0.8682 - val_acc: 0.8587\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1566 - acc: 0.9946 - val_loss: 0.8988 - val_acc: 0.8519\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 58s 148ms/step - loss: 0.1551 - acc: 0.9949 - val_loss: 0.9274 - val_acc: 0.8477\n",
            "Model took 2917.48 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREpJP4f5lkFndr8RjkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGQmpP39vZ4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCE2s4JL-NlM",
        "colab_type": "text"
      },
      "source": [
        "## Resnet20V1 with 32 filter and 2 Million parameters and batch size of 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-QxlRSa-XAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "3b215bfc-f38c-45a9-b4d6-5443a0823054"
      },
      "source": [
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX7UH2Uh_s-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=32,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppnzDroz-p8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 32\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0WBFJqf-3ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe2aa776-4887-4a24-8f64-b5dd0217179d"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 32),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_18 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 32, 32, 32)   896         input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 32, 32, 32)   128         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 32, 32, 32)   0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_166 (Dropout)           (None, 32, 32, 32)   0           activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 32, 32, 32)   9248        dropout_166[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 32, 32, 32)   128         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 32, 32, 32)   0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_167 (Dropout)           (None, 32, 32, 32)   0           activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 32, 32, 32)   9248        dropout_167[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 32, 32, 32)   128         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_94 (Add)                    (None, 32, 32, 32)   0           dropout_166[0][0]                \n",
            "                                                                 batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 32, 32, 32)   0           add_94[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 32, 32, 32)   9248        activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 32, 32, 32)   128         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 32, 32, 32)   0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_168 (Dropout)           (None, 32, 32, 32)   0           activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 32, 32, 32)   9248        dropout_168[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 32, 32, 32)   128         conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_95 (Add)                    (None, 32, 32, 32)   0           activation_230[0][0]             \n",
            "                                                                 batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 32, 32, 32)   0           add_95[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 32, 32, 32)   9248        activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 32, 32, 32)   128         conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 32, 32, 32)   0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_169 (Dropout)           (None, 32, 32, 32)   0           activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 32, 32, 32)   9248        dropout_169[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 32, 32, 32)   128         conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_96 (Add)                    (None, 32, 32, 32)   0           activation_232[0][0]             \n",
            "                                                                 batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 32, 32, 32)   0           add_96[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 16, 16, 64)   18496       activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 16, 16, 64)   256         conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 16, 16, 64)   0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_170 (Dropout)           (None, 16, 16, 64)   0           activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 16, 16, 64)   36928       dropout_170[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 16, 16, 64)   2112        activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 16, 16, 64)   256         conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_97 (Add)                    (None, 16, 16, 64)   0           conv2d_270[0][0]                 \n",
            "                                                                 batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 16, 16, 64)   0           add_97[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 16, 16, 64)   36928       activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 16, 16, 64)   256         conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 16, 16, 64)   0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_171 (Dropout)           (None, 16, 16, 64)   0           activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 16, 16, 64)   36928       dropout_171[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 16, 16, 64)   256         conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_98 (Add)                    (None, 16, 16, 64)   0           activation_236[0][0]             \n",
            "                                                                 batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 16, 16, 64)   0           add_98[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 16, 16, 64)   36928       activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 16, 16, 64)   256         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 16, 16, 64)   0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_172 (Dropout)           (None, 16, 16, 64)   0           activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 16, 16, 64)   36928       dropout_172[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 16, 16, 64)   256         conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_99 (Add)                    (None, 16, 16, 64)   0           activation_238[0][0]             \n",
            "                                                                 batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 16, 16, 64)   0           add_99[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 8, 8, 128)    73856       activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 8, 8, 128)    512         conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 8, 8, 128)    0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_173 (Dropout)           (None, 8, 8, 128)    0           activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 8, 8, 128)    147584      dropout_173[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 8, 8, 128)    8320        activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 8, 8, 128)    512         conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_100 (Add)                   (None, 8, 8, 128)    0           conv2d_277[0][0]                 \n",
            "                                                                 batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 8, 8, 128)    0           add_100[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 8, 8, 128)    147584      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 8, 8, 128)    512         conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 8, 8, 128)    0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_174 (Dropout)           (None, 8, 8, 128)    0           activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 8, 8, 128)    147584      dropout_174[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 8, 8, 128)    512         conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_101 (Add)                   (None, 8, 8, 128)    0           activation_242[0][0]             \n",
            "                                                                 batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 8, 8, 128)    0           add_101[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 128)    147584      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 8, 8, 128)    512         conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 8, 8, 128)    0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_175 (Dropout)           (None, 8, 8, 128)    0           activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 8, 8, 128)    147584      dropout_175[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 8, 8, 128)    512         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_102 (Add)                   (None, 8, 8, 128)    0           activation_244[0][0]             \n",
            "                                                                 batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 8, 8, 128)    0           add_102[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 1, 1, 128)    0           activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 128)          0           average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 10)           1290        flatten_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,088,522\n",
            "Trainable params: 1,085,770\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=1562, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 1.6468 - acc: 0.5100 - val_loss: 1.5029 - val_acc: 0.5609\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 1.1943 - acc: 0.6814 - val_loss: 1.3542 - val_acc: 0.6337\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 1.0203 - acc: 0.7470 - val_loss: 1.0845 - val_acc: 0.7299\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 0.8996 - acc: 0.7866 - val_loss: 0.9218 - val_acc: 0.7788\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.8115 - acc: 0.8129 - val_loss: 1.1559 - val_acc: 0.7216\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.7392 - acc: 0.8334 - val_loss: 0.8815 - val_acc: 0.7847\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.6803 - acc: 0.8510 - val_loss: 0.7686 - val_acc: 0.8229\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "1562/1562 [==============================] - 74s 48ms/step - loss: 0.6312 - acc: 0.8650 - val_loss: 0.7411 - val_acc: 0.8320\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "1562/1562 [==============================] - 74s 48ms/step - loss: 0.5865 - acc: 0.8788 - val_loss: 0.7553 - val_acc: 0.8242\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.5508 - acc: 0.8886 - val_loss: 0.6639 - val_acc: 0.8528\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 0.5102 - acc: 0.9013 - val_loss: 0.7821 - val_acc: 0.8284\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 0.4789 - acc: 0.9134 - val_loss: 0.7375 - val_acc: 0.8404\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.4518 - acc: 0.9215 - val_loss: 0.7950 - val_acc: 0.8261\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 0.4236 - acc: 0.9309 - val_loss: 0.6920 - val_acc: 0.8565\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.4011 - acc: 0.9359 - val_loss: 0.7081 - val_acc: 0.8469\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.3833 - acc: 0.9419 - val_loss: 0.7364 - val_acc: 0.8437\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.3608 - acc: 0.9488 - val_loss: 0.7613 - val_acc: 0.8395\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 0.3495 - acc: 0.9508 - val_loss: 0.7692 - val_acc: 0.8455\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.3367 - acc: 0.9557 - val_loss: 0.7030 - val_acc: 0.8579\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 0.3211 - acc: 0.9591 - val_loss: 0.7647 - val_acc: 0.8487\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.3075 - acc: 0.9627 - val_loss: 0.6925 - val_acc: 0.8648\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 0.3000 - acc: 0.9654 - val_loss: 0.6706 - val_acc: 0.8658\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "1562/1562 [==============================] - 73s 47ms/step - loss: 0.2892 - acc: 0.9687 - val_loss: 0.7988 - val_acc: 0.8469\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.2813 - acc: 0.9699 - val_loss: 0.7970 - val_acc: 0.8494\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "1562/1562 [==============================] - 74s 47ms/step - loss: 0.2737 - acc: 0.9709 - val_loss: 0.6753 - val_acc: 0.8687\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "1562/1562 [==============================] - 75s 48ms/step - loss: 0.2631 - acc: 0.9735 - val_loss: 0.7604 - val_acc: 0.8555\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2615 - acc: 0.9741 - val_loss: 0.7320 - val_acc: 0.8594\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "1562/1562 [==============================] - 75s 48ms/step - loss: 0.2503 - acc: 0.9773 - val_loss: 0.7337 - val_acc: 0.8629\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "1562/1562 [==============================] - 75s 48ms/step - loss: 0.2466 - acc: 0.9767 - val_loss: 0.7136 - val_acc: 0.8643\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "1562/1562 [==============================] - 75s 48ms/step - loss: 0.2418 - acc: 0.9776 - val_loss: 0.7336 - val_acc: 0.8632\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "1562/1562 [==============================] - 73s 46ms/step - loss: 0.2364 - acc: 0.9782 - val_loss: 0.7598 - val_acc: 0.8588\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "1562/1562 [==============================] - 72s 46ms/step - loss: 0.2292 - acc: 0.9799 - val_loss: 0.7468 - val_acc: 0.8559\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "1562/1562 [==============================] - 72s 46ms/step - loss: 0.2251 - acc: 0.9815 - val_loss: 0.7625 - val_acc: 0.8626\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2217 - acc: 0.9814 - val_loss: 0.7333 - val_acc: 0.8653\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "1562/1562 [==============================] - 71s 46ms/step - loss: 0.2157 - acc: 0.9825 - val_loss: 0.7266 - val_acc: 0.8658\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "1562/1562 [==============================] - 71s 46ms/step - loss: 0.2132 - acc: 0.9827 - val_loss: 0.7576 - val_acc: 0.8632\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "1562/1562 [==============================] - 71s 46ms/step - loss: 0.2099 - acc: 0.9827 - val_loss: 0.7164 - val_acc: 0.8662\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "1562/1562 [==============================] - 72s 46ms/step - loss: 0.2041 - acc: 0.9840 - val_loss: 0.7960 - val_acc: 0.8611\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "1562/1562 [==============================] - 71s 46ms/step - loss: 0.2020 - acc: 0.9848 - val_loss: 0.7161 - val_acc: 0.8683\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "1562/1562 [==============================] - 71s 45ms/step - loss: 0.1971 - acc: 0.9853 - val_loss: 0.7935 - val_acc: 0.8576\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "1562/1562 [==============================] - 71s 45ms/step - loss: 0.1977 - acc: 0.9844 - val_loss: 0.7429 - val_acc: 0.8659\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "1562/1562 [==============================] - 71s 45ms/step - loss: 0.1917 - acc: 0.9855 - val_loss: 0.7536 - val_acc: 0.8635\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "1562/1562 [==============================] - 71s 46ms/step - loss: 0.1865 - acc: 0.9868 - val_loss: 0.7267 - val_acc: 0.8693\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "1562/1562 [==============================] - 71s 45ms/step - loss: 0.1846 - acc: 0.9865 - val_loss: 0.7879 - val_acc: 0.8578\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "1562/1562 [==============================] - 71s 45ms/step - loss: 0.1823 - acc: 0.9867 - val_loss: 0.7260 - val_acc: 0.8695\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "1562/1562 [==============================] - 71s 46ms/step - loss: 0.1778 - acc: 0.9879 - val_loss: 0.7344 - val_acc: 0.8699\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "1562/1562 [==============================] - 71s 46ms/step - loss: 0.1766 - acc: 0.9877 - val_loss: 0.6908 - val_acc: 0.8734\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "1562/1562 [==============================] - 71s 45ms/step - loss: 0.1737 - acc: 0.9885 - val_loss: 0.7032 - val_acc: 0.8689\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "1562/1562 [==============================] - 71s 46ms/step - loss: 0.1717 - acc: 0.9879 - val_loss: 0.7205 - val_acc: 0.8730\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "1562/1562 [==============================] - 72s 46ms/step - loss: 0.1682 - acc: 0.9890 - val_loss: 0.7591 - val_acc: 0.8619\n",
            "Model took 3680.63 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He2ojfhN_IWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}