{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP4_Phase1_Assignment_4_ver3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharathbolla/EIP4/blob/assignment_4/EIP4_Phase1_Assignment_4_ver3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8SeRSLZimz1",
        "colab_type": "code",
        "outputId": "c5dcfddf-d6f1-43d4-9029-e4a92cbddbb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "#print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORnoLoAyiqQb",
        "colab_type": "code",
        "outputId": "fffb179f-73c1-491d-b08c-9f44f070a708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=35079b6745ef91c735992830a2913d5d7dade18049b759d7f18ca26bef316a3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU4ulPetizd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "100fWT9Gi3Px",
        "colab_type": "code",
        "outputId": "c2336573-6af2-4b9d-80ef-fc52491a8897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.7 GB  | Proc size: 415.1 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "najpwTCPi6cj",
        "colab_type": "code",
        "outputId": "97904ef6-dd3a-4871-e5fa-7d459b639a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec  9 11:03:01 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    32W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXKpjGGdi7wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, Dropout\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfFkFhX7jA4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "#batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zzN-vCMjC7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvDFhC8gjFcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5rDiwNwjHfn",
        "colab_type": "code",
        "outputId": "a9f45fff-5bb2-40a0-b4a3-9c90574aeabb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "n = 4\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 2\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 12s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D52mBtEMj0Ug",
        "colab_type": "text"
      },
      "source": [
        "## Droput Added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATK1fseSjLj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Id1GIjvjvlJ",
        "colab_type": "text"
      },
      "source": [
        "## Resnet38V2 two with 32 filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zatLffGjmyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 32\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhi8Tag1kDeo",
        "colab_type": "code",
        "outputId": "f1bf45a8-f786-4f3d-e021-113b9570a91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "#else:\n",
        "    #model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 128),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 32)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   1056        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 32)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9248        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 32)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 128)  4224        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 128)  4224        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 128)  0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 128)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 32)   4128        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 32)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9248        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 32)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  4224        dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 128)  0           add_1[0][0]                      \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 128)  0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 32)   4128        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 32)   0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 32)   9248        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 32)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  4224        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 128)  0           add_2[0][0]                      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 128)  0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 32)   4128        dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 32)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 32)   9248        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 32)   0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 128)  4224        dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 128)  0           add_3[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 128)  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 128)  16512       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 16, 16, 128)  0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 128)  147584      dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 16, 16, 128)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 256)  33024       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 256)  33024       dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 256)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 16, 16, 256)  0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 128)  32896       dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 128)  0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 128)  147584      dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 128)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 256)  33024       dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 256)  0           add_5[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 256)  1024        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 256)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 256)  0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 128)  32896       dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 128)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 128)  0           activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 128)  147584      dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 128)  512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 128)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 128)  0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 256)  33024       dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 256)  0           add_6[0][0]                      \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 256)  1024        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 256)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 16, 16, 256)  0           activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 128)  32896       dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 128)  512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 128)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 128)  0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 128)  147584      dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 128)  512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 128)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 16, 16, 128)  0           activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 256)  33024       dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 256)  0           add_7[0][0]                      \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 256)  1024        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 256)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 256)  0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 256)    65792       dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 256)    1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 256)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 8, 8, 256)    0           activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 256)    590080      dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 256)    1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 256)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 8, 8, 256)    0           activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 512)    131584      add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 512)    131584      dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 512)    0           conv2d_31[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 512)    2048        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 512)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 8, 8, 512)    0           activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 256)    131328      dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 8, 8, 256)    0           activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 256)    590080      dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 256)    1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 256)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 8, 8, 256)    0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 512)    131584      dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 512)    0           add_9[0][0]                      \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 512)    2048        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 512)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 8, 8, 512)    0           activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 256)    131328      dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 256)    1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 256)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 8, 8, 256)    0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 256)    590080      dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 256)    1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 256)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 8, 8, 256)    0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 512)    131584      dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 512)    0           add_10[0][0]                     \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 512)    2048        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 512)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 8, 8, 512)    0           activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 256)    131328      dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 256)    1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 256)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 8, 8, 256)    0           activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 256)    590080      dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 256)    1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 256)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 8, 8, 256)    0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 512)    131584      dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 512)    0           add_11[0][0]                     \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 512)    2048        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 512)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           5130        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,454,026\n",
            "Trainable params: 4,440,138\n",
            "Non-trainable params: 13,888\n",
            "__________________________________________________________________________________________________\n",
            "ResNet38v2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 186s 478ms/step - loss: 2.0623 - acc: 0.4838 - val_loss: 2.0728 - val_acc: 0.4696\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 1.3324 - acc: 0.6399 - val_loss: 2.0003 - val_acc: 0.4715\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 171s 439ms/step - loss: 1.1588 - acc: 0.6883 - val_loss: 1.4409 - val_acc: 0.6026\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 171s 440ms/step - loss: 1.0373 - acc: 0.7254 - val_loss: 1.2421 - val_acc: 0.6563\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 171s 440ms/step - loss: 0.9554 - acc: 0.7529 - val_loss: 1.8268 - val_acc: 0.5173\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 171s 439ms/step - loss: 0.8747 - acc: 0.7808 - val_loss: 1.1624 - val_acc: 0.6898\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.8168 - acc: 0.7977 - val_loss: 0.9391 - val_acc: 0.7659\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.7636 - acc: 0.8130 - val_loss: 0.8189 - val_acc: 0.7958\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.7227 - acc: 0.8254 - val_loss: 0.8419 - val_acc: 0.7871\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.6831 - acc: 0.8395 - val_loss: 0.8959 - val_acc: 0.7804\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.6476 - acc: 0.8482 - val_loss: 0.8742 - val_acc: 0.7752\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.6181 - acc: 0.8578 - val_loss: 0.9813 - val_acc: 0.7586\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.5873 - acc: 0.8661 - val_loss: 0.7933 - val_acc: 0.8077\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 171s 440ms/step - loss: 0.5548 - acc: 0.8783 - val_loss: 0.7077 - val_acc: 0.8288\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.5349 - acc: 0.8840 - val_loss: 0.7103 - val_acc: 0.8302\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.5153 - acc: 0.8907 - val_loss: 0.8331 - val_acc: 0.7919\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.4887 - acc: 0.8983 - val_loss: 0.7828 - val_acc: 0.8175\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.4692 - acc: 0.9045 - val_loss: 0.6765 - val_acc: 0.8443\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.4509 - acc: 0.9100 - val_loss: 0.7073 - val_acc: 0.8427\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.4376 - acc: 0.9135 - val_loss: 0.6701 - val_acc: 0.8434\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.4149 - acc: 0.9217 - val_loss: 0.6444 - val_acc: 0.8578\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3980 - acc: 0.9265 - val_loss: 0.6892 - val_acc: 0.8449\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3858 - acc: 0.9310 - val_loss: 0.6714 - val_acc: 0.8534\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3756 - acc: 0.9334 - val_loss: 0.6136 - val_acc: 0.8642\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3634 - acc: 0.9369 - val_loss: 0.6106 - val_acc: 0.8734\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3534 - acc: 0.9403 - val_loss: 0.6696 - val_acc: 0.8605\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3443 - acc: 0.9424 - val_loss: 0.6670 - val_acc: 0.8643\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3289 - acc: 0.9472 - val_loss: 0.6801 - val_acc: 0.8591\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3197 - acc: 0.9504 - val_loss: 0.6649 - val_acc: 0.8646\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3107 - acc: 0.9538 - val_loss: 0.7022 - val_acc: 0.8582\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.3032 - acc: 0.9561 - val_loss: 0.6556 - val_acc: 0.8656\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2956 - acc: 0.9574 - val_loss: 0.7817 - val_acc: 0.8466\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2917 - acc: 0.9591 - val_loss: 0.8164 - val_acc: 0.8312\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2855 - acc: 0.9599 - val_loss: 0.6886 - val_acc: 0.8653\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2797 - acc: 0.9618 - val_loss: 0.6556 - val_acc: 0.8673\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.2732 - acc: 0.9642 - val_loss: 0.6526 - val_acc: 0.8744\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2658 - acc: 0.9672 - val_loss: 0.7056 - val_acc: 0.8573\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2602 - acc: 0.9680 - val_loss: 0.6603 - val_acc: 0.8714\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2575 - acc: 0.9685 - val_loss: 0.6532 - val_acc: 0.8763\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2479 - acc: 0.9711 - val_loss: 0.6377 - val_acc: 0.8781\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2466 - acc: 0.9710 - val_loss: 0.6800 - val_acc: 0.8704\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2433 - acc: 0.9716 - val_loss: 0.6873 - val_acc: 0.8644\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2368 - acc: 0.9740 - val_loss: 0.6629 - val_acc: 0.8720\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.2311 - acc: 0.9761 - val_loss: 0.6527 - val_acc: 0.8728\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2330 - acc: 0.9743 - val_loss: 0.7218 - val_acc: 0.8686\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2301 - acc: 0.9755 - val_loss: 0.6681 - val_acc: 0.8709\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2217 - acc: 0.9785 - val_loss: 0.6989 - val_acc: 0.8730\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.2217 - acc: 0.9773 - val_loss: 0.6273 - val_acc: 0.8816\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2218 - acc: 0.9773 - val_loss: 0.6662 - val_acc: 0.8759\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.2140 - acc: 0.9800 - val_loss: 0.6876 - val_acc: 0.8687\n",
            "Model took 8604.61 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7tKBJ4slZIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBshDWPj4XBK",
        "colab_type": "text"
      },
      "source": [
        "## Batch size of 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2vLr2KE4TXh",
        "colab_type": "code",
        "outputId": "6cd13c6f-3f84-4407-d4c3-688b7c62aec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "#else:\n",
        "    #model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 256),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 32, 32, 32)   896         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 32, 32, 32)   128         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 32, 32, 32)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 32, 32, 32)   0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 32)   1056        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 32, 32, 32)   128         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 32, 32, 32)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 32, 32, 32)   0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 32)   9248        dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 32)   128         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 32)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 32, 32, 32)   0           activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 32, 32, 128)  4224        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 128)  4224        dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 32, 32, 128)  0           conv2d_45[0][0]                  \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 128)  512         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 128)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 32, 32, 128)  0           activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 32, 32, 32)   4128        dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 32)   128         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 32)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 32, 32, 32)   0           activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 32, 32, 32)   9248        dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 32, 32, 32)   128         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 32)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 32, 32, 32)   0           activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 32, 32, 128)  4224        dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 32, 32, 128)  0           add_13[0][0]                     \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 32, 32, 128)  512         add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 32, 32, 128)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 32, 32, 128)  0           activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 32, 32, 32)   4128        dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 32, 32, 32)   128         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 32, 32, 32)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 32, 32, 32)   0           activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 32, 32, 32)   9248        dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 32, 32, 32)   128         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 32, 32, 32)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 32, 32, 32)   0           activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 32, 32, 128)  4224        dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 32, 32, 128)  0           add_14[0][0]                     \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 32, 32, 128)  512         add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 32, 32, 128)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 32, 32, 128)  0           activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 32, 32, 32)   4128        dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 32, 32, 32)   128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 32, 32, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 32, 32, 32)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 32, 32, 32)   9248        dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 32, 32, 32)   128         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 32, 32, 32)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 32, 32, 32)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 32, 32, 128)  4224        dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 32, 32, 128)  0           add_15[0][0]                     \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 128)  512         add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 128)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 32, 32, 128)  0           activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 128)  16512       dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 128)  512         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 16, 16, 128)  0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 128)  147584      dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 128)  512         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 128)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 16, 16, 128)  0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 256)  33024       add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 256)  33024       dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 16, 16, 256)  0           conv2d_58[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 256)  1024        add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 256)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 16, 16, 256)  0           activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 128)  32896       dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 128)  512         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 16, 16, 128)  0           activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 128)  147584      dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 128)  512         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 128)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 16, 16, 128)  0           activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 256)  33024       dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 16, 16, 256)  0           add_17[0][0]                     \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 256)  1024        add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 256)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 16, 16, 256)  0           activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 128)  32896       dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 128)  512         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 128)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 16, 16, 128)  0           activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 128)  147584      dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 128)  512         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 128)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 16, 16, 128)  0           activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 256)  33024       dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 16, 16, 256)  0           add_18[0][0]                     \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 256)  1024        add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 256)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 16, 16, 256)  0           activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 128)  32896       dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 128)  512         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 128)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 16, 16, 128)  0           activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 128)  147584      dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 128)  512         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 128)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 16, 16, 128)  0           activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 256)  33024       dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 16, 16, 256)  0           add_19[0][0]                     \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 256)  1024        add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 256)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 16, 16, 256)  0           activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 256)    65792       dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 8, 8, 256)    1024        conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 8, 8, 256)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 8, 8, 256)    0           activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 256)    590080      dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 8, 8, 256)    1024        conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 256)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 8, 8, 256)    0           activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 512)    131584      add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 512)    131584      dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 8, 8, 512)    0           conv2d_71[0][0]                  \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 8, 8, 512)    2048        add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 8, 8, 512)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 8, 8, 512)    0           activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 256)    131328      dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 256)    1024        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 256)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 8, 8, 256)    0           activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 256)    590080      dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 256)    1024        conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 256)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 8, 8, 256)    0           activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 512)    131584      dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 8, 8, 512)    0           add_21[0][0]                     \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 512)    2048        add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 512)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 8, 8, 512)    0           activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 256)    131328      dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 256)    1024        conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 256)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 8, 8, 256)    0           activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 256)    590080      dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 256)    1024        conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 256)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 8, 8, 256)    0           activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 512)    131584      dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 8, 8, 512)    0           add_22[0][0]                     \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 512)    2048        add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 512)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 8, 8, 512)    0           activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 256)    131328      dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 256)    1024        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 256)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 8, 8, 256)    0           activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 256)    590080      dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 256)    1024        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 256)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 8, 8, 256)    0           activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 512)    131584      dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 8, 8, 512)    0           add_23[0][0]                     \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 512)    2048        add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 512)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 512)    0           activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 512)          0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           5130        flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,454,026\n",
            "Trainable params: 4,440,138\n",
            "Non-trainable params: 13,888\n",
            "__________________________________________________________________________________________________\n",
            "ResNet38v2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=195, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "195/195 [==============================] - 79s 408ms/step - loss: 2.2581 - acc: 0.4825 - val_loss: 4.5067 - val_acc: 0.2375\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "195/195 [==============================] - 60s 308ms/step - loss: 1.4167 - acc: 0.6410 - val_loss: 2.7954 - val_acc: 0.3765\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 1.2040 - acc: 0.6933 - val_loss: 1.4911 - val_acc: 0.6011\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 1.0615 - acc: 0.7372 - val_loss: 2.0102 - val_acc: 0.4964\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.9644 - acc: 0.7665 - val_loss: 1.2949 - val_acc: 0.6486\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.8834 - acc: 0.7934 - val_loss: 1.0816 - val_acc: 0.7229\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.8230 - acc: 0.8113 - val_loss: 0.9784 - val_acc: 0.7558\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.7705 - acc: 0.8283 - val_loss: 1.0550 - val_acc: 0.7436\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.7207 - acc: 0.8434 - val_loss: 0.9255 - val_acc: 0.7734\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.6824 - acc: 0.8540 - val_loss: 1.2104 - val_acc: 0.6987\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.6494 - acc: 0.8645 - val_loss: 0.8156 - val_acc: 0.8136\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.6070 - acc: 0.8779 - val_loss: 0.8397 - val_acc: 0.8039\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.5841 - acc: 0.8839 - val_loss: 0.8388 - val_acc: 0.8133\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.5547 - acc: 0.8946 - val_loss: 0.8146 - val_acc: 0.8170\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.5278 - acc: 0.9015 - val_loss: 0.7925 - val_acc: 0.8230\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.5019 - acc: 0.9098 - val_loss: 0.8910 - val_acc: 0.8048\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.4843 - acc: 0.9159 - val_loss: 0.7687 - val_acc: 0.8270\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.4594 - acc: 0.9232 - val_loss: 0.8217 - val_acc: 0.8274\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.4439 - acc: 0.9270 - val_loss: 0.7444 - val_acc: 0.8449\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.4250 - acc: 0.9328 - val_loss: 0.7554 - val_acc: 0.8376\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.4051 - acc: 0.9393 - val_loss: 0.8076 - val_acc: 0.8356\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.3950 - acc: 0.9423 - val_loss: 0.7684 - val_acc: 0.8420\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "195/195 [==============================] - 59s 305ms/step - loss: 0.3834 - acc: 0.9460 - val_loss: 0.6927 - val_acc: 0.8568\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.3643 - acc: 0.9512 - val_loss: 0.7848 - val_acc: 0.8426\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.3544 - acc: 0.9538 - val_loss: 0.7726 - val_acc: 0.8462\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.3430 - acc: 0.9578 - val_loss: 0.6780 - val_acc: 0.8594\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.3303 - acc: 0.9615 - val_loss: 0.7398 - val_acc: 0.8494\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.3244 - acc: 0.9635 - val_loss: 0.7694 - val_acc: 0.8500\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.3103 - acc: 0.9673 - val_loss: 0.8276 - val_acc: 0.8426\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "195/195 [==============================] - 59s 305ms/step - loss: 0.3072 - acc: 0.9676 - val_loss: 0.8186 - val_acc: 0.8439\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.3008 - acc: 0.9687 - val_loss: 0.7602 - val_acc: 0.8566\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.2942 - acc: 0.9702 - val_loss: 0.7700 - val_acc: 0.8572\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.2902 - acc: 0.9716 - val_loss: 0.7413 - val_acc: 0.8582\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.2822 - acc: 0.9729 - val_loss: 0.8940 - val_acc: 0.8327\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.2744 - acc: 0.9761 - val_loss: 0.7346 - val_acc: 0.8667\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "195/195 [==============================] - 59s 305ms/step - loss: 0.2679 - acc: 0.9774 - val_loss: 0.7574 - val_acc: 0.8611\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "195/195 [==============================] - 60s 308ms/step - loss: 0.2611 - acc: 0.9790 - val_loss: 0.7299 - val_acc: 0.8620\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "195/195 [==============================] - 60s 308ms/step - loss: 0.2574 - acc: 0.9798 - val_loss: 0.7662 - val_acc: 0.8589\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.2582 - acc: 0.9791 - val_loss: 0.7982 - val_acc: 0.8618\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.2556 - acc: 0.9788 - val_loss: 0.7380 - val_acc: 0.8688\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.2440 - acc: 0.9823 - val_loss: 0.7561 - val_acc: 0.8667\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.2448 - acc: 0.9811 - val_loss: 0.7347 - val_acc: 0.8699\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.2383 - acc: 0.9835 - val_loss: 0.7755 - val_acc: 0.8589\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.2387 - acc: 0.9826 - val_loss: 0.8008 - val_acc: 0.8605\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.2301 - acc: 0.9853 - val_loss: 0.8639 - val_acc: 0.8488\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.2313 - acc: 0.9839 - val_loss: 0.8380 - val_acc: 0.8551\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "195/195 [==============================] - 60s 308ms/step - loss: 0.2241 - acc: 0.9865 - val_loss: 0.7743 - val_acc: 0.8665\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "195/195 [==============================] - 60s 306ms/step - loss: 0.2202 - acc: 0.9866 - val_loss: 0.7592 - val_acc: 0.8697\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "195/195 [==============================] - 60s 308ms/step - loss: 0.2222 - acc: 0.9849 - val_loss: 0.7226 - val_acc: 0.8717\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "195/195 [==============================] - 60s 307ms/step - loss: 0.2171 - acc: 0.9867 - val_loss: 0.7833 - val_acc: 0.8682\n",
            "Model took 3013.39 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXxcdb3/8dcnySSZLG32dG+60ZW9\n7CD7IruyC4IbXO8FBHdUVC4/VPR6r4qoCCqKssgOssiiBWSVlgJd6b4kbdqszb5/f398J22aNsk0\nncnMpO/n43EeZ+acM+d8JkXPfM73+/18zTmHiIiIiIiIJL6kWAcgIiIiIiIikaEET0REREREZJhQ\ngiciIiIiIjJMKMETEREREREZJpTgiYiIiIiIDBNK8ERERERERIYJJXgie8nMSszMmVlKGMd+xsxe\nH4q4REREEpXurSKDpwRP9ilmts7M2sysoNf2haEbSUlsItspliwzazCz52Mdi4iIyEDi+d66J4mi\nyHChBE/2RWuBy7rfmNn+QEbswtnFBUArcKqZjRrKC+sGKCIigxTv91aRfYYSPNkX/Rm4ssf7q4D7\neh5gZiPN7D4zqzCz9WZ2s5klhfYlm9lPzazSzNYAZ+3ms783s81mVmZmt5lZ8h7EdxVwF/AhcEWv\nc483s8dDcVWZ2Z099l1tZsvMrN7MlprZIaHtzsym9jjuj2Z2W+j1CWZWambfNLNy4F4zyzWzZ0LX\nqAm9Htfj83lmdq+ZbQrtfzK0fbGZndPjuEDob3TwHnx3ERFJTPF+b92FmaWZ2c9D97NNoddpoX0F\noftfrZlVm9m/esT6zVAM9Wb2kZmdvDdxiESaEjzZF70NjDCzmaGbw6XAX3od80tgJDAZOB5/0/ps\naN/VwNnAwcBc4MJen/0j0AFMDR1zGvCFcAIzs4nACcD9oeXKHvuSgWeA9UAJMBZ4KLTvIuCW0PEj\ngHOBqnCuCYwC8oCJwDX4/1+4N/R+AtAM3Nnj+D/jn8rOBoqAn4W238fOCemZwGbn3MIw4xARkcQV\nt/fWfnwHOBI4CDgQOBy4ObTvq0ApUAgUA98GnJlNB64DDnPOZQOnA+v2Mg6RiFKCJ/uq7ieNpwLL\ngLLuHT1uTN9yztU759YB/wt8OnTIxcDPnXMbnXPVwI96fLYYn9jc6JxrdM5txSdAl4YZ16eBD51z\nS/HJ2+weLWCHA2OAr4fO3eKc6x5U/gXgJ865d523yjm3PsxrdgHfd861OueanXNVzrnHnHNNzrl6\n4Af4GzFmNhr4OPBF51yNc67dOfdq6Dx/Ac40sxE9vsufw4xBREQSX7zeW/tyOXCrc26rc64C+O8e\n8bQDo4GJoXvdv5xzDugE0oBZZhZwzq1zzq3eyzhEIkrjbWRf9WfgNWASvbqQAAVAAN9S1m09vsUM\nfJK1sde+bhNDn91sZt3bknod358rgXsAnHNlZvYqvpvLQmA8sN4517Gbz40HBnuDqXDOtXS/MbMM\n/I3zDCA3tDk7dHMeD1Q752p6n8Q5t8nM3gAuMLMn8IngDYOMSUREEk+83lv7MmY38YwJvf4ffM+Y\nF0PXvNs5d7tzbpWZ3RjaN9vMXgC+4pzbtJexiESMWvBknxRq3VqLfyL4eK/dlfgndxN7bJvAjieR\nm/GJTs993TbiC6QUOOdyQssI59zsgWIys6OBacC3zKw8NCbuCOBToeInG4EJfRRC2QhM6ePUTew8\n0L134RbX6/1XgenAEc65EcDHukMMXSfPzHL6uNaf8N00LwLecs6V9XGciIgMM/F4bx3Apt3Esyn0\nXeqdc191zk3GD3v4SvdYO+fcA865Y0OfdcCP9zIOkYhSgif7ss8DJznnGntudM51Ag8DPzCz7NC4\nuK+wYyzBw8CXzGycmeUCN/X47GbgReB/zWyEmSWZ2RQzOz6MeK4CXgJm4ccDHATMAYL41rB/42+A\nt5tZppmlm9kxoc/+DviamR1q3tRQ3ADv45PEZDM7g1B3y35k48fd1ZpZHvD9Xt/veeDXoWIsATP7\nWI/PPgkcgm+56/30VkREhr94u7d2SwvdN7uXJOBB4GYzKzQ/xcP3uuMxs7ND91IDtuG7ZnaZ2XQz\nOylUjKUFf7/s2sO/kUhUKcGTfZZzbrVzbn4fu68HGoE1wOvAA8AfQvvuAV4APgDeY9enlFcCqcBS\noAZ4FN+Pv09mlo4ff/BL51x5j2UtvsvLVaGb4zn4AeYb8IO/Lwl9l0fwY+UeAOrxiVZe6PQ3hD5X\nix9v8GR/sQA/xyeVlfhB83/vtf/T+Kewy4GtwI3dO5xzzcBj+O45vf8uIiIyzMXTvbWXBnwy1r2c\nBNwGzMdXrV4Uuu5toeOnAS+HPvcW8Gvn3Dz8+Lvb8ffIcnyxsW/tQRwiUWd+vKiISGSY2feA/Zxz\nVwx4sIiIiIhElIqsiEjEhLp0fp4dVchEREREZAipi6aIRISZXY0fCP+8c+61WMcjIiIisi9SF00R\nEREREZFhQi14IiIiIiIiw4QSPBERERERkWEi4YqsFBQUuJKSkliHISIiQ2DBggWVzrnCWMeRKHSP\nFBHZN/R3f0y4BK+kpIT58/uaXkVERIYTM1sf6xgSie6RIiL7hv7uj+qiKSIiIiIiMkwowRMRERER\nERkmopbgmdkfzGyrmS3uY7+Z2R1mtsrMPjSzQ6IVi4iIiIiIyL4gmmPw/gjcCdzXx/6PA9NCyxHA\nb0LrPdbe3k5paSktLS2D+XjCSE9PZ9y4cQQCgViHIiIiIiISM/r937eoJXjOudfMrKSfQ84D7nN+\npvW3zSzHzEY75zbv6bVKS0vJzs6mpKQEMxtkxPHNOUdVVRWlpaVMmjQp1uGIiIiIiMSMfv/3LZZj\n8MYCG3u8Lw1t22MtLS3k5+cP239cADMjPz9/2D+lEBEREREZiH7/9y0hiqyY2TVmNt/M5ldUVPR1\nzBBHNfT2he8oIiIiIhKOfeG38WC+YywTvDJgfI/340LbduGcu9s5N9c5N7ewMP7mu62treXXv/71\nHn/uzDPPpLa2NgoRiYiIiIhItMTz7/9YJnhPA1eGqmkeCWwbzPi7eNDXP3BHR0e/n3vuuefIycmJ\nVlgiIiIiIhIF8fz7P2pFVszsQeAEoMDMSoHvAwEA59xdwHPAmcAqoAn4bLRiibabbrqJ1atXc9BB\nBxEIBEhPTyc3N5fly5ezYsUKzj//fDZu3EhLSws33HAD11xzDQAlJSXMnz+fhoYGPv7xj3Psscfy\n5ptvMnbsWJ566imCwWCMv5mIDFetHZ1srm1hU20z25rbAXChfc7tOC6QbORlppKbmUpuRiojgwGS\nk3buLtLZ5ahtaqOqsY2qhjaqGlupb+ngssMnDNG3kYhZ8iSkj4ApJ8U6EhGRuBbPv/+jWUXzsgH2\nO+DaaF1/KN1+++0sXryY999/n1deeYWzzjqLxYsXb69284c//IG8vDyam5s57LDDuOCCC8jPz9/p\nHCtXruTBBx/knnvu4eKLL+axxx7jiiuuiMXXEZEh1tXlqGxoZfO2FjZva8E5R3pqMhmBZIKpyQQD\nyaSHXtc1t7OxppnSmiZKa5pDi3/d2eUYGQzssuRkBGjt6KKstpmymmY21Taztb51ULGawchggLyM\nVFKSjerGNqob2+hyux538dzxuySDEudeuR0KpirBExEZQDz//o/mPHgx8d9/W8LSTXURPeesMSP4\n/jmzwz7+8MMP36mU6R133METTzwBwMaNG1m5cuUu/8CTJk3ioIMOAuDQQw9l3bp1ex+4iPSps8vR\n2tFJa3sXbZ1dpCQZgZQkUpP9khRmYtLR2cXGmmbWVDSwpqKRNZWNrKloYH1VE2aQmZZCZloKWWnJ\nZIVeZ6amsK25nc3bmtlU28KWuhY6emdIYQgkG2NygozLDXLS9CICKca25g5qm9qobWpjfVUjtc3t\n1DW3k5KcxNicIGNzgpw4vYgxOUHG5vr3ORkBusdwG/5F9/vW9i5qmtqoafKJXE1TOzWN/n1bRxeH\nTsyjICuV/MxU8rPSyM9KpSArjbzMVJTbJaBgLjRrbLiIJBb9/t/ZsEvw4kFmZub216+88govv/wy\nb731FhkZGZxwwgm7LXWalpa2/XVycjLNzc1DEqtIInLO0dzeSV1zB3UtPoGpa2lnW3M7NY3t1DaF\nEpFQYlLT6Pe1tHfS2tFFa0cn7Z39J1QpSUYgOYlAspGSnESSQZIZyUlGkhlJoRHM5dtadjpXXmYq\nkwsyOWZqAUkGjW0d1Ld00NjaQWV9Gw2tHTS2dTAiPcCokekcVpLL6JwgY0amM2pkkNEj00lJNpra\nOmlp66SprZPm9k6aQ+vs9BTG5WYwPi9IUXZ6WC1kXV0Os32j2pjspWAu1KyLdRQiIgknnn7/D7sE\nb08y7UjJzs6mvr5+t/u2bdtGbm4uGRkZLF++nLfffnuIoxNJTC3tnayramT1Vt8itqaykdUVDZTW\nNFPX3N5vi5cZ5AQD5GakkpMRYExOOjNGZ5ORmkxaSjJpKUmkpSSTHkgiLSWJQEoSnV2Otg7fmtfW\n0UV7aN3W0UWnc3Q5nyh1djn/vsvhgDE5QSYXZDK5MIsphZnkZKQO3R8pTOG2RoqQkQubFsY6ChGR\nPaLf/zsbdgleLOTn53PMMccwZ84cgsEgxcXF2/edccYZ3HXXXcycOZPp06dz5JFHxjBSkaHV2eWo\nD7WsdS91zR1+3dJOQ0sHDa2+hauhtZ2G1g4aWjupamilrLZ5p2IfY0amM7kwizPmjCQ3I8CI9AAj\ngn6dnZ4Sep1CbkYqI3ZTCEREwhDMheaaWEchIhL34vn3vzm35+M+Ymnu3Llu/vz5O21btmwZM2fO\njFFEQ2tf+q4ydJxzOAdd3S1VO713tLR3hRIxn5TVtYRet/pkrbZpR7fI2qY2apv9OK26lv5LBScZ\nZKWlkJ0eICsthaz0FLLSUsjJCDAp1CrmW8cyyUjV86h9kZktcM7NjXUciWJ398g98q//hX/cCt8p\nh4AqOYtI/NqXfhPv7rv2d3/ULyaRfcy25nZWbKnno/LQEnrdXSp/MLJDLWc5GQFyMlIpKcgkJxhg\nZKis/u6WEcEUgoFkjQsTiSfBPL9urlGCJyKSoJTgiQwjDa0dbA6VwK+ob2VrfUto3crWulbWVTWy\neduOQb7ZaSnsNyqbsw4YTVF2GslmJCUZFioo0l1YJDUliez0FLLTAmSlp/gukaFWt+z0FFKSk2L4\nrUUkYoK5ft1cAyPGxDYWEREZFCV4Igmopb2TVVsbfEvclnpWlNezYksDZbW7Vl9KDyRRlJ1OUXYa\nR07OZ/qobKYXZzN9VDajR6arBU1EduhO8JqqYxuHiIgMmhI8kTi3ramdJZu2sXjTNhaV1bGkbBvr\nqhq3TyydmpzE5MJM5pbk8qniCUzIy6AwO42i7DQKs9PISktREici4cno0UVTREQSkhI8kTjQ0dlF\neV0LZTXNlNU2U1rTzPLyOhaX1bGhumn7cWNzgswaM4JzDhzD9FHZ7FecTUl+hrpIikhk9OyiKSIi\nCUkJnsgQ6uxyrNhSz4L1NXywsZb1VU2U1TZTXtdCZ6953SbmZ7D/2JFcevh45owZyZyxI8nLjL85\n1kRkGNme4KmLpohIolKCFwNZWVk0NDTEOgwZArVNbSzcWMvC9TUs2FDDBxu30dDqpw7Iz0xlSmEW\nR0zKY2xukLE5we3rMTlB0gPJMY5eRPY5gQxITlMLnohIhA3l738leCIR4JyjtKaZpZvrWLqpbvu6\nu+hJksGMUSP4xMFjOWRiDodMyGVCXobGxolIfDHTZOciIglOCV4E3HTTTYwfP55rr70WgFtuuYWU\nlBTmzZtHTU0N7e3t3HbbbZx33nkxjlT2Vl1LO+srm1hf3cj6qibWVzWyrrKJZeV11Icm9TaDyQWZ\nHDIxl8uPnMBB43M4cFwOmWn6n5uIJIBgrqpoiogMIJ5//+sXZwRccskl3Hjjjdv/gR9++GFeeOEF\nvvSlLzFixAgqKys58sgjOffcc9Vik0CccyzdXMfLS7fy2soK1lQ0UNO082TghdlpTMzL4LyDxjBr\n9EhmjvbTD2Sk6n9aIpKgMvKguTbWUYiIxLV4/v0//H6FPn8TlC+K7DlH7Q8fv73P3QcffDBbt25l\n06ZNVFRUkJuby6hRo/jyl7/Ma6+9RlJSEmVlZWzZsoVRo0ZFNjaJqLaOLt5eU8XLy7bw8tItbNrW\nghkcOC6HM+aMZmJ+BiX5GUzMz2RCXoZa5URk+AnmQvXaWEchIhI+/f7fiX6dRshFF13Eo48+Snl5\nOZdccgn3338/FRUVLFiwgEAgQElJCS0tLbEOU3ZjU20zr6+s5NUVFby6ooKG1g7SA0kcN62QG0/d\nj5NmFFGQlRbrMEVEhkYwR1U0RUTCEK+//4dfgtdPph1Nl1xyCVdffTWVlZW8+uqrPPzwwxQVFREI\nBJg3bx7r16+PSVyyq6a2Dt5ZU81rKyv418pKVm31FY2KstM458DRnDKzmGOmFqiKpYjsm4J5KrIi\nIolFv/93MvwSvBiZPXs29fX1jB07ltGjR3P55ZdzzjnnsP/++zN37lxmzJgR6xD3SS3tnaza2sDy\n8no+Kq9jUdk2Fqyvob3TkZaSxBGT87n0sPEcN62Q/YqzNEZSRCSYCx0t0N4MgWCsoxERiVvx+vtf\nCV4ELVq0o+9vQUEBb7311m6P0xx40eGcY1HZNl75qILl5XUsL69nXWUj3fOHp6YkMb04m88dM4nj\nphUytyRXrXQiIr11T3beVA0jx8Y2FhGROBePv/+V4ElC6650+cyHm3n2w81sqG7CDCbkZTC9OJuz\n9x/N9FEjmD4qm5L8DFKSk2IdsohIfMvI8+vmGiV4IiIJSAmeJBznHB9tqefZDzfzzIebWVvZSHKS\ncczUAq47cSqnzS4mJyM11mGKiCSm7hY8jcMTEUlISvAkITS1dfDmqipeWbGVVz6qoLSmmSSDo6bk\nc83HJnP67FHkZSqpExHZa0rwREQS2rBJ8Jxzw75AhnMu1iEMGeccq7Y28OqKCl75qIJ/r62mrbOL\njNRkjp6SzxePn8Lps0dRmK3pC0REIirY3UVTUyWISHzT7//di2qCZ2ZnAL8AkoHfOedu77V/IvAH\noBCoBq5wzpXu6XXS09OpqqoiPz9/2P4jO+eoqqoiPT091qFEVU1jG08sLOOv727koy31AEwryuKq\noydywvQi5pbkkpaiwigiIlGjFjwRSQD6/d+3qCV4ZpYM/Ao4FSgF3jWzp51zS3sc9lPgPufcn8zs\nJOBHwKf39Frjxo2jtLSUioqKSIQet9LT0xk3blysw4i4ri7H66sq+ev8jby0ZAttnV0cOD6H/3fe\nbE6cUcS43IxYhygiEjOh++l8oMw5d3bULxgIQnKaEjwRiWv6/d+3aLbgHQ6scs6tATCzh4DzgJ4J\n3izgK6HX84AnB3OhQCDApEmT9iJUiYUNVU08vrCUR+aXUlbbTE5GgMuPnMAlh41nxqgRsQ5PRCRe\n3AAsA4bm/xjNfCXNJnXRFJH4pd//fYtmgjcW2NjjfSlwRK9jPgA+ie/G+Qkg28zynXNVUYxLYmhd\nZSPPLtrMc4s2s2RTHWZw7NQCvnXmDE6dVazulyIiPZjZOOAs4AfseCAafcFcteCJiCSoWBdZ+Rpw\np5l9BngNKAM6ex9kZtcA1wBMmDBhKOOTCFhT0cBzizbz7KJylm2uA+DgCTl858yZnHnAaMbmBGMc\noYhI3Po58A0ge0ivGsyF5tohvaSIiERGNBO8MmB8j/fjQtu2c85twrfgYWZZwAXOuV3uKM65u4G7\nAebOnbvvlJJMcG+uruTnL6/k32t9N59DJ+Zy81kz+fj+SupERAZiZmcDW51zC8zshH6Oi/xD0GAu\nVK+JzLlERGRIRTPBexeYZmaT8IndpcCneh5gZgVAtXOuC/gWvqKmJLi3Vlfx85dX8M7aaopHpPGd\nM2dy9oGjGT1SSZ2IyB44BjjXzM4E0oERZvYX59wVPQ+KykNQddEUEUlYUUvwnHMdZnYd8AJ+moQ/\nOOeWmNmtwHzn3NPACcCPzMzhu2heG614JPreWVPFz15ewdtrqinKTuOWc2Zx6eETSA9oXJ2IyJ5y\nzn0L//CTUAve13ond1GjBE9EJGFFdQyec+454Lle277X4/WjwKPRjEGiq76lnbdWV/HHN9fx5uoq\nCrPT+P45s7hMiZ2ISOLKyIOOFmhrglRNVSMikkhiXWRFEkxHZxcflNbyr5WVvL6ykoUba+nschRk\npfHds2dx+RFK7EREIs059wrwypBdsOdk50rwREQSihI8GZBzjucXl/PEwjLeXl1FfWsHZnDA2JF8\n8fjJHDu1kEMn5pKakhTrUEVEJBJ6Jngjx8Y2FhER2SNK8KRf6yob+e5Ti/nXykrG5gQ5+8AxHDet\ngKOn5JOTkRrr8EREJBqCeX7drMnORUQSjRI82a3Wjk5+++oa7py3irTkJG49bzaXHzGR5CSLdWgi\nEgvtzdCwNbRs8YvrgoL9oHAGZBWB6f8fho2eLXgiIpJQlODJLt5cXcnNTy5mTUUjZx8wmu+ePYvi\nEemxDkskfjgHW5fCqpchOQ2yiyFr1I5195gl53xCVLUKqlaG1quhZh1MOBKO+1r8dH/r6oRtpaE4\nV4diXQW1G/x3aK3r//PpI32iVzjdrwumw+TjITkwNPFLZCnBExFJWErwZLvKhlZ++OwyHl9YxoS8\nDP742cM4YXpRrMMS2WHD2/CPW2HsITDpBJh4FKRmDs21nYPyD2HpU36pWtX3sWkjILMAGit3ToyS\n0yB/CmSPgvf+DAvvh7mfg2O/7JPDodZYBW/8DFa+7Ce17mzdsS8128daPBumnOxb6LKKQ0voNQ4q\nV0DFR1CxHCpWwPLn4L37IDkVvr156L+TREZGqItmk7poiogkGiV4QmVDK/f8aw1/fms97Z1dXHfi\nVK47aaqqYUp8aW+GJ//TJ02l78Kbv4SkAIw7zLcUTToexh7quwm2Nfrj25tCr5ugsx1yxsPI8ZAU\n5n/bzbU+cVn+rE/qateDJcOk4+DI/4IZZ/kYGsqhvtx3W+xeN2yBzELIn+YTpfypMHLcjmvXrIfX\nfgL/vhsW/BGOuAaOuXHHD+toam2At38Nb9wB7Y0+gZt2io8xf5pfh9vlcsQYmHzCztsaK/3fKlm3\nmIQVCEJKulrwREQSkO6++7AtdS389tU1PPDv9bR1dHH2AWP40snTmFqUFevQpC/OwbrXISMfimfF\nOprBc86v92TM1ms/9a1MVz4F4w6HDW/B2ldhzavwyu3wyo8AA1z/50lOhdwSyJsSSrymwIhxPiGr\nWQvVa30Xypq1O37cJgV8EvOxr8H0syAzf+dzZub7lq49kTsRzvsVHPsVH/8bd8C7f4Aj/9O3UDZV\n+wIX29dVPuEce4hv8evuQrcnOtp8MvnaT6CxAmacDSd9F4pm7Pm5+pNZ4BdJbJrsXEQkISnB2wdt\nqm3mrldX89C7G+nscpx/0FiuPXEKkwuV2EVUaz3M/wNMOw2KZu79+apWw3Nfg9X/9O+nneZ/6E84\nKnbFLTa8DWte8RMid7T5Ln49X7e3hFrQGv26rRHaGvx65Hi46m++VW0gW5bCGz+HAy/b0Vo09WS/\ngE+C1r8Bmz/wCVwgw4+DC2T6lojUDN/yVrsBqleHxpithjXzfLzdLBlyJvgEcPYnIHcS5E2GkmMG\nl1CFI38KXHAPHPcVn6S+9pOd9yel+IqGGXm+O+obd8CCP/lk87CrIRDG+NiuLlj8KPzzNt+yVnIc\nXPogjD8sOt9JhodgnhI8EZEEZM4N8LQ7zsydO9fNnz8/1mEkpLLaZn41bxWPzN+Ic3DhoeP4rxOm\nMiFfk9hG3Po34YkvhrqppcLx3/Dd7wZTcKKjFd74hW/BSk6Fk77jk6S374KmSt+adeyXYb8zIGmI\n5iKs2wQvfQ8WPeLfJwUgJc3Hl5IWeh1ap2X7xGT7kuWTrnd/75Opz/3dH9OXri649wyoXAnXzd+1\n9WxvdHVBXZlfsop90hnrboWVq6B1246kLm3Ezgl8+WJ4+fu+wMvICXDyd2HOhbv+27c3w9p/wcoX\nYMULsG0jjDoATvm+75KZIBUvzWyBc25urONIFBG9R957FuDgs89F5nwiIhIx/d0f1YK3D9gUSuwe\nnr8Rw7h47nj+84QpjMtVYhdxHa0w7we+lSV3Ilz2V/jwId9ysuxvcN6vYdSc8M+35lV49iu+oMfs\nT8LpP4QRo/2+I6+F9++HN++Ahy7zlQuPuQEmHu1b0DpaoLPNx9T9Om+yr3I46O/X5sduvfoT6OqA\nj30Djr1xcIVOSo6F+y+Cx6+BS/7S97i4BffCxnfg/N9ENrkDnxTljA+vFXGoFEztf/+oOXDFY7B6\nnk+yH7/aj0c87f/5sXMrXoCVL/r/djqafWvm5BPg1Fth1vlD9xBAEl8wx3eLFhGRhKIWvGFs87Zm\nfj1vNX99dyMOx8Vzx3PtiVMZkxOMdWjDU/lieOI/YMtiOOQqn4ylhbq9Ln0Knv2qH0N1/Dd8i1t/\nrXkNW+HFm+HDv/pugmf9FKaesvtjOztgyRO+C+OWxQPHWTwH5nwS5lzguyKGa9U/4Plv+jL608/0\n3y9vUvif35137obnvw5Hf8knKL3Vl8Odh8OYA+HKpxOm1WnIdHe9/MetvoWuW85E2O90v0w8Nrxu\nnHFKLXh7JqL3yKevhxUvwtc+isz5REQkYtSCt4/ZUtfCb15ZzQPvbKDLOS6aO55rT1SLHRUrfIvX\n+CP82K2UtMict6vTt6DM+wGk5/hWu+ln7HzMrPP8D+3nv+GPW/Y3OP/XvmJh1UrYuhwqlu1Y16zz\n48E+9g0/NivQT1KenAIHXAT7X+iLjmwr69VNMtWvk1OhbD4sfswnBP+4FcbO9Z+b/Qlfuh98K13L\nNl/ev6XWJ6Xz/wDLn/EtgJ96BPY7LTJ/uyOugcqPfCtk4XQ4+Iqd9z//Td/6ePbPldztTlISHHAx\nzDwXFv7Zd8vc73Q/+bj+XrK3uousOKf/nkREEogSvGHEOcejC0q55ekltHZ0ceGh47j2xKmMz9vH\nEzvwT6Ef+/yOOcnSRsLMs/tu4VcAACAASURBVH23x8FOxtxQ4cc3LfgTlP4bZp7jE5G+qgdm5sOF\nv4fZ58MzX4HfHg84cF1+vyX7Lnaj9of9L/aJV8G08OMx27VcfW/jDoUj/sOX6F/yhG/9+ftN8Pdv\n+bL4LXW+W19vgQw4+Xtw1HWRS4y7nfFjX/Dkbzf6FsWSY/32FS/A0ifhpJt9IRLpWyAdDr861lHI\ncBPMDRVLavaFikREJCEowRsmapva+PYTi3huUTmHT8rjfy48gIn5QzQBdDxzzhcoefkWP3bp4vt8\nMrH4cd+K9v79vpjFrHN9K0j+FF9sY3ctZs75LpAr/g4f/R3KFgAOssf48WEHXhbeU+6Z58DEY3yr\nVVKKr7BZONMndympkf4L7F7uRD927tgbfcvmksd9oZH0kT75Te9eRvh1wX7RK3ufnAIX/RF+fyr8\n9Qq4+p+QWeS7tBbOhKNviM51RaR/wdCcjM3VSvBERBKIErxh4I1VlXz14Q+obGjlm2fM4JqPTSY5\nSd1paG+Gp78Eix72xSXO/7UvBpI3GaadCu0/g9X/8Mneh4/4+cG6pY3wLVpZxX6y6kDQVySsK/X7\nxxwCJ37bd4cbdcCed1/KyINTbonQF91LhfvBCTfFNoZgDlz2EPzuZHjgEl8oZttG+NwLQ5f0isjO\nuqcGaa6BkeNiG4uIiIRNCV4Ca+3o5KcvfMQ9/1rL5MJMnrzqGOaMHRnrsOJD3SZ46FOwaaHv4nfc\n13ZNwgLpMOMsv7Q1+Ymz6zf7Ca8btu5YtizxY9HGHQ4nfNPPP9c9Xk0iJ38KXPxn+PP5ULkCDv0s\nTDgy1lGJ7Lt6JngiIpIwlOAlqBVb6rnhofdZtrmOK46cwHfOnEUwtY8y8/uaje/CXy/3k2lf+oBP\n4AaSmrFj0myJnUnH+e6u790XPy2cIvuqjFAXzabq2MYhIiJ7RAleAnrq/TK++diHZKam8Pur5nLy\nzOJYhzS01r0Or//cd8Hs6oCuduhs99Usu9p9BcoRY+DTT0LxrFhHK3vqgIv9IiKxpRY8EZGEpAQv\ngXR0dnH788v53etrObwkjzsvP5ii7ASd36qzHTb+209uvSfd8Na/CX+50P/wyC3x47OSMn0VzKQU\nv558oh9T1v30WURE9pwSPBGRhKQEL0FUN7Zx/YPv8caqKq46aiI3nz2LQHJSrMPaM7UbYNXLfsLs\nNa9CW73fftxX4cSb/Zxe/SmdD/dfBDnj4TPP+iIoIiISHYEgpAR9FU0REUkYSvASwJJN27jmvgVU\nNLTyPxcewEVzx8c6pIF1dkD1Gti6FDa+4xO7yhV+38jxsP8FMPUUv/1f/wtVq+ATv+17Qu/NH8Bf\nPulL9V/5lJI7EZGh0D3ZuYiIJAwleHGue7xdTjCVR/7jKA4cnxO9i20r82Pacifu2eeaa3xhk61L\nYOsyn9RVrPAT5AKkpPt53w79rE/qCqbtqGg542zInwYv3gzbSuHSByG715jCLUvhvvP91AVX/c2P\nrxMRkegL5kJzbayjEBGRPaAEL051dHbx478v555/+fF2v7r8EAqz06J70Yc+5VvKZp4NR38Jxh/e\n//EVK+Cdu+CDB6G9yW8bMdZP3D35RCiaFZrEe4afkmB3zODo6yBvEjz2BT8P2qf+CsWz/f7KVXDf\neZCc6lvuciZE7vuKiEj/MvJURVNEJMFENcEzszOAXwDJwO+cc7f32j8B+BOQEzrmJufcc9GMKRFs\na27n+gcX8tqKCq48aiLfHYrxdu0tsGUxjD7AT+i97G8w/gg4+nqYfqYvhgLgHKyZB2/9Gla9BMlp\ncMBFcOBlUDzHT1g9GDPOgs8+Dw9eCr8/HS6617f0/ekccF3wmWf8PGkiIjJ0gjn+QZuIiCSMqCV4\nZpYM/Ao4FSgF3jWzp51zS3scdjPwsHPuN2Y2C3gOKIlWTIlgdUUDV/9pPhtrmvjRJ/fnssOHqMWq\nYrnvnnnsl/1E3gvvh7fuhL9eAXmT4ahrISkAb/8GKpZBZhGc8G2Y+znIKoxMDGMOgqv/CQ9cAg9c\nDBkF0NnmC6oUTo/MNUREJHwagyciknCi2YJ3OLDKObcGwMweAs4DeiZ4DhgRej0S2BTFeOLeqysq\nuO6B9wgkJ3H/F47k8ElDWOa/fJFfjzoAUjPhiGvgsM/7lrw374Bnvxrav7+fiHrOBZAShS6jI8b4\nlrzHr4H1b8Cnn4BRcyJ/HRERGVgwz1fRdG7H2GkREYlr0UzwxgIbe7wvBY7odcwtwItmdj2QCZwS\nxXjilnOO37++lh8+t4z9irO558q5jM/LGNogyhdBIBNyJ+3YlpQMs8+HWef5KQpcp++2Ge2bfFoW\nXPYAdLRGJ4kUEZHwBHN9T4r2Jv/wT0RE4l6si6xcBvzROfe/ZnYU8Gczm+Oc6+p5kJldA1wDMGHC\n8Cqy0drRyc1PLOaRBaWcPruY/7v4IDLTYvDPsmWxL2yyu7nozGD8YUMfk5I7EZHY6jnZuRI8EZGE\nEM3KHWVAzwnbxoW29fR54GEA59xbQDpQ0PtEzrm7nXNznXNzCwsjNN4rDjS1dXD5Pe/wyIJSvnTy\nNH5z+aGxSe6c8y14o/Yf+muLiEj8yggNFVAlTRGRhBHNBO9dYJqZTTKzVOBS4Olex2wATgYws5n4\nBK8iijHFDeccNz22iPc21HDHZQfzlVP3IykpRuMbatdDa53GuomIyM56tuCJiEhCiFqC55zrAK4D\nXgCW4atlLjGzW83s3NBhXwWuNrMPgAeBzzjnXLRiiie/f30tT3+wia+dPp1zD4zxxN3li/161AGx\njUNEROKLEjwRkYQT1f6AoTntnuu17Xs9Xi8FjolmDPHordVV/Oj55Zw+u5j/PD4O5nYrXwSW5Ccm\nFxER6RYMddFsVhdNEZFEEeXZs6W3zduaue6B9yjJz+CnFx2IxUPZ6fJFkDcFUoe4cqeIiMS3YI5f\nqwVPRCRhKMEbQq0dnXzxL+/R2tHFbz89l+z0QKxD8raowIqIiOxGIAgpQSV4IiIJRAneELrl6aV8\nsLGWn150IFOLsqJ3oT0ZxthcC7UblOCJiMjuZeQpwRMRSSBK8IbIQ//ewIP/3sB/nTCFM+aMit6F\nmmvgl4fCKz8O7/gt3QVWlOCJiMhuBHOhSQmeiEiiUII3BN7fWMv3nlrCcdMK+Opp06N3IefgmS9D\n9WpY9Eh4nylXgiciIv0I5qoFT0QkgSjBi7Lqxjb+8y8LKBqRxh2XHkxyNOe6e/9+WPKEr4ZZtRKq\n1w78mfJFkFkIWcXRi0tERBKXEjwRkYSiBC+KnHN8/ZEPqGpo464rDiU3MzV6F6tcBc99A0qOg4v+\n5Letenngz5V/CMVzIB6qeYqISPwJ5mqaBBGRBKIEL4rufWMd/1i+lW+fOYM5Y0dG70IdbfDY5yE5\nAJ/4LRTuB7mTYOVL/X+usx0qlqt7poiI9K27BW9PCniJiEjMKMGLksVl2/jR88s4ZWYxVx1dMriT\n1G6A9paBj5t3G2x+H879JYwc67dNOxXWvtb/5ytXQGcbjDpgcPGJiMjwl5Hn7xXtTbGOREREwqAE\nLwoaWju4/sGF5Gem8T8XHjC4ycw3fwB3HAx3zoXFj/X95HTNK/DGL+DQz8Csc3dsn3YadDTD+tf7\nvkb5Ir8eNWfP4xMRkX1DMNevm9RNU0QkESjBi4LvPbmY9VWN/OLSgwY37q6zHZ66FoJ5kJ4Dj34O\n/nAGlC3Y+bjGKnjii1CwH5z+w533lRwLKemwsp9xeOWLIDkN8qfteYwiIrJv6E7wVGhFRCQhKMGL\nsMcWlPL4wjKuP2kaR0zOH9xJ3rzDJ19n/x/8x6u+62X1arjnJJ/Q1W3yLXpPXw9NVXDB7yA1c+dz\nBIK+4MqqfsbhlS+C4lmQnDK4OEVEZPgL5vm1EjwRkYSgBC+C1lQ08N2nFnP4pDyuP2nq4E5SscJP\nUj7rPJh5DiQlwyFXwvXvwbFf9t01f3koPPxp+OhZOOUWGH3g7s817VSoWgXVa3bd51wowVP3TBER\n6cf2Fjx10RQRSQRK8CKktaOT6x9cSGpKEr+49CBSkgfxp+3qgqev861vZ/50533pI3wyd927PnFb\n9jeYcjIc8Z99n2/qKX69u26adZv8zVoFVkREpD/qoikiklDUNy9Cbn9+OUs21XHPlXMZPTI4uJO8\new9sfAfOvwuyinZ/TG4JXHwfbF0GORMhqZ9EMn8K5E3x3TSPuGbnfVsW+7WmSBARkf4owRMRSShq\nwYuABetruPeNdXzm6BJOnVU8uJPUrIeX/9u3uh146cDHF82E1IyBj9s+XULzztvLP/Tr4tl7HquI\niOw7AukQyFAVTRGRBKEELwLu+MdK8jNT+cYZ0wd3AufgbzeAGZz9c7+OlKmnQkcLrHtj5+3li3xr\nYPqIyF1LREQixszSzezfZvaBmS0xs/+OWTDBXGiujdnlRUQkfErw9tL7G2t5dUUFXzhuMhmpg+zx\n+v79sGaeH2OXMz6S4UHJMZAS3LWaZvlidc8UEYlvrcBJzrkDgYOAM8zsyJhEEsxTF00RkQShBG8v\n3fnPleRkBPj0URMHd4L6cnjh2zDhaJj7+cgGB75gy6TjYOWLO7a11vvKmsVK8ERE4pXzGkJvA6HF\nxSSYYI6qaIqIJAgleHthyaZtvLxsK587ZhJZaYNsvXv2q9De4ue6669gyt6YeqpP6KpW+/dblgJO\nLXgiInHOzJLN7H1gK/CSc+6dmAQSzFULnohIglCCtxfu/OcqstNSuOroksGdoOIjWP4MfOzrUDDI\nefPCMe1Uv14Vmi5hyyK/VoInIhLXnHOdzrmDgHHA4Wa2y+SlZnaNmc03s/kVFRXRCSRDXTRFRBKF\nErxBWrGlnucXl/OZY0oYGQwM7iTd3SbDqZq5N/ImQf7UHdcrXwTpOTByXHSvKyIiEeGcqwXmAWfs\nZt/dzrm5zrm5hYWF0QkgmOuraLrY9BAVEZHwKcEbpDv/uYrM1GQ+d8ykwZ9k5YtQNCvyhVV2Z9pp\nsO51P11C+SLfehfJap0iIhJRZlZoZjmh10HgVGB5TIIJ5kJXO7Q1xuTyIiISPiV4g7CmooFnPtzE\nFUdNJDczdXAnaa2H9W/t6D4ZbVNP8dMlrHnVj8FT90wRkXg3GphnZh8C7+LH4D0Tk0iCeX6tbpoi\nInFvkJVBwmNmZwC/AJKB3znnbu+1/2fAiaG3GUCRcy4nmjFFwq/mrSY1JYmrj5s8+JOsedU/DZ12\nWuQC68/EY/xEte/cBR3NSvBEROKcc+5D4OBYxwH4FjzwlTSHoteJiIgMWtQSPDNLBn6F71JSCrxr\nZk8755Z2H+Oc+3KP468nXm5k/dhQ1cST75dx1VElFGSlDf5EK1+EtBEw/ojIBdefQDpM+his+Lt/\nX7zLOH0REZHd257gqQVPRCTeRbOL5uHAKufcGudcG/AQcF4/x18GPBjFeCLiN6+uIjnJ+I/j96L1\nzjlY+RJMPgGSB1mgZTCmnuLXSQEonDF01xURkcSWoS6aIiKJIpoJ3lhgY4/3paFtuzCzicAk4J9R\njGevldU28+iCUi6ZO57iEemDP9HWpVC/aei6Z3brHu9XOANSBjl2UERE9j3dLXhNmuxcRCTexUuR\nlUuBR51znbvbOSRz/IThrlf8ROFfPGHK3p2oe7qC7ha1oZJbAmPn+q6aIiIi4VIXTRGRhBHNIitl\nQM+R2ONC23bnUuDavk7knLsbuBtg7ty5MZmEZ2tdC3+dv5ELDhnH2Jzg3p1s5Uu+yMmI0ZEJbk98\n/kWweMnrRUQkIaSkQSBTCZ6ISAKI5i/9d4FpZjbJzFLxSdzTvQ8ysxlALvBWFGPZa/e/s4H2zi6+\nePxett4118KGt4e+e2a3pGTNfyciInsumKsET0QkAUQtwXPOdQDXAS8Ay4CHnXNLzOxWMzu3x6GX\nAg8552LSMheO9s4uHnp3Ax+bVkhJQebenWzNK+A6Y5fgiYiIDEYwV2PwREQSQFTnwXPOPQc812vb\n93q9vyWaMUTCP5ZtYUtdK7edP3HvT7byJUjP8WPhREREEkVmATRVxjoKEREZgAZjheEvb29gzMh0\nTppRtHcn6uqCVS/B1JMhOaq5tYiISGRlFUPDllhHISIiA1CCN4C1lY28vqqSSw+fQHLSXo5dK//Q\n3xynnhqZ4ERERIZKVhE0bPVzuYqISNxSgjeAB95ZT0qScelh4wc+eCCrXvLroZ4eQUREZG9lFUNH\nC7TWxToSERHpx4AJnpldb2a5QxFMvGlp7+SRBaWcNruYor2Z2LzbypdgzCGQVbj35xIRERlKWcV+\n3bA1tnGIiEi/wmnBKwbeNbOHzewMs32nxv6zH26mtqmdK46IQHGVpmoofVfVM0VEJDFlhcahaxye\niEhcGzDBc87dDEwDfg98BlhpZj80s72cEC7+/eWd9UwuzOSoKfl7f7LV/wTXBdM0/k5ERBLQ9hY8\nJXgiIvEsrDF4oTnqykNLB35i8kfN7CdRjC2mlmzaxsINtVx+xEQi0mi58iXIyIcxB+/9uURERIba\n9hY8ddEUEYlnA9bqN7MbgCuBSuB3wNedc+1mlgSsBL4R3RBj4/53NpAeSOLCQ8bt/cm2T49wCiQl\n7/35REREhlowF5ICasETEYlz4UzGlgd80jm3vudG51yXmZ0dnbBiq76lnScXlnHOAWMYmRHY+xNu\nWghNVRp/JyIiicssNBeeWvBEROJZOF00nwequ9+Y2QgzOwLAObcsWoHF0pMLy2hq6+TyIyNQXAVg\n5YtgSTDlpMicT0REJBayitSCJyIS58JJ8H4DNPR43xDaNiw55/jL2xuYM3YEB44bGZmTrnoJxs6F\njLzInE9ERCQWsoqV4ImIxLlwEjwLFVkBfNdMwuvamZDmr6/hoy31XBGp4iqNVVD2nrpniohI4ssq\nUhdNEZE4F06Ct8bMvmRmgdByA7Am2oHFyv1vryc7PYVzDxoTmRNWLAMcjDs0MucTERGJlaxiaKyA\nrs5YRyIiIn0IJ8H7InA0UAaUAkcA10QzqFipamjluUXlXHDIODJSI9RIWR3KhfOG/bSBIiIy3GUV\n+TldGytjHYmIiPRhwCzGObcVuHQIYom511dV0tbZxYWHRmBqhG7Va3xZ6ZERPKeIiEgs9JzsPLs4\ntrGIiMhuhTMPXjrweWA2kN693Tn3uSjGFRPrKpswg6lFWZE7afUayC3R/HciIvswM5sClDrnWs3s\nBOAA4D7nXG1sI9tD2xM8jcMTEYlX4XTR/DMwCjgdeBUYB9RHM6hY2VDdxKgR6aQHIpiMVa+BvMmR\nO5+IiCSix4BOM5sK3A2MBx6IbUiDkN2jBU9EROJSOAneVOfcd4FG59yfgLPw4/CGnQ3VjYzPy4jc\nCZ2D6rVK8EREpMs51wF8Avilc+7rwOgYx7TnMov8WgmeiEjcCifBaw+ta81sDjASKIpeSLGzobqJ\niZFM8BoroK1BCZ6IiLSb2WXAVcAzoW2BGMYzOKkZkDZCXTRFROJYOAne3WaWC9wMPA0sBX4c1ahi\noKW9ky11rUyIZIK3vYKmEjwRkX3cZ4GjgB8459aa2ST8EIjEk1WkFjwRkTjWb5EVM0sC6pxzNcBr\nwLDNVDZWNwEwIT8aCd6kyJ1TREQSjnNuKfAlgNBD02znXGI+LM0qVgueiEgc67cFzznXBXxjiGKJ\nqfVVoQQv0i14lgw5EyJ3ThERSThm9oqZjTCzPOA94B4z+79YxzUoasETEYlr4XTRfNnMvmZm480s\nr3uJemRDbEN1lBK8nAmQnHjDLEREJKJGOufqgE/ip0c4AjglxjENjlrwRETi2oDz4AGXhNbX9tjm\nGGbdNTdUN5GVlkJeZmrkTqopEkRExEsxs9HAxcB3Yh3MXskqgtZt0N4MgWCsoxERkV4GbMFzzk3a\nzRJW1mJmZ5jZR2a2ysxu6uOYi81sqZktMbOYzQm0obqJ8XkZmFlkTugcVCnBExERAG4FXgBWO+fe\nNbPJwMoYxzQ4muxcRCSuDdiCZ2ZX7m67c+6+AT6XDPwKOBUoBd41s6dDA827j5kGfAs4xjlXY2Yx\nm35hQ3UTUwuzInfC5hr/hFMJnojIPs859wjwSI/3a4ALYhfRXuiZ4OVOjG0sIiKyi3DG4B3WYzkO\nuAU4N4zPHQ6scs6tcc61AQ8B5/U65mrgV6EqnTjnYvI4sKvLsaG6aeAKmtvKwj+ppkgQEZEQMxtn\nZk+Y2dbQ8piZjYt1XIOSpcnORUTiWThdNK/vsVwNHAKE09Q1FtjY431paFtP+wH7mdkbZva2mZ0R\nbuCRtLW+lbaOrv4LrJQugJ/NgrIF4Z1UCZ6IiOxwL34u2TGh5W+hbYlnewueEjwRkXgUTgteb41A\npCZ2SwGmAScAl+HLRuf0PsjMrjGz+WY2v6KiIkKX3mF9VSMwQAXNqtBQifVvhXfS6jWAqfuKiIgA\nFDrn7nXOdYSWPwKFsQ6qN+ccLe2d/R+UUQCYxuCJiMSpARM8M/ubmT0dWp4BPgKeCOPcZcD4Hu/H\nhbb1VAo87Zxrd86tBVbgE76dOOfuds7Ndc7NLSyM/P2we4qEif110awv9+tN74V30uo1MHI8pKTt\nZXQiIjIMVJnZFWaWHFquAKpiHVRvp/7sNb79+KL+D0pOgcwCaCgfmqBERGSPhDNNwk97vO4A1jvn\nSsP43LvANDObhE/sLgU+1euYJ/Etd/eaWQG+y+aaMM4dURuqm0gyGJPTT7nn7ieVmxaGd9LqNZAX\nqYZOERFJcJ8Dfgn8DD/V0JvAZ2IZ0O4UZqWxNtSrpV+aC09EJG6F00VzA/COc+5V59wb+KeQJQN9\nyDnXAVyHLwu9DHjYObfEzG41s+4iLS+EzrcUmAd83Tk35E80N1Q3MSYnSCC5nz9H91iD6jW+QuZA\nNAeeiIiEOOfWO+fOdc4VOueKnHPnE4dVNCcVZrKuMpwEr0hj8ERE4lQ4Cd4jQFeP9530KPXcH+fc\nc865/ZxzU5xzPwht+55z7unQa+ec+4pzbpZzbn/n3EN7+gUiYX1VU//dM8HfyJIC/vWm9/s/trkW\nmqqU4ImISH++EusAepuUn0lNUzu1TW39H6gWPBGRuBVOgpcSmuYAgNDr1OiFNPQ2Vjf1X2AFfII3\n8Wj/eqBumjVr/VoJnoiI9M1iHUBvJQWZAKwdqBWvuwXPuSGISkRE9kQ4CV5Fjy6VmNl5QGX0Qhpa\nDa0dVDW2MSEvc4ADt0DhdJ+0DZTgaYoEEREZWNxlR5MK/MPOdQONw8sqhs42aKkdgqhERGRPhFNk\n5YvA/WZ2Z+h9KXBl9EIaWhuqfAXNflvw2puhZZt/YjnmYNj47/5P2p3g5ZZEJkgREUlIZlbP7hM5\nA/qp7BUb4/MySDJYW9nU/4Hb58LbCsHc6AcmIiJhGzDBc86tBo40s6zQ+4aoRzWENlT7p5T9jsHr\nHmeQNQpS0mHxY9BQAVl9TNlQvRayx0DqAN0+RURkWHPOZcc6hj2RlpLMmJzgwIVWsor8urt3i4iI\nxI1w5sH7oZnlOOcanHMNZpZrZrcNRXBDoXsOvPH9teB1VwrLKoYxh/jXm/sptKIKmiIikqAmFWSG\nMQZvlF+r0IqISNwJZwzex51z2zvZO+dqgDOjF9LQ2lDdRE5GgJHBQN8HbU/wimD0AYBBWT8TnmsO\nPBERSVCTCvxUCa6/Aio9W/BERCSuhJPgJZtZWvcbMwsCaf0cn1DWV4VZQRMgexSkZUPBfn0XWmlt\n8MerBU9ERBJQSX4m9aECZH1KHwnJaUrwRETiUDgJ3v3AP8zs82b2BeAl4E/RDWvobKxu6r97JkD9\nFsAgo8C/H3tI3wmepkgQEZEENik0VUK/4/DMNBeeiEicGjDBc879GLgNmAlMB14AJkY5riHR0dlF\naU0zE8NpwcsshORQTZoxB0NDOdRt2vVYTZEgIiIRYGbjzWyemS01syVmdsNQXHeP58ITEZG4Ek4L\nHsAWfJnni4CTgGVRi2gIbd7WQkeXC6+LZndJaPAJHuy+FW97gqcxeCIislc6gK8652YBRwLXmtms\naF90XG6Q5CQLby48teCJiMSdPhM8M9vPzL5vZsuBXwIbAHPOneicu7OvzyWS7gqaE/qbIgFCCV7R\njvej9gdL7jvByyzyY/VEREQGyTm32Tn3Xuh1Pf7h6thoXzeQnMSEvIzIteBteBuWPh2Z4EREZED9\nzYO3HPgXcLZzbhWAmX15SKIaItsTvAFb8LZCUY+HpoGgf7+7SprVa9U9U0REIsrMSoCDgXeG4nol\n+RnhTXbeWAmdHTuGMOzOS9+H6tUw69zIBikiIrvVXxfNTwKbgXlmdo+ZnQzY0IQ1NNZXNRFINkaP\nDPZ9UFfXri14AGMO8i14vctIaw48ERGJIDPLAh4DbnTO1e1m/zVmNt/M5ldUVETkmiUFmayvCmeq\nBAdNlX0f094Cm96DxgqfDIqISNT1meA55550zl0KzADmATcCRWb2GzM7bagCjKaN1U2My80gOamf\nvLW5Bro6dkzq2m3sIdBcDbUbdmxrb4a6MiV4IiISEWYWwCd39zvnHt/dMc65u51zc51zcwsLCyNy\n3UkFmTS1dbK1vrXvg7rHpteX933MpoXQGZpuYeuwGL4vIhL3wqmi2eice8A5dw4wDlgIfDPqkQ2B\n9dWN4c+Bt0sLXnehlR7dNGvW+bUKrIiIyF4yMwN+Dyxzzv3fUF67JD+MSprdCV5/hVY2vLnjtRI8\nEZEhEW4VTQCcczWhJ4UnRyugobQhrEnOQ08me1bRBD8GLzl150IrmiJBREQi5xjg08BJZvZ+aDlz\nKC4c1lx43Q8++yu0suFtKJgO6TlQoQRPRGQo9FdkZVirbWqjrqUjvAIrANm9umimpEHx7D4SPLXg\niYjI3nHOvU6Mxr6PyQmSmpw0QAveAAleVydseAfmfAIqVqgFT0RkiOxRC95wEvYUCd1jC3p30QQY\ncwhset8XYvn/7d152YEnJgAAIABJREFUnFxVnffxz6nqfU9v2bo7naSzEkIIIewQUCRsMqIj4AZu\nKIKDoyPi+IzOOI+POuPCOKIIqKCjRHQEAVkSkVVCQgIEyL7vvaf3tarO88epSneSql6Sqq5K1ff9\netXrVt17+9Sp011961e/s4AL8LKLIXtcFGsqIiIytrweQ1XJMEslpGdDZmHkLpr1G6G3FarOgfI5\nUL/h2InJREQk6hTgjSSDl54bfl27SadDb9tA5k4zaIqISJKoLskdwWLnQ6yFt2el24YCvJ5WaD8Y\n3UqKiMgxUjbA29000gAvzBIJIYcnWgl201SAJyIiSWJqaQ67m7oIBIZaKmF85AzenpWQPwmKqlyA\nBy6LJyIiMZWyAd7e5i5K8zLIzRxmGGJH3bETrISUzYa0bDeTpq8XWvcpwBMRkaRQXZpLry/Awbae\nyCdFyuBZC7tXwpRzwBgoCwV4GocnIhJrKRvg7R7JDJrgLlz5EQI8bxpMnO8yeC17wAYU4ImISFKY\nGloqoWGYpRLCZfBa9kD7Adc9EyC3xJ1bvykGNRURkcFSNsDb0zzCAK99iAweuG6aB9dB41b3WAGe\niIgkgallwQBvqHF4eeXQ1w59R52z51W3rTp7YF9oohUREYmplAzw+nwBDrZ2UxX8djKi/m43A9iQ\nAd5C6O+CLU+5xwrwREQkCYzPzyIr3TPMWngRFjvf84qbYbN87sC+8rnQsGlg5mkREYmJmAZ4xpil\nxpjNxphtxpg7wxy/yRjTMGgB10/Fsj4h+1u6CdgRzqAJw2fwADY85i5mOcXRqaSIiEgceTzGzaR5\nXAHeq1C5GDzegX3lc9wXoi27o19ZERE5LGYBnjHGC9wNXA7MBW4wxswNc+rvrLULgrf7Y1WfwXYH\nu5uMaAZNGDrAK6mBjHzoaXELnJu4rEkrIiISddUluUN30QyNUR880UpXs8vUTTnnyHND2TxNtCIi\nElOxzOAtBrZZa3dYa/uAZcA1MXy+EdsbXANvynCLnIcuWJEmWQHweGDSAndf3TNFRCSJVJfmsre5\nC58/QrfKvDAB3uHxd0cFeGWz3Fbj8EREYiqWAd5kYO+gx/uC+472fmPMW8aYPxhjKmNYn8N2N3WR\nmeahLC9z6BPba912qAweKMATEZGkNK00l36/ZX9Ld/gTckrAeI7sorlnJXgz3Bj1wTLzobBKGTwR\nkRiL9yQrjwPV1tr5wArgwXAnGWNuNsasMcasaWhoOOEnDc2g6fEM052yo95duHLLhj4vNA5PAZ6I\niCSR6tLgTJqRxuF5vO4aeUQGb6UL7tKzjj2/fI7rvikiIjETywBvPzA4I1cR3HeYtbbJWtsbfHg/\ncEa4gqy191prF1lrF5WVDRNsjcCIl0joqIOc0iMHiYcz7WKYdQVMW3LCdRMREUkU1aXuWjn0RCvl\nAxm8vi448OaRyyMMVj4HGreAvz/KNRURkZBYBnivATOMMVONMRnA9cBjg08wxkwc9PC9QMz7bVhr\nXYA33Pg7cAHecN0zwc2cecNDUBiuB6qIiMjJqSwvk9wML7uauiKflDd+IIO3fy0E+mHKueHPLZ8L\n/j5o3hH9yoqICBDDAM9a6wNuA57BBW4PW2vXG2O+aYx5b/C0fzDGrDfGrAP+AbgpVvUJaerso6vP\nP/IM3lATrIiIiCQxYwzVpbmRu2jCkQHenlcB45ZICKd8jttqohURkZhJi2Xh1tongSeP2vf1Qfe/\nCnw1lnU42u6mEc6gCa7LSXm4lR1ERERSQ3VpLu/sb418QqiLZiDgxt+Vz4XsceHPLZ3pxrbXb4RT\n3hebCouIpLh4T7Iy5kJLJAybwQsERt5FU0REJElNCy6V0OcbYqmEQD90NcHe1ZHH34GbeKV4mjJ4\nIiIxlHIB3vSyPD5z4TQqxg0T4HUfgoBPAZ6IiKS06pJcAhb2HoowDi+v3G23/xX62o9d/+5o5XOg\nXjNpiojESky7aCaiUysKObWicPgTO0Jr4JXHtkIiIiIJLLRUwq7GTqaX5R17QuiL0A2Puu2U4QK8\nubDpz9DfE34pBREROSEpl8EbsdCA8fwJ8a2HiIhIHE0dbi28UIC37VkorITCiqELLJ8DNuCWSxAR\nkahTgBdJaE0fddEUEZEUNi4nnYKsNHY1RQrwgj1d/L3Dd8+EgcnL6mO+MpKISEpSgBdJe6iLpgI8\nERFJXcYYppbmsqsxwhi8zAJIC3a1HGqClZDiaeDN0EQrIiIxogAvko56SM+FzDDjDURERFLI1KHW\nwjNmIIsXaYHzwbzpbrkEZfBERGJCAV4kHbWaYEVERAQ30cqB1m56+v3hT8gbD1lFUDprZAWWzVaA\nJyISIwrwIumo1wQrIiIiuAyetbCnOUI3zdOuh/O/AJ4RfqwonwOte6C3PXqVFBERQAFeZB11yuCJ\niIjg1sKDIWbSPPNTcP4/jrzA0EQrDZtPsGYiInI0BXiRtNdBnjJ4IiIig9fCi4ryOW6riVZERKJO\nAV44/d3Q26oMnoiICFCYnU5xbkbkDN5oFU2B9ByNwxMRiQEFeOFoDTwREZEjzJ6Qz4tbGiJPtDIa\nHk9wohVl8EREok0BXjgddW6rSVZEREQA+PwlMzjQ2sN9L+6IToHlc5XBExGJAQV44YQCPHXRFBER\nAeCc6SVcPm8CP3l+O7WtPSdeYPlsd73taj7xskRE5DAFeOG017qtJlkRERE57J+vmIPfWr779KYT\nL+zwRCvK4omIRJMCvHA66sF4ILc03jURERFJGJXFOXz6gqk88sZ+Xt9z6MQKCy2VoHF4IiJRpQAv\nnI46yCkFjzfeNREREUkon1tSQ3l+Jv/2+AYCAXv8BeVPhKxCZfBERKJMAV44HXWQrxk0RUREjpab\nmcZXls5m3d4WHn1z//EXZIwmWhERiQEFeOF01GmJBBERkQjed/pkTqss4jtPbaKz13f8BU06Hfav\nhZY90auciEiKU4AXTnudJlgRERGJwOMxfOPqudS39/LT57cff0Hn3OrGvK/4evQqJyKS4hTgHS0Q\ngM56LZEgIiIyhIVV43jf6ZO596Ud7G3uOr5CCivg/C/A+kdg19+iW0ERkRSlAO9o3Ycg4FMXTRER\nkWF8ZelsvMbw7adOYBzduf8ABRXw9J0Q8EevciIiKUoB3tE6gmvgaZIVERGRIU0ozOJzS6bz5Nu1\nvLqj6fgKyciBS/8Nat+CN38T3QqORm87rL4P/CcwplBEJAHENMAzxiw1xmw2xmwzxtw5xHnvN8ZY\nY8yiWNZnRDrq3FYZPBERkWF9+sJpTC7K5qt/fJuWrr7jK2Te+6HyLHj2m9DTFt0KjtTKu+HJf4Kt\nz8Tn+UVEoiRmAZ4xxgvcDVwOzAVuMMbMDXNePnA7sCpWdRmVdgV4IiIiI5WV7uWu6xew/1A3n/n1\nWvp8gdEXYgws/TZ0NsBL34t+JYfj64PXfu7ub3py7J9fRCSKYpnBWwxss9busNb2AcuAa8Kc9+/A\nd4GeGNZl5JTBExERGZUzq4v5z7+fz6qdzdz5x7ew9jgWQJ98Bpz2IXj1p9C8I/qVHMqGR90Ea0VT\nYMtTGgsoIie1WAZ4k4G9gx7vC+47zBizEKi01v45hvUYnY56SM+FzLx410REROSkcc2CyXzx0pn8\n8fX9/Pdftx1fIe/6OnjSYfm/RLdyw1l1D5TUwLv/FbqaYG9idCoSETkecZtkxRjjAX4AfGkE595s\njFljjFnT0NAQ24p11GqCFRERkePw+UtquHbhZH6wYguPvrF/9AUUTIQLvgibnoAdL0S/guHsW+MW\nW1/8GZhxKXgzYFPifO8sIjJasQzw9gOVgx5XBPeF5APzgOeNMbuAs4HHwk20Yq2911q7yFq7qKys\nLIZVxmXw1D1TRERk1IwxfOfa+Zw9rZg7/vAWq3c2j76Qc26Doip4+qtjM6PlqnsgswAW3ACZ+TD1\nIhfgHU83UxGRBBDLAO81YIYxZqoxJgO4HngsdNBa22qtLbXWVltrq4FXgfdaa9fEsE7D66hTgCci\nInKcMtI8/Owji6gozubmX69hR0PH6ApIz4JL/x3q18PrD8amkiFtB90i66d/xAV3ALOvgEM7of4E\n1vYTEYmjmAV41lofcBvwDLAReNhau94Y801jzHtj9bwnrF0BnoiIyIkozEnngZsW4zWGTzzwGs2d\no1w+Ye41MOU8+Mu/wo7nY1FFZ+0v3YQqZ35qYN+sK9x2s7ppisjJKaZj8Ky1T1prZ1prp1trvxXc\n93Vr7WNhzl0S9+xdfzf0tkJeeVyrISIicrKrKsnh3o8t4kBrDzf9cjW1raOYLNsYeN/PoGAy/M/7\nYc0vR/6zB96Av/0I/P1Dn+frhTW/gJmXQcn0gf35E2DyIi2XICInrbhNspKQQksk5E+Ibz1ERCTl\nGWN+YYypN8a8E++6HK8zpozjpx9eyLb6Dq7675dYtaNp5D9cVAmfXA7TLoYnvgBP//PQyxf0tsNT\nX4H7LoEV/wKP3jL0+esfcevunfWZY4/NvgIOvA5tB0ZeXxGRBKEAb7COerdVF00REYm/B4Cl8a7E\niXrXnPH86dbzKMhK50P3r+LnL+8c+Tp5WQVwwzI467Pw6t3w0A0ukDvaxifgx4th1c9g0SdgyVfh\n7d/DE/8YfrIUa916e6WzXAB5tNlXue1mZfFE5OSjAG+w9oNuqwBPRETizFr7InAc01Amnhnj83n0\ntvO4ZHY5//7EBm5f9iZdfSOcIdObBpd/F674Hmz7C/z8MmjZ44617oOHPgS/+zDkFMOn/gJXfh+W\n3AkXfMlN0rL8/xwb5O1dDQffhLNudt1Bj1Y6E4qna7kEETkppcW7AgmlKbgwa/HU+NZDRERkhIwx\nNwM3A1RVVcW5NpEVZKXzs4+cwU9f2M73lm9mS10793zkDKpLc0dWwOJPu7FyD9/kumEu/Bi8eg/Y\nAFz6TTj7c+BNHzj/kn9x2b6VP3YzZC65c+DYqnsgsxBOuyH8cxkDs690Wb6eVsgqPO7XLSIy1pTB\nG6xxG+RPHJgqWUREJMGN6VqxJ8jjMdx6cQ0PfHwxtW09XP3jl/nLhrqRFzD9EvjUCsjIhZe+D1PO\nhVtXwXm3HxncgQvSln4XFnwYnv82vPJjt791P2z4Eyz8qCsnktlXQqAftq4Y/QsVEYkjZfAGa9wC\npTPiXQsREZGkdtHMMh6/7Xw++z9r+dSv1nDdokq+dtUcCrLSh//hsllw8/NQt8EFeOG6WIZ4PHD1\nj6CvA5Z/DTLzoGWvy/ot/vTQz1NxJuSUunF4p35gNC9PRCSulMELsRaatkKJAjwREZFYqyzO4X9v\nOZdblkzn92v3ctkPX+T5zfUj++HscVB93tDBXYg3Da69H2reDY9/wXW7nHUFjKse+uc8Xph1ucvg\n+Ua5jp+ISBwpwAvpbHT97EtnxrsmIiIiGGMeAlYCs4wx+4wxn4x3naItK93LV5bO5o+fO4/czDRu\n+uVr3PGHdbT1DLOG3WilZcAHf+0yfv2d4ZdGCGf2ldDbBrteim59RERiSAFeSOMWty2tiW89RERE\nAGvtDdbaidbadGtthbX25/GuU6wsqCziic+fzy1LpvOHtfu47Icv8txIs3kjlZEDH/493PQkTLto\nZD8zbQmk5yTebJr93eGXf5Dkd2hX+KVCRAZRgBfStNVt1UVTRERkzB2dzfv4L1/ji797k73NXdF7\nkoxc17VzpNKz3cQum59KnIBq05PwvZmw7EPg6413bWQsHVwHd58FD1wJ/T3xro0kMAV4IY1bIS0L\nCivjXRMREZGUFcrmfW7JdJ546yBLvvc8//T7dexs7IxPhWZfCe0H4MAb8Xn+kEAAnv8OLLsBckrc\n5C8Pf0xBXqrobIRlH3YZ5YPr4Ok7h/8ZcRo2w3PfhnXL3Of9QCDeNYo5zaIZ0rgVSmrcjFsiIiIS\nN1npXu5YOpuPnVPNz17czm9X7eGPr+/jvadN4rZLaqgpH8PljGYuBeNx3TQnLzz2uN8HLbsh4HPn\nGY+b/MV4AOOWb8ibcGKfL3ra4JHPwuY/u7X7rvohvPlb+PMXXZD3wV9BWubxly+Jze+D398EHfXw\niadhw6Pwt/+CqrPhtOvjXbvE1bwDXvgPeOt3bubckKxCmLQQJp/hbhWLIK88fvWMAQV4IY1bYNKC\neNdCREREgiYUZvGNq0/hliXTuf+lnfx65W7+tO4AV5w6kdsurmHOxILYVyKnGKrOdRmzJXdC/UaX\nQTn4ptvWvgO+7qHLyMiDCfPd54yJC2DiaW5ZJo93+Odv3Oa6YzZtg6XfgbM+6wLIMz/ptk/8I/zu\no3Ddr4cP8ny94Ekb2fOK09HgAipPmvtbyB4H2cUD99OzY1+HFf/iJvr5u3vclwwT5sO+tW5W2Amn\nwvhTYl+Hk0nLXnjxP+HN37jf2zm3wrn/4LKg+9cO3F7+IVi/+5m518DFX3PLsCQBYxOlT/kILVq0\nyK5Zsya6hfp64VsT4IJ/gku+Ft2yRUTkuBlj1lprF8W7HieLmFwjE0hTRy8/f3knv1q5m45eH+dO\nL+HGc6t595zxeD0jWDLheK38CTzzVfBmgj/YJTIjHybOd8Ha+HmQnuXG6dnAkTdf70BQWPv2QDCY\nnuM+nIc+oI+fB+VzIHNQdnLLcvjfT7mA7IMPwtQLj63bml+4IG/GZZGDvIbNsOoe10UtbzxcfZeb\nQCYamndC9yEXuCZTL6iWPfDKf8PrvwLfEOPdMvJg3vvhvNuhZHr067FuGTzyGTjrFrj8OwP72+vg\nZxe4v5dPPwdZY/BlR6Jrr4WXfgBrf+nei4s+Dhd8CfInhD+/rwtq34Kty2HVz6C/C+ZfBxd9BYqn\njm3dj8NQ10cFeAD1m+AnZ7l1cub/fXTLFhGR46YAb3SSPcALaenq47er9/A/K3dzoLWHyUXZfPSc\nKVx/ZiVFORnRf8LORnjyy1A4OZiBWwDF00Yf0Ph9rsdQKPt34E2oWw99g2ZFHFftgr3sInjjNzBh\nHlz3Gxg3JXK54YK8QAC2rXCB3fa/uuD0lPfBvtWu69r86+Gyb0Fu6ejbIxCA7c+6D8XbVrh9+RNh\n9lUw52qYcp5bf/Bk1LAZXr4L3n7YPT7tejjn8y6A6mqG7uYjt8074O0/QKAfTrkWLvhi9DJq+1+H\nXyyFysXw0Udcd9/Bdr0MD74X5lwFf//gyNaFjIbWfbDjBdj5ggukzrl17HvBWetmFD3wuhsfu/8N\n2L8G/P1w+ofhwi9DUdXIy+tsdBm91+533a0XfsyVUTAp+nX3+1zm8AS7VSvAG86Gx+Dhj8LNz8Ok\n06NbtoiIHDcFeKOTKgFeiM8f4C8b63jglV28uqOZzDQP7zt9MjeeWz023TejwVqXLapbH7y947bN\nO+DUD8BVd7klHoaz5pfwxBdgxnvcou6rfgbN213gdeYn4YyPu2Cuvxte/B787S7ILHBB3mk3jCw4\n6Gl1Y/9W3+fKzi2HRZ9w2Y5NT8DWv7gMZfY4t5j8nKth2sUuuzlSfZ3w1B0uaMopcRnH/ImQH9zm\njYey2VB11sjLHI61LlB4+Yew8Qk36d4ZN8G5t0FhxfA/314Hr94Nr/0c+jpg5uUuc1R5Zvjn6m13\nWc/8CZE/5Hc0wL0XubGcNz8fORB/+S74yzdc992zbxnhCx6lrmbY+aIL6Ha84H73ADmlLqDqbXVj\nVS+8AyrOiE0drIV9a2DrM6575YE3XBsCeDNcJrxiMSz+9IllUtsOuu6drz/ouncu+qTLnBdVQVHl\nkRn20fL74O3fu/IXfRzO/fzxl4UCvOG99H149pvw1X0n9osTEZGoUoA3OqkW4A22qbaNB1/ZzSNv\n7KOnP8AZU8bxkbOruHzeRLLST8IxZwH/6MfKhYI8gIoz3Xi9udccm/kB12308dth7yr3Afaqu478\nYBzwQ1eTm9ijo86NQVy3zAUwFWfC4s+4stMGZUz7ulxmb+PjsPlp98E/txwu+38uWB0uiKzfBL+/\n0WXRTrvB7euodV3v2mtd1ixk0Sdh6bePLwsSCEDDJtj9N9j9irt11LrJNxbf7NrteDKb3Ydc8Pvq\nT9z9Kee5IK6z0QVJXY2uTf197vy0LDfJR9XZUHWOa9fsIhc0/eoaF8h84pmhs2PWutk1tz7j1ng8\nOvD1+9xSYHXrXSBUuThyl8XB7VO7znUR3vJ0cAZZ67qjTjnPrSM59SIon+uyz6vvhZV3u9dc824X\n6IULwK11v8embdDbBqWz3JcDkf7OQ0Hd+kdgw5+gbR8Yr3veSQvceMRJC93jtChn7g/tgue/C28t\nO3KCluxxwWCvCoqmuN/btCWQmRe5LH+/m+jlxe/BoZ0uGH3XN2DGpSdURQV4w3nks+4biS9tjG65\nIiJyQhTgjU4qB3ghLV19/GHtPn6zag87GzsZl5POBxdV8qGzqphSkhvv6sXejhfcB/GRZFICATde\n6S//6sYKVp0FnU3QWe8CkcEfbL0ZMO8DLkMSbjbRo/n6XNbnuW+57NjUi+DKH0BpTfjz33zIzQqa\nkQvX3gfTLw5TZq8LNlffB6/8yH24/+CDI+uK19nkPqzv+hvseWUg+5M/ya2NOOU8N5YuGmPZejtc\nBui1nwPWZbpySiC3xG1zSl0w2bgF9qx03XUDPsC47p1ZhS74vPY+mP/B4Z+vuwXuXeLa5+/udhPz\n1L3txnzWbzx2DGFRlct2VQZv4+e5n93xvAsUtyx3AS/GzTBZc6kLYiYvDP9lAbis5Gv3wys/doHs\n1Itg3rXQut8FdE3boGk79B+13ElatpvYZPwpbgxq+Vw3cc3GJwaCOm8GTH8XnPJ3MOty1z5jpbPJ\nZdNb97hMe8seN4lL6L6v23V/nnqBy2LOXOoyfeACu3UPuUTSoV1uvO5Fd7rXEIXutArwhnPfu1z3\nhxsfj265IiJyQhTgjY4CvAGBgOWV7U38ZtVulm+owx+wXDizjA8trmLJrLKTM6sXK+21Lshr2uYy\nbnllbptbNnC/fI6bOXK0Av5gEPlN92H4gi/BeV8Y6LbZ1wVPfRne+B+Ycj68/34omDh8uRsfh0c/\n57I/77/fZY7C6Wp2weCqe11wUTwNppzrArop57oszFiNXYukr9Nl6/a86gK+fWtc19dL/23kZRx8\nC+5/98AkQNnFA5P4TDg1GMT1uIzt3tXu1n7AnZuW7caE+ftct93pl7hAZcalo89k9nW6TPLf/st9\nUWC8LqAsqQneprtbZoHLotZtgPr1bttZP1BOPIO6kfL3u9/X5qdhy1MuEATX1tXnu6x3yx43/Oui\nO2HmZVH9W1OANxRr4TtT3OQqV34/euWKiMgJU4A3Ogrwwqtr62HZ6r08tHoPtW095GR4uWhmGe85\nZTyXzBpPYU6ErIRET3sdLP+aG4NUPN195iqYBA/f6D7oX/hlN3vhaCZnadruloio3+CWsLjwjoGJ\nb7qaYeWP3VjEvk6XTbrwDiifHZvXlwj2r3XdQSec6sYrDhdMtO4LBnyvuUB5xntcl8NodHfs74G2\n/VBYOfLyOhvd77K7xXUDTcSgbiiNW12X1s1Pu8Bv0unu77Lm3TH5EkEB3lA66uF7M2Dpd+Hsz0av\nXBEROWEK8EZHAd7QfP4Af9vexIoNtSxfX0d9ey9pHsNZ04p5z9wJvHvueCYXjcG6Zqls+1/hz19y\n2Q5vhsvkXHsv1Lzr+Mrr63JdO9c95D5IX/4f7v6r97jxYae8zwWO5XOi+zpEhuLvd5O0xDA7rABv\nKLtehgeuhI/8b+T0voiIxIUCvNFRgDdygYDlrf2tLF9fy/INdWyr7wCgpjyP82tKuWBGKWdPKyE3\n8ySd7j+R9fe4WTzrN7gv2EfSJXMo1sLaB9zsm6EJTOZe47rFjZ97wtUVSURDXR/1X6txq9uWzoxv\nPURERGTMeDyGBZVFLKgs4o6ls9ne0MGzG+t4aWsjD63ewwOv7CLdazi9ahwX1JRywcwy5k8uxBPL\nBdVTRXqW67oWLca4aecnnuaydwtvdOsHiqQoBXhN29zg0oIRrHMiIiIiSWl6WR7Ty/K4+cLp9PT7\nWbv7EC9ubeDlrY18f8UWvr9iC5MKs7jqtElcPX8S8yYXYOI9OYccafLCkc3wKZLkYhrgGWOWAv8F\neIH7rbXfOer4Z4FbAT/QAdxsrd0Qyzodo3GLm9UnNChXREREUlpWupfzako5r6YULoemjl5e2NLA\nE28d5Bcv7+TeF3cwpSSHq+dP4urTJjFrgtbQFZHEEbMAzxjjBe4GLgX2Aa8ZYx47KoD7rbX2nuD5\n7wV+ACyNVZ3Catw69AKSIiIiktJK8jK5dmEF1y6soKWrj2fW1/L4uoP85Plt/Pi5bdSU57Foyjjm\nTipgzsQCZk/IJz9LM3OKSHzEMoO3GNhmrd0BYIxZBlwDHA7wrLVtg87PBcZ2xhdfL7TshlP/fkyf\nVkRERE5ORTkZXHdmFdedWUVDey9Pv3OQ5RvqeGZ9Lcte23v4vKriHOZOLGDupALOmDKO06uKyMnQ\nyBgRib1Y/qeZDOwd9HgfcNbRJxljbgW+CGQAl8SwPsdq3gE2oAlWREREZNTK8jP56DnVfPScaqy1\n1Lb1sPFgGxsPtrPhQBsbD7bxzIZarIU0j2F+RSFnTSth8dRiFk0ZpyyfiMRE3L9KstbeDdxtjPkQ\n8H+AG48+xxhzM3AzQFVVVfSevHGL25bWRK9MERERSTnGGCYWZjOxMJtLZo8/vL+9p5+1uw+xamcz\nq3Y0cd+LO/jp89vxGJg3uZCFVS67t7BqHBXjsjVxi4icsFgGePuBykGPK4L7IlkG/DTcAWvtvcC9\n4Nb4iVYFDy+RUDIjakWKiIiIhORnpbNkVjlLZpUD0NXn4409Laza0cSqnc387rW9PPDKLgBK8zI5\nvarI3SrHcWpFIXlah09ERimW/zVeA2YYY6biArvrgQ8NPsEYM8NaG4yyuBLYylhq2gb5kyAzb0yf\nVkRERFJTTkbKVhyXAAAQIklEQVTawAydgM8fYHNdO2/saXG3vYdYsaEOcMu7zSjPY35FEadVFrGg\noohZE/LJSNPM3yISWcwCPGutzxhzG/AMbpmEX1hr1xtjvgmssdY+BtxmjHk30A8cIkz3zJhq3AKl\nyt6JiIhIfKR5PZwyqZBTJhXykbOnANDS1ccbe1t4a28r6/a18Nymev6wdh8AGWke5k4sYOb4PKpL\nc5lakkt1aS7VJblkZ3jj+VJEJEHENO9vrX0SePKofV8fdP/2WD7/kKyFxm0wXzNoioiISOIoysng\n4lnlXBzs1mmtZX9LN+uCAd+6vS38dVMDjR37jvi5CQVZVJfmMGt8PqdWFDG/opDpZXl4PRrXJ5JK\nUrdjd0c99LZq/J2IiIgkNGMMFeNyqBiXw5XzJx7e397Tz+6mLnY2drKrsZOdTZ3sbOzk92v38eDK\n3QBkp3s5ZVIB8yYXMr+ikBnl+VQWZ1OYna4JXUSSVOoGeE3B4X7qoikiIiInofysdOZNLmTe5MIj\n9vsDlp2NHby1r5W39rXyzv7WIyZzAcjPTKOiOIfKcdlUFudQMS6b6pJcppflMXlctrJ+Iiex1A3w\nDi+RoABPREREkofXY6gpz6emPJ9rF1YALujb3tDBjoZO9h3qYm9zF3sPdbOrqZOXtjbS3e8//PMZ\naR6mluQyrczdppfluVt5nmb1FDkJpO67tHEbpGVDQUW8ayIiIiISU16PYeb4fGaOzz/mmLWWps4+\ndjV2sqOhk+0NHWxv6GRzbTvLN9ThDwysUDWpMIvp5XnUlOcxozyfmvI8ppTkMC4nQ7N7iiSI1A3w\nmrZCSQ149M9IREREUpcxhtK8TErzMllUXXzEsT5fgD3NXWxv6GBb/cBt2eq9R2T9APKz0ijNy6Q4\nN4Pi3AxKcjMozcukvCCT8vwsygsyGV+QRVlepoJBkRhK3QCvcQtMOj3etRARERFJWBlpHmqCGbvL\nThnYHwhYDrR2s7W+g/2Humnu7KO5s4/Gjl6aO/vY29zFG3taaO7sZVAC8LDi3AwmFmZRXZrLtNJc\npgZv00rzKMxJH7sXKJKEUjPA6++Blj0w/7p410RERETkpOPxDMzsORR/wNLU2Ut9Wy/17T3Ut/VS\nF7y/v6Wb9ftbefqd2iO6gRbnZlBZnEPJoEzg4axgXgYluS4rWJqXSbpXmUCRo6VmgNe8A2xASySI\niIiIxJDXY1z3zPwsoDDsOX2+AHsPdbGzwS3zsKPRTQRT29rDhgNtNHf20ecPhP3Z4twMyvMzKQve\nyvOzGB/sChraludnqUuopJTUDPC0RIKIiIhIQshI8xyeqTMcay2dfX6aO/po6uylqaOP+vZeGtqD\nWcHg/R0NndS399DvP7ZPaCgQzMtMIzczjdxML7kZ7n5eZhp5WWmML8hkYmE2kwqzGV+YSWaaN9Yv\nXSQmUjPACy2RUFIT33qIiIiIyJCMMS4Iy0yjqmToLqHWWg519VPX1kNtWw/1bT3UtfVS29ZDQ3sv\nnb0+Wrr62HfIR1efn45eH529vrDjBEvzMplUlMX4gixyMrykez2kez1kpnlI9xrSvR4y0jzkZrgA\nMW9QsHj4fvCxupLKWErRAG8bFEyGzPDfFImIiIjIyccYc3i83pyJBSP6mVCGsLa1h4Ot3Rxs7eFg\ni7t/oLWHvc1d9PT76fdb+vwB+v0B+nxuGy5bGE5mmof8rCMDwOx0L5lpXrLSPQPbdC+ZaR7yMtMo\nyE6nMDudgqx0CrLTgtt08hUwyjBSM8ALLZEgIiIiIiktlCEMzRY6GoGApavfT0ePj47eftp7fHT0\n+ujo8Q3cD2YJ24P7Q8ebOvvo6ffT6wsc3vb2B+jx+bHDxI25GV4KBgV/oUAwPyvY7TQrjfzMQV1Q\nQ/uC5+RnpakLahJLvQDPWmjcCvM/GO+aiIiIiMhJzOMZ6D4KWVEp01pLV5+ftp5+2rp9wW0/rcFb\ne4/v8OPQOQdaetjY3U5nnwss/eH6nB4lI81DQTDoy073kpHmupxmpnnICHY/zUjz4PUYCBYXKtUG\nI1BjDGkeQ5rXQ4bXbdO8hnSPh+wML2V5mZTmZxxeZ7FUayCOidQL8DrqobcNSmfGuyYiIiIiIkcw\nxgQngkljYviJR4dkraXXF6C9x2UOO3pdkNjZ66e9xwWI7T39tPf6gvd9dPf56PW5rqcdvT76gvf7\n/AF8fosxYEywfphgPSFgLT6/pd9v6fcH8PkD9Afc/UhZyMJg11OLxVqCN4vFlecZ9PrzgxPi5GWm\nk5fpJTsjDWOCP3NU1GmMoSA7jaLsDIpy0inKTqcwxz1Xflb64bbxByx+657bH3Cl5GZ4yctMIy1J\nur6mXoCnCVZEREREJEkZY8hK95KV7qUsPzNu9ejp99PQ3ktjRy+NHX2D7vfS1t2PMS5UNMZgDHiM\nCx791tLV56Oj109HTz8N7b2Hu7p29/kHvVCCoaYLNv0BO+IxkZHkZHgPd3XND2Y3Q2MkM9M8ZA66\nn5HmORwk+gIWfyAQ3LpbutdDToaX7HQv2RnuFnrsugPnn1Bdh5J6Ad7hJRKUwRMRERERiYWsdC+V\nxTlUFg8982k09fT7aenqp6W7j5auYLfWLteVFdy6jB5j8HgMXmNcUGmg4+jsZo/Leh7q6qO3P0Cv\nLzhGMpjZ7PX5DweTXo/B63FdVUNbjzH0+QN09/nxheku+9mLpnPn5bNj1g6pF+DN+wCUn+Jm0RQR\nERERkaSQle5lQqGXCYXRGQ85FH/ABgNEM+R5/f4AXX1+evr9dPX56e7zMy43PaZ1S70AL6sAqs6K\ndy1EREREROQk5fUMHdiFpHs9FGZ7KMyObVA3WHKMJBQREREREREFeCIiIiIiIslCAZ6IiIiIiEiS\nUIAnIiIiIiKSJBTgiYiIiIiIJAkFeCIiIiIiIklCAZ6IiIiIiEiSUIAnIiIiIiKSJBTgiYiIiIiI\nJAkFeCIiIiIiIknCWGvjXYdRMcY0ALtHcGop0BjhWCHQGuVjsSo3FsfGum1OlmNDtUs86pNIx5L9\nb+ZEfjbZ2yZW76eRmmKtLYtCOSkhga+RJ8ux422XWNUnkY6l8t/McMdTuW2SoV3i8ZzRuEZGvj5a\na5PyBqwZ4ti90T4Wq3JjdGxM2+YkOhaxXRKwrgnTNglWz3i8f5O6bWL1ftItvjf93Ua3XRLwdSRM\n2yTDMbVNcv/NJFrbROOWql00H4/BsViVG6u6JkpdEunYcBKpronUNolUz3i8f2NRZjIck5NXIv0d\nJdLfbbJ8BtD/utEfG8nxaD9nMhwbSqLVM5Ha5oSddF00R8oYs8Zauyje9UhEapvw1C6RqW0iU9uE\np3ZJbPr9hKd2iUxtE5naJjy1S2SxbptkzuDdG+8KJDC1TXhql8jUNpGpbcJTuyQ2/X7CU7tEpraJ\nTG0Tntolspi2TdJm8ERERERERFJNMmfwREREREREUkpSBnjGmKXGmM3GmG3GmDvjXZ94Msb8whhT\nb4x5Z9C+YmPMCmPM1uB2XDzrGA/GmEpjzHPGmA3GmPXGmNuD+9U2xmQZY1YbY9YF2+bfgvunGmNW\nBd9XvzPGZMS7rvFgjPEaY94wxjwRfKx2AYwxu4wxbxtj3jTGrAnuS/n3U6LR9XGAro/h6foYma6P\nQ9P1Mbx4XB+TLsAzxniBu4HLgbnADcaYufGtVVw9ACw9at+dwLPW2hnAs8HHqcYHfMlaOxc4G7g1\n+HeitoFe4BJr7WnAAmCpMeZs4LvAD621NcAh4JNxrGM83Q5sHPRY7TLgYmvtgkEDx/V+SiC6Ph7j\nAXR9DEfXx8h0fRyaro+Rjen1MekCPGAxsM1au8Na2wcsA66Jc53ixlr7ItB81O5rgAeD9x8E/m5M\nK5UArLUHrbWvB++34/4hTUZtg3U6gg/TgzcLXAL8Ibg/JdvGGFMBXAncH3xsULsMJeXfTwlG18dB\ndH0MT9fHyHR9jEzXx1GL6fspGQO8ycDeQY/3BffJgPHW2oPB+7XA+HhWJt6MMdXA6cAq1DbA4W4W\nbwL1wApgO9BirfUFT0nV99VdwB1AIPi4BLVLiAWWG2PWGmNuDu7T+ymx6Po4PP3NDqLr47F0fYxI\n18fIxvz6mBbNwuTkY621xpiUnUrVGJMH/C/wBWttm/vCyUnltrHW+oEFxpgi4BFgdpyrFHfGmKuA\nemvtWmPMknjXJwGdb63db4wpB1YYYzYNPpjK7yc5OaX636yuj+Hp+ngsXR+HNebXx2TM4O0HKgc9\nrgjukwF1xpiJAMFtfZzrExfGmHTcxes31to/BnerbQax1rYAzwHnAEXGmNCXQqn4vjoPeK8xZheu\na9slwH+hdgHAWrs/uK3HfehZjN5PiUbXx+HpbxZdH0dC18cj6Po4hHhcH5MxwHsNmBGcuScDuB54\nLM51SjSPATcG798I/CmOdYmLYN/wnwMbrbU/GHRIbWNMWfCbSYwx2cCluDEYzwEfCJ6Wcm1jrf2q\ntbbCWluN+7/yV2vth0nxdgEwxuQaY/JD94H3AO+g91Oi0fVxeCn/N6vrY2S6Poan62Nk8bo+JuVC\n58aYK3B9gb3AL6y134pzleLGGPMQsAQoBeqAbwCPAg8DVcBu4IPW2qMHmic1Y8z5wEvA2wz0F/9n\n3DiDVG+b+bgBv17cl0APW2u/aYyZhvtmrhh4A/iItbY3fjWNn2AXlH+y1l6ldoFgGzwSfJgG/NZa\n+y1jTAkp/n5KNLo+DtD1MTxdHyPT9XF4uj4eKV7Xx6QM8ERERERERFJRMnbRFBERERERSUkK8ERE\nRERERJKEAjwREREREZEkoQBPREREREQkSSjAExERERERSRIK8ETGkDHGb4x5c9DtziiWXW2MeSda\n5YmIiIwlXSNFoiNt+FNEJIq6rbUL4l0JERGRBKRrpEgUKIMnkgCMMbuMMf9hjHnbGLPaGFMT3F9t\njPmrMeYtY8yzxpiq4P7xxphHjDHrgrdzg0V5jTH3GWPWG2OWG2Oy4/aiREREokDXSJHRUYAnMray\nj+p+ct2gY63W2lOBHwN3Bff9N/CgtXY+8BvgR8H9PwJesNaeBiwE1gf3zwDuttaeArQA74/x6xER\nEYkWXSNFosBYa+NdB5GUYYzpsNbmhdm/C7jEWrvDGJMO1FprS4wxjcBEa21/cP9Ba22pMaYBqLDW\n9g4qoxpYYa2dEXz8FSDdWvt/Y//KREREToyukSLRoQyeSOKwEe6PRu+g+340zlZERJKDrpEiI6QA\nTyRxXDdouzJ4/xXg+uD9DwMvBe8/C9wCYIzxGmMKx6qSIiIicaBrpMgI6ZsLkbGVbYx5c9Djp621\noWmgxxlj3sJ9w3hDcN/ngV8aY74MNAAfD+6/HbjXGPNJ3LeQtwAHY157ERGR2NE1UiQKNAZPJAEE\nxxcsstY2xrsuIiIiiUTXSJHRURdNERERERGRJKEMnoiIiIiISJJQBk9ERERERCRJKMATERERERFJ\nEgrwREREREREkoQCPBERERERkSShAE9ERERERCRJKMATERERERFJEv8fTKLSdU1CwHEAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8V76ULoIjZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "labTzDZrIkdn",
        "colab_type": "text"
      },
      "source": [
        "## Batch Size =32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6APKJPKzInBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38e5409e-821f-4afd-bb91-1766a3af3714"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "#else:\n",
        "    #model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 32),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 32, 32, 32)   896         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 32, 32, 32)   128         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 32, 32, 32)   0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 32, 32, 32)   0           activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 32, 32, 32)   1056        dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 32, 32, 32)   128         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 32, 32, 32)   0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 32, 32, 32)   0           activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 32, 32, 32)   9248        dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 32, 32, 32)   128         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 32, 32, 32)   0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 32, 32, 32)   0           activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 128)  4224        dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 32, 32, 128)  4224        dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 32, 32, 128)  0           conv2d_85[0][0]                  \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 32, 32, 128)  512         add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 32, 32, 128)  0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 32, 32, 128)  0           activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 32, 32, 32)   4128        dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 32, 32, 32)   128         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 32, 32, 32)   0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 32, 32, 32)   0           activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 32, 32, 32)   9248        dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 32, 32, 32)   128         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 32, 32, 32)   0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 32, 32, 32)   0           activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 32, 32, 128)  4224        dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 32, 32, 128)  0           add_25[0][0]                     \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 32, 32, 128)  512         add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 32, 32, 128)  0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 32, 32, 128)  0           activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 32, 32, 32)   4128        dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 32, 32, 32)   128         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 32, 32, 32)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 32, 32, 32)   0           activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 32, 32, 32)   9248        dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 32, 32, 32)   128         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 32, 32, 32)   0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, 32, 32, 32)   0           activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 32, 32, 128)  4224        dropout_81[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 32, 32, 128)  0           add_26[0][0]                     \n",
            "                                                                 conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 32, 32, 128)  512         add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 32, 32, 128)  0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, 32, 32, 128)  0           activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 32, 32, 32)   4128        dropout_82[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 32, 32, 32)   128         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 32, 32, 32)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_83 (Dropout)            (None, 32, 32, 32)   0           activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 32, 32, 32)   9248        dropout_83[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 32, 32, 32)   128         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 32, 32, 32)   0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 32, 32, 32)   0           activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 32, 32, 128)  4224        dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 32, 32, 128)  0           add_27[0][0]                     \n",
            "                                                                 conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 32, 32, 128)  512         add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 32, 32, 128)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 32, 32, 128)  0           activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 16, 16, 128)  16512       dropout_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 16, 16, 128)  512         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 16, 16, 128)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 16, 16, 128)  0           activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 16, 16, 128)  147584      dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 16, 16, 128)  512         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 16, 16, 128)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_87 (Dropout)            (None, 16, 16, 128)  0           activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 16, 16, 256)  33024       add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 16, 16, 256)  33024       dropout_87[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 16, 16, 256)  0           conv2d_98[0][0]                  \n",
            "                                                                 conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 16, 16, 256)  1024        add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 16, 16, 256)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_88 (Dropout)            (None, 16, 16, 256)  0           activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 128)  32896       dropout_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 16, 16, 128)  512         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 16, 16, 128)  0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_89 (Dropout)            (None, 16, 16, 128)  0           activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 128)  147584      dropout_89[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 16, 16, 128)  512         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 16, 16, 128)  0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_90 (Dropout)            (None, 16, 16, 128)  0           activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 256)  33024       dropout_90[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 16, 16, 256)  0           add_29[0][0]                     \n",
            "                                                                 conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 16, 16, 256)  1024        add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 16, 16, 256)  0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_91 (Dropout)            (None, 16, 16, 256)  0           activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 128)  32896       dropout_91[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 16, 16, 128)  512         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 16, 16, 128)  0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, 16, 16, 128)  0           activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 128)  147584      dropout_92[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 16, 16, 128)  512         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 16, 16, 128)  0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 16, 16, 128)  0           activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 256)  33024       dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 16, 16, 256)  0           add_30[0][0]                     \n",
            "                                                                 conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 16, 16, 256)  1024        add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 16, 16, 256)  0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, 16, 16, 256)  0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 128)  32896       dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 16, 16, 128)  512         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 16, 16, 128)  0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_95 (Dropout)            (None, 16, 16, 128)  0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 128)  147584      dropout_95[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 16, 16, 128)  512         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 16, 16, 128)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, 16, 16, 128)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 256)  33024       dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 16, 16, 256)  0           add_31[0][0]                     \n",
            "                                                                 conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 256)  1024        add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 256)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_97 (Dropout)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 8, 8, 256)    65792       dropout_97[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 8, 8, 256)    1024        conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 8, 8, 256)    0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, 8, 8, 256)    0           activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 8, 8, 256)    590080      dropout_98[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 8, 8, 256)    1024        conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 8, 8, 256)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_99 (Dropout)            (None, 8, 8, 256)    0           activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 8, 8, 512)    131584      add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 8, 8, 512)    131584      dropout_99[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 8, 8, 512)    0           conv2d_111[0][0]                 \n",
            "                                                                 conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 8, 8, 512)    2048        add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 8, 8, 512)    0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_100 (Dropout)           (None, 8, 8, 512)    0           activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 8, 8, 256)    131328      dropout_100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 8, 8, 256)    1024        conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 8, 8, 256)    0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_101 (Dropout)           (None, 8, 8, 256)    0           activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 8, 8, 256)    590080      dropout_101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 8, 8, 256)    1024        conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 8, 8, 256)    0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_102 (Dropout)           (None, 8, 8, 256)    0           activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 8, 8, 512)    131584      dropout_102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 8, 8, 512)    0           add_33[0][0]                     \n",
            "                                                                 conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 8, 8, 512)    2048        add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 8, 8, 512)    0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 8, 8, 512)    0           activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 8, 8, 256)    131328      dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 8, 8, 256)    1024        conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 8, 8, 256)    0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 8, 8, 256)    0           activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 8, 8, 256)    590080      dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 8, 8, 256)    1024        conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 8, 8, 256)    0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 8, 8, 256)    0           activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 8, 8, 512)    131584      dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 8, 8, 512)    0           add_34[0][0]                     \n",
            "                                                                 conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 8, 8, 512)    2048        add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 8, 8, 512)    0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 8, 8, 512)    0           activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 8, 8, 256)    131328      dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 8, 8, 256)    1024        conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 8, 8, 256)    0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 8, 8, 256)    0           activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 8, 8, 256)    590080      dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 8, 8, 256)    1024        conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 8, 8, 256)    0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 8, 8, 256)    0           activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 8, 8, 512)    131584      dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 8, 8, 512)    0           add_35[0][0]                     \n",
            "                                                                 conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 8, 8, 512)    2048        add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 8, 8, 512)    0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 512)    0           activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 512)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           5130        flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,454,026\n",
            "Trainable params: 4,440,138\n",
            "Non-trainable params: 13,888\n",
            "__________________________________________________________________________________________________\n",
            "ResNet38v2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=1562, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "1562/1562 [==============================] - 120s 77ms/step - loss: 1.8897 - acc: 0.4653 - val_loss: 1.7784 - val_acc: 0.4600\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 1.3646 - acc: 0.5982 - val_loss: 1.3647 - val_acc: 0.5965\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 1.2038 - acc: 0.6452 - val_loss: 1.3527 - val_acc: 0.5936\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 1.0959 - acc: 0.6804 - val_loss: 1.3198 - val_acc: 0.5984\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 1.0083 - acc: 0.7093 - val_loss: 1.0251 - val_acc: 0.7227\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 0.9415 - acc: 0.7307 - val_loss: 1.1140 - val_acc: 0.6662\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 0.8794 - acc: 0.7547 - val_loss: 1.0415 - val_acc: 0.7004\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "1562/1562 [==============================] - 102s 66ms/step - loss: 0.8312 - acc: 0.7711 - val_loss: 0.9091 - val_acc: 0.7550\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 0.7881 - acc: 0.7855 - val_loss: 0.9335 - val_acc: 0.7386\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 0.7481 - acc: 0.7983 - val_loss: 0.7862 - val_acc: 0.7798\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.7189 - acc: 0.8083 - val_loss: 0.9651 - val_acc: 0.7474\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.6948 - acc: 0.8156 - val_loss: 0.7092 - val_acc: 0.8178\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.6667 - acc: 0.8244 - val_loss: 0.7451 - val_acc: 0.8084\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.6425 - acc: 0.8341 - val_loss: 0.7065 - val_acc: 0.8026\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.6261 - acc: 0.8382 - val_loss: 0.7105 - val_acc: 0.8114\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.6041 - acc: 0.8459 - val_loss: 0.6585 - val_acc: 0.8299\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "1562/1562 [==============================] - 104s 66ms/step - loss: 0.5875 - acc: 0.8526 - val_loss: 0.6591 - val_acc: 0.8296\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "1562/1562 [==============================] - 104s 66ms/step - loss: 0.5684 - acc: 0.8578 - val_loss: 0.7175 - val_acc: 0.8029\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "1562/1562 [==============================] - 104s 66ms/step - loss: 0.5525 - acc: 0.8628 - val_loss: 0.6066 - val_acc: 0.8460\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "1562/1562 [==============================] - 104s 67ms/step - loss: 0.5361 - acc: 0.8663 - val_loss: 0.6001 - val_acc: 0.8505\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.5251 - acc: 0.8697 - val_loss: 0.7077 - val_acc: 0.8232\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "1562/1562 [==============================] - 102s 66ms/step - loss: 0.5127 - acc: 0.8744 - val_loss: 0.6044 - val_acc: 0.8467\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "1562/1562 [==============================] - 104s 67ms/step - loss: 0.4951 - acc: 0.8787 - val_loss: 0.6414 - val_acc: 0.8364\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 0.4871 - acc: 0.8816 - val_loss: 0.5616 - val_acc: 0.8591\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.4779 - acc: 0.8850 - val_loss: 0.5914 - val_acc: 0.8523\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.4637 - acc: 0.8902 - val_loss: 0.6029 - val_acc: 0.8536\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "1562/1562 [==============================] - 101s 65ms/step - loss: 0.4492 - acc: 0.8937 - val_loss: 0.5900 - val_acc: 0.8532\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "1562/1562 [==============================] - 104s 66ms/step - loss: 0.4447 - acc: 0.8947 - val_loss: 0.6252 - val_acc: 0.8397\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "1562/1562 [==============================] - 102s 66ms/step - loss: 0.4356 - acc: 0.8974 - val_loss: 0.5350 - val_acc: 0.8702\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "1562/1562 [==============================] - 103s 66ms/step - loss: 0.4213 - acc: 0.9030 - val_loss: 0.5794 - val_acc: 0.8566\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "1562/1562 [==============================] - 104s 67ms/step - loss: 0.4177 - acc: 0.9025 - val_loss: 0.6096 - val_acc: 0.8516\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "1562/1562 [==============================] - 101s 65ms/step - loss: 0.4120 - acc: 0.9061 - val_loss: 0.5509 - val_acc: 0.8653\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "1562/1562 [==============================] - 102s 66ms/step - loss: 0.3988 - acc: 0.9095 - val_loss: 0.5731 - val_acc: 0.8598\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3944 - acc: 0.9098 - val_loss: 0.5405 - val_acc: 0.8707\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3893 - acc: 0.9127 - val_loss: 0.5415 - val_acc: 0.8696\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3838 - acc: 0.9142 - val_loss: 0.5559 - val_acc: 0.8654\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3717 - acc: 0.9171 - val_loss: 0.5873 - val_acc: 0.8651\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "1562/1562 [==============================] - 101s 65ms/step - loss: 0.3705 - acc: 0.9184 - val_loss: 0.5341 - val_acc: 0.8739\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "1562/1562 [==============================] - 101s 65ms/step - loss: 0.3605 - acc: 0.9220 - val_loss: 0.5643 - val_acc: 0.8623\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3571 - acc: 0.9218 - val_loss: 0.5468 - val_acc: 0.8705\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3511 - acc: 0.9231 - val_loss: 0.5485 - val_acc: 0.8726\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3456 - acc: 0.9265 - val_loss: 0.5642 - val_acc: 0.8657\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3391 - acc: 0.9278 - val_loss: 0.5477 - val_acc: 0.8705\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3351 - acc: 0.9286 - val_loss: 0.5404 - val_acc: 0.8736\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3313 - acc: 0.9288 - val_loss: 0.5157 - val_acc: 0.8839\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3248 - acc: 0.9314 - val_loss: 0.4999 - val_acc: 0.8863\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3198 - acc: 0.9340 - val_loss: 0.5206 - val_acc: 0.8780\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3158 - acc: 0.9341 - val_loss: 0.5295 - val_acc: 0.8801\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "1562/1562 [==============================] - 102s 65ms/step - loss: 0.3064 - acc: 0.9379 - val_loss: 0.5388 - val_acc: 0.8780\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "1562/1562 [==============================] - 101s 65ms/step - loss: 0.3062 - acc: 0.9377 - val_loss: 0.5308 - val_acc: 0.8779\n",
            "Model took 5139.35 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBz-bxH5dBat",
        "colab_type": "text"
      },
      "source": [
        "## Batch size 32 increased accuracy to 88.63\n",
        "## Trying with batch size =16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x_y6cOPdTGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ab7b922-330e-4015-8d02-48569ae05d79"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "#else:\n",
        "    #model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 16),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 32, 32, 32)   896         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 32)   128         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 32, 32, 32)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 32, 32, 32)   0           activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 32, 32, 32)   1056        dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 32, 32, 32)   128         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 32, 32, 32)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 32, 32, 32)   0           activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 32, 32, 32)   9248        dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 32, 32, 32)   128         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 32, 32, 32)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 32, 32, 32)   0           activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 32, 32, 128)  4224        dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 32, 32, 128)  4224        dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 32, 32, 128)  0           conv2d_125[0][0]                 \n",
            "                                                                 conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 32, 32, 128)  512         add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 32, 32, 128)  0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 32, 32, 128)  0           activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 32, 32, 32)   4128        dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 32, 32, 32)   128         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 32, 32, 32)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 32, 32, 32)   0           activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 32, 32, 32)   9248        dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 32, 32, 32)   128         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 32, 32, 32)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 32, 32, 32)   0           activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 32, 32, 128)  4224        dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 32, 32, 128)  0           add_37[0][0]                     \n",
            "                                                                 conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 32, 32, 128)  512         add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 32, 32, 128)  0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 32, 32, 128)  0           activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 32, 32, 32)   4128        dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 32, 32, 32)   128         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 32, 32, 32)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, 32, 32, 32)   0           activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 32, 32, 32)   9248        dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 32, 32, 32)   128         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 32, 32, 32)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, 32, 32, 32)   0           activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 32, 32, 128)  4224        dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 32, 32, 128)  0           add_38[0][0]                     \n",
            "                                                                 conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 32, 32, 128)  512         add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 32, 32, 128)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, 32, 32, 128)  0           activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 32, 32, 32)   4128        dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 32, 32, 32)   128         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 32, 32, 32)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 32, 32, 32)   0           activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 32, 32, 32)   9248        dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 32, 32, 32)   128         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 32, 32, 32)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 32, 32, 32)   0           activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 32, 32, 128)  4224        dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 32, 32, 128)  0           add_39[0][0]                     \n",
            "                                                                 conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 32, 32, 128)  512         add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 32, 32, 128)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 32, 32, 128)  0           activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 16, 16, 128)  16512       dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 16, 16, 128)  512         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 16, 16, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 16, 16, 128)  0           activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 16, 16, 128)  147584      dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 16, 16, 128)  512         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 16, 16, 128)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 16, 16, 128)  0           activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 16, 16, 256)  33024       add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 16, 16, 256)  33024       dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 16, 16, 256)  0           conv2d_138[0][0]                 \n",
            "                                                                 conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 16, 16, 256)  1024        add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 16, 16, 256)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 16, 16, 256)  0           activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 16, 16, 128)  32896       dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 16, 16, 128)  512         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 16, 16, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 16, 16, 128)  0           activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 16, 16, 128)  147584      dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 16, 16, 128)  512         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 16, 16, 128)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 16, 16, 128)  0           activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 16, 16, 256)  33024       dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 16, 16, 256)  0           add_41[0][0]                     \n",
            "                                                                 conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 16, 16, 256)  1024        add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 16, 16, 256)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 16, 16, 256)  0           activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 16, 16, 128)  32896       dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 16, 16, 128)  512         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 16, 16, 128)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 16, 16, 128)  0           activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 16, 16, 128)  147584      dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 16, 16, 128)  512         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 16, 16, 128)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 16, 16, 128)  0           activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 16, 16, 256)  33024       dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 16, 16, 256)  0           add_42[0][0]                     \n",
            "                                                                 conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 16, 16, 256)  1024        add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 16, 16, 256)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 16, 16, 256)  0           activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 16, 16, 128)  32896       dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 16, 16, 128)  512         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 16, 16, 128)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 16, 16, 128)  0           activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 16, 16, 128)  147584      dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 16, 16, 128)  512         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 16, 16, 128)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 16, 16, 128)  0           activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 16, 16, 256)  33024       dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 16, 16, 256)  0           add_43[0][0]                     \n",
            "                                                                 conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 16, 16, 256)  1024        add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 16, 16, 256)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 16, 16, 256)  0           activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 8, 8, 256)    65792       dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 8, 8, 256)    1024        conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 8, 8, 256)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 8, 8, 256)    0           activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 8, 8, 256)    590080      dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 8, 8, 256)    1024        conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 256)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 8, 8, 256)    0           activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 8, 8, 512)    131584      add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 8, 8, 512)    131584      dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 8, 8, 512)    0           conv2d_151[0][0]                 \n",
            "                                                                 conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 8, 8, 512)    2048        add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 512)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 8, 8, 512)    0           activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 8, 8, 256)    131328      dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 8, 8, 256)    1024        conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 8, 8, 256)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 8, 8, 256)    0           activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 8, 8, 256)    590080      dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 8, 8, 256)    1024        conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 8, 8, 256)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 8, 8, 256)    0           activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 8, 8, 512)    131584      dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 8, 8, 512)    0           add_45[0][0]                     \n",
            "                                                                 conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 8, 8, 512)    2048        add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 8, 8, 512)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 8, 8, 512)    0           activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 8, 8, 256)    131328      dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 8, 8, 256)    1024        conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 8, 8, 256)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 8, 8, 256)    0           activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 8, 8, 256)    590080      dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 8, 8, 256)    1024        conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 8, 8, 256)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 8, 8, 256)    0           activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 8, 8, 512)    131584      dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 8, 8, 512)    0           add_46[0][0]                     \n",
            "                                                                 conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 8, 8, 512)    2048        add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 8, 8, 512)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 8, 8, 512)    0           activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 8, 8, 256)    131328      dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 8, 8, 256)    1024        conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 8, 8, 256)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 8, 8, 256)    0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 8, 8, 256)    590080      dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 8, 8, 256)    1024        conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 8, 8, 256)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 8, 8, 256)    0           activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 8, 8, 512)    131584      dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 8, 8, 512)    0           add_47[0][0]                     \n",
            "                                                                 conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 8, 8, 512)    2048        add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 8, 8, 512)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 1, 1, 512)    0           activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 512)          0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 10)           5130        flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,454,026\n",
            "Trainable params: 4,440,138\n",
            "Non-trainable params: 13,888\n",
            "__________________________________________________________________________________________________\n",
            "ResNet38v2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=3125, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "3125/3125 [==============================] - 191s 61ms/step - loss: 1.8909 - acc: 0.3959 - val_loss: 1.5887 - val_acc: 0.4534\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "3125/3125 [==============================] - 176s 56ms/step - loss: 1.4634 - acc: 0.5197 - val_loss: 1.3176 - val_acc: 0.5586\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "3125/3125 [==============================] - 174s 56ms/step - loss: 1.3496 - acc: 0.5605 - val_loss: 1.2107 - val_acc: 0.6073\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "3125/3125 [==============================] - 170s 55ms/step - loss: 1.2657 - acc: 0.5907 - val_loss: 1.2207 - val_acc: 0.6115\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "3125/3125 [==============================] - 170s 54ms/step - loss: 1.2027 - acc: 0.6127 - val_loss: 1.1395 - val_acc: 0.6297\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "3125/3125 [==============================] - 170s 54ms/step - loss: 1.1570 - acc: 0.6304 - val_loss: 1.2415 - val_acc: 0.6127\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "3125/3125 [==============================] - 167s 54ms/step - loss: 1.1160 - acc: 0.6445 - val_loss: 1.0444 - val_acc: 0.6675\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "3125/3125 [==============================] - 167s 54ms/step - loss: 1.0795 - acc: 0.6573 - val_loss: 1.0243 - val_acc: 0.6807\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "3125/3125 [==============================] - 168s 54ms/step - loss: 1.0432 - acc: 0.6706 - val_loss: 1.0319 - val_acc: 0.6817\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "3125/3125 [==============================] - 169s 54ms/step - loss: 1.0240 - acc: 0.6764 - val_loss: 1.0013 - val_acc: 0.6932\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.9944 - acc: 0.6862 - val_loss: 1.2682 - val_acc: 0.6103\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "3125/3125 [==============================] - 167s 54ms/step - loss: 0.9713 - acc: 0.6968 - val_loss: 0.9834 - val_acc: 0.6883\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.9528 - acc: 0.7007 - val_loss: 0.9308 - val_acc: 0.7087\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "3125/3125 [==============================] - 167s 54ms/step - loss: 0.9310 - acc: 0.7097 - val_loss: 0.9086 - val_acc: 0.7176\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.9124 - acc: 0.7174 - val_loss: 0.9295 - val_acc: 0.7156\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.8944 - acc: 0.7228 - val_loss: 0.8812 - val_acc: 0.7290\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.8786 - acc: 0.7244 - val_loss: 0.9635 - val_acc: 0.7119\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.8663 - acc: 0.7328 - val_loss: 0.8961 - val_acc: 0.7265\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.8494 - acc: 0.7379 - val_loss: 0.9328 - val_acc: 0.7182\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.8355 - acc: 0.7437 - val_loss: 0.8611 - val_acc: 0.7390\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.8205 - acc: 0.7466 - val_loss: 0.8461 - val_acc: 0.7493\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "3125/3125 [==============================] - 167s 54ms/step - loss: 0.8111 - acc: 0.7510 - val_loss: 0.8697 - val_acc: 0.7373\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "3125/3125 [==============================] - 169s 54ms/step - loss: 0.8014 - acc: 0.7560 - val_loss: 0.9062 - val_acc: 0.7250\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "3125/3125 [==============================] - 168s 54ms/step - loss: 0.7879 - acc: 0.7576 - val_loss: 0.8440 - val_acc: 0.7439\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "3125/3125 [==============================] - 175s 56ms/step - loss: 0.7790 - acc: 0.7647 - val_loss: 0.7549 - val_acc: 0.7742\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "3125/3125 [==============================] - 169s 54ms/step - loss: 0.7705 - acc: 0.7650 - val_loss: 0.8019 - val_acc: 0.7603\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "3125/3125 [==============================] - 167s 54ms/step - loss: 0.7610 - acc: 0.7688 - val_loss: 0.8112 - val_acc: 0.7585\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.7519 - acc: 0.7718 - val_loss: 0.7379 - val_acc: 0.7760\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.7399 - acc: 0.7768 - val_loss: 0.8195 - val_acc: 0.7593\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "3125/3125 [==============================] - 165s 53ms/step - loss: 0.7356 - acc: 0.7768 - val_loss: 0.7601 - val_acc: 0.7725\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.7293 - acc: 0.7765 - val_loss: 0.7724 - val_acc: 0.7655\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.7210 - acc: 0.7805 - val_loss: 0.7796 - val_acc: 0.7694\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.7151 - acc: 0.7832 - val_loss: 0.7863 - val_acc: 0.7722\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.7095 - acc: 0.7846 - val_loss: 0.7195 - val_acc: 0.7906\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "3125/3125 [==============================] - 170s 54ms/step - loss: 0.7020 - acc: 0.7869 - val_loss: 0.7228 - val_acc: 0.7871\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "3125/3125 [==============================] - 172s 55ms/step - loss: 0.6982 - acc: 0.7880 - val_loss: 0.7743 - val_acc: 0.7720\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.6888 - acc: 0.7918 - val_loss: 0.7804 - val_acc: 0.7697\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.6839 - acc: 0.7938 - val_loss: 0.7250 - val_acc: 0.7894\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.6752 - acc: 0.7966 - val_loss: 0.7284 - val_acc: 0.7895\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.6719 - acc: 0.7980 - val_loss: 0.6866 - val_acc: 0.7999\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "3125/3125 [==============================] - 165s 53ms/step - loss: 0.6636 - acc: 0.8001 - val_loss: 0.7458 - val_acc: 0.7857\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.6626 - acc: 0.7990 - val_loss: 0.6830 - val_acc: 0.7973\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.6600 - acc: 0.8015 - val_loss: 0.7419 - val_acc: 0.7842\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.6511 - acc: 0.8045 - val_loss: 0.7089 - val_acc: 0.7987\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.6469 - acc: 0.8048 - val_loss: 0.6871 - val_acc: 0.8008\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "3125/3125 [==============================] - 170s 54ms/step - loss: 0.6433 - acc: 0.8064 - val_loss: 0.7158 - val_acc: 0.7915\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "3125/3125 [==============================] - 170s 54ms/step - loss: 0.6383 - acc: 0.8076 - val_loss: 0.6780 - val_acc: 0.8008\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "3125/3125 [==============================] - 167s 53ms/step - loss: 0.6365 - acc: 0.8087 - val_loss: 0.6486 - val_acc: 0.8083\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "3125/3125 [==============================] - 166s 53ms/step - loss: 0.6312 - acc: 0.8103 - val_loss: 0.6693 - val_acc: 0.8057\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "3125/3125 [==============================] - 169s 54ms/step - loss: 0.6264 - acc: 0.8127 - val_loss: 0.7031 - val_acc: 0.7979\n",
            "Model took 8419.27 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8YY0uwcT9iB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT4qqQsvT-QT",
        "colab_type": "text"
      },
      "source": [
        "## Batch Size = 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NztH26XKUR7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d2476fa-210f-4b2b-d953-8f33381b7591"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "#else:\n",
        "    #model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 64),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 32, 32, 32)   896         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 32, 32, 32)   128         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 32, 32, 32)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 32, 32, 32)   0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 32)   1056        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 32, 32, 32)   128         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 32, 32, 32)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 32, 32, 32)   0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 32)   9248        dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 32)   128         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 32)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 32, 32, 32)   0           activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 32, 32, 128)  4224        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 128)  4224        dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 32, 32, 128)  0           conv2d_45[0][0]                  \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 128)  512         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 128)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 32, 32, 128)  0           activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 32, 32, 32)   4128        dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 32)   128         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 32)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 32, 32, 32)   0           activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 32, 32, 32)   9248        dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 32, 32, 32)   128         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 32)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 32, 32, 32)   0           activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 32, 32, 128)  4224        dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 32, 32, 128)  0           add_13[0][0]                     \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 32, 32, 128)  512         add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 32, 32, 128)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 32, 32, 128)  0           activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 32, 32, 32)   4128        dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 32, 32, 32)   128         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 32, 32, 32)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 32, 32, 32)   0           activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 32, 32, 32)   9248        dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 32, 32, 32)   128         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 32, 32, 32)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 32, 32, 32)   0           activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 32, 32, 128)  4224        dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 32, 32, 128)  0           add_14[0][0]                     \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 32, 32, 128)  512         add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 32, 32, 128)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 32, 32, 128)  0           activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 32, 32, 32)   4128        dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 32, 32, 32)   128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 32, 32, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 32, 32, 32)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 32, 32, 32)   9248        dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 32, 32, 32)   128         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 32, 32, 32)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 32, 32, 32)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 32, 32, 128)  4224        dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 32, 32, 128)  0           add_15[0][0]                     \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 128)  512         add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 128)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 32, 32, 128)  0           activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 128)  16512       dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 128)  512         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 16, 16, 128)  0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 128)  147584      dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 128)  512         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 128)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 16, 16, 128)  0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 256)  33024       add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 256)  33024       dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 16, 16, 256)  0           conv2d_58[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 256)  1024        add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 256)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 16, 16, 256)  0           activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 128)  32896       dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 128)  512         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 16, 16, 128)  0           activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 128)  147584      dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 128)  512         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 128)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 16, 16, 128)  0           activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 256)  33024       dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 16, 16, 256)  0           add_17[0][0]                     \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 256)  1024        add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 256)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 16, 16, 256)  0           activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 128)  32896       dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 128)  512         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 128)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 16, 16, 128)  0           activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 128)  147584      dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 128)  512         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 128)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 16, 16, 128)  0           activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 256)  33024       dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 16, 16, 256)  0           add_18[0][0]                     \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 256)  1024        add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 256)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 16, 16, 256)  0           activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 128)  32896       dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 128)  512         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 128)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 16, 16, 128)  0           activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 128)  147584      dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 128)  512         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 128)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 16, 16, 128)  0           activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 256)  33024       dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 16, 16, 256)  0           add_19[0][0]                     \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 256)  1024        add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 256)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 16, 16, 256)  0           activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 256)    65792       dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 8, 8, 256)    1024        conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 8, 8, 256)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 8, 8, 256)    0           activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 256)    590080      dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 8, 8, 256)    1024        conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 256)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 8, 8, 256)    0           activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 512)    131584      add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 512)    131584      dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 8, 8, 512)    0           conv2d_71[0][0]                  \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 8, 8, 512)    2048        add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 8, 8, 512)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 8, 8, 512)    0           activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 256)    131328      dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 256)    1024        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 256)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 8, 8, 256)    0           activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 256)    590080      dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 256)    1024        conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 256)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 8, 8, 256)    0           activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 512)    131584      dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 8, 8, 512)    0           add_21[0][0]                     \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 512)    2048        add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 512)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 8, 8, 512)    0           activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 256)    131328      dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 256)    1024        conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 256)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 8, 8, 256)    0           activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 256)    590080      dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 256)    1024        conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 256)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 8, 8, 256)    0           activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 512)    131584      dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 8, 8, 512)    0           add_22[0][0]                     \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 512)    2048        add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 512)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 8, 8, 512)    0           activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 256)    131328      dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 256)    1024        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 256)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 8, 8, 256)    0           activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 256)    590080      dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 256)    1024        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 256)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 8, 8, 256)    0           activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 512)    131584      dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 8, 8, 512)    0           add_23[0][0]                     \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 512)    2048        add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 512)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 512)    0           activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 512)          0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           5130        flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,454,026\n",
            "Trainable params: 4,440,138\n",
            "Non-trainable params: 13,888\n",
            "__________________________________________________________________________________________________\n",
            "ResNet38v2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=781, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "781/781 [==============================] - 99s 126ms/step - loss: 1.9422 - acc: 0.4892 - val_loss: 2.1549 - val_acc: 0.4039\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 1.3366 - acc: 0.6208 - val_loss: 1.4400 - val_acc: 0.5873\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 1.1823 - acc: 0.6676 - val_loss: 1.4344 - val_acc: 0.5824\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 1.0772 - acc: 0.6995 - val_loss: 1.2284 - val_acc: 0.6636\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "781/781 [==============================] - 82s 106ms/step - loss: 0.9954 - acc: 0.7262 - val_loss: 1.3495 - val_acc: 0.6096\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.9254 - acc: 0.7508 - val_loss: 0.9423 - val_acc: 0.7425\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.8632 - acc: 0.7709 - val_loss: 1.0156 - val_acc: 0.7322\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.8038 - acc: 0.7906 - val_loss: 0.8672 - val_acc: 0.7733\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.7560 - acc: 0.8058 - val_loss: 0.8358 - val_acc: 0.7834\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.7161 - acc: 0.8178 - val_loss: 0.8615 - val_acc: 0.7733\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.6783 - acc: 0.8311 - val_loss: 0.7352 - val_acc: 0.8143\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.6481 - acc: 0.8401 - val_loss: 0.7605 - val_acc: 0.8023\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.6257 - acc: 0.8484 - val_loss: 0.8987 - val_acc: 0.7675\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.5977 - acc: 0.8561 - val_loss: 0.7164 - val_acc: 0.8178\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.5711 - acc: 0.8654 - val_loss: 0.7297 - val_acc: 0.8122\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.5519 - acc: 0.8696 - val_loss: 0.7160 - val_acc: 0.8237\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "781/781 [==============================] - 82s 104ms/step - loss: 0.5327 - acc: 0.8770 - val_loss: 0.7211 - val_acc: 0.8250\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "781/781 [==============================] - 82s 104ms/step - loss: 0.5133 - acc: 0.8826 - val_loss: 0.6501 - val_acc: 0.8393\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "781/781 [==============================] - 82s 104ms/step - loss: 0.4933 - acc: 0.8892 - val_loss: 0.7593 - val_acc: 0.8119\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.4727 - acc: 0.8963 - val_loss: 0.6217 - val_acc: 0.8543\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "781/781 [==============================] - 82s 106ms/step - loss: 0.4638 - acc: 0.8980 - val_loss: 0.6612 - val_acc: 0.8442\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.4469 - acc: 0.9051 - val_loss: 0.6310 - val_acc: 0.8529\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.4381 - acc: 0.9060 - val_loss: 0.5995 - val_acc: 0.8595\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.4204 - acc: 0.9125 - val_loss: 0.6244 - val_acc: 0.8554\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.4063 - acc: 0.9161 - val_loss: 0.6465 - val_acc: 0.8514\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3925 - acc: 0.9221 - val_loss: 0.6149 - val_acc: 0.8592\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3844 - acc: 0.9230 - val_loss: 0.6682 - val_acc: 0.8505\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3741 - acc: 0.9270 - val_loss: 0.6154 - val_acc: 0.8584\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3637 - acc: 0.9311 - val_loss: 0.6297 - val_acc: 0.8631\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3562 - acc: 0.9321 - val_loss: 0.6611 - val_acc: 0.8518\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3486 - acc: 0.9351 - val_loss: 0.7672 - val_acc: 0.8312\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3376 - acc: 0.9395 - val_loss: 0.5903 - val_acc: 0.8670\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3302 - acc: 0.9409 - val_loss: 0.6547 - val_acc: 0.8575\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3222 - acc: 0.9453 - val_loss: 0.6109 - val_acc: 0.8669\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3192 - acc: 0.9428 - val_loss: 0.6607 - val_acc: 0.8583\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3076 - acc: 0.9472 - val_loss: 0.5891 - val_acc: 0.8736\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3029 - acc: 0.9489 - val_loss: 0.6046 - val_acc: 0.8717\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.2968 - acc: 0.9519 - val_loss: 0.6443 - val_acc: 0.8585\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.2924 - acc: 0.9514 - val_loss: 0.6313 - val_acc: 0.8724\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "781/781 [==============================] - 82s 106ms/step - loss: 0.2878 - acc: 0.9536 - val_loss: 0.6294 - val_acc: 0.8640\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.2806 - acc: 0.9557 - val_loss: 0.5745 - val_acc: 0.8785\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.2744 - acc: 0.9572 - val_loss: 0.6104 - val_acc: 0.8741\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.2718 - acc: 0.9586 - val_loss: 0.6649 - val_acc: 0.8609\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.2673 - acc: 0.9601 - val_loss: 0.6307 - val_acc: 0.8731\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.2615 - acc: 0.9615 - val_loss: 0.6071 - val_acc: 0.8719\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.2580 - acc: 0.9627 - val_loss: 0.6071 - val_acc: 0.8674\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.2561 - acc: 0.9621 - val_loss: 0.6531 - val_acc: 0.8654\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.2505 - acc: 0.9653 - val_loss: 0.6538 - val_acc: 0.8618\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.2512 - acc: 0.9642 - val_loss: 0.6191 - val_acc: 0.8717\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.2460 - acc: 0.9653 - val_loss: 0.5801 - val_acc: 0.8817\n",
            "Model took 4133.44 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3hcxfX/8fdR77Kae5N7weCGTcem\n995NDYGEkAQSUsg3/IAkJCE9IYQQWugtdAidGJtiwAX33i25qNnqXfP7Y1a2bEuyZEtarfx5Pc8+\nu3vv3N2zK8y9Z2fmjDnnEBERERERkdAXFuwAREREREREpG0owRMREREREekilOCJiIiIiIh0EUrw\nREREREREuggleCIiIiIiIl2EEjwREREREZEuQgmeyAEys4Fm5swsogVtrzWzTzsiLhERkVClc6vI\n/lOCJwcVM1tvZlVmlr7H9q8DJ5KBwYlst1gSzKzEzN4JdiwiIiL70pnPra1JFEW6CiV4cjBaB1xe\n/8TMxgBxwQtnLxcClcDJZtazI99YJ0AREdlPnf3cKnLQUIInB6OngKsbPL8GeLJhAzNLNrMnzSzX\nzDaY2R1mFhbYF25mfzSzPDNbC5zZyLGPmtkWM8s2s3vMLLwV8V0DPAgsBK7c47X7mdkrgbjyzez+\nBvtuMLNlZlZsZkvNbHxguzOzIQ3aPW5m9wQeTzGzLDP7qZltBf5tZilm9lbgPbYHHvdtcHyqmf3b\nzDYH9r8W2L7YzM5u0C4y8B2Na8VnFxGR0NTZz617MbNoM/tr4Hy2OfA4OrAvPXD+22FmBWb2SYNY\nfxqIodjMVpjZiQcSh0hbU4InB6MvgCQzGxk4OVwGPL1Hm78DycAg4Hj8Seu6wL4bgLOAccBE4KI9\njn0cqAGGBNqcAnyzJYGZ2QBgCvBM4HZ1g33hwFvABmAg0Ad4PrDvYuDuQPsk4BwgvyXvCfQEUoEB\nwI34/y/8O/C8P1AO3N+g/VP4X2VHA92BvwS2P8nuCekZwBbn3NctjENEREJXpz23NuPnwBHAWOAw\nYBJwR2DfbUAWkAH0AP4PcGY2HPgucLhzLhE4FVh/gHGItCkleHKwqv+l8WRgGZBdv6PBielnzrli\n59x64E/AVYEmlwB/dc5tcs4VAL9tcGwPfGJzq3Ou1DmXg0+ALmthXFcBC51zS/HJ2+gGPWCTgN7A\njwOvXeGcq59U/k3g98652c5b7Zzb0ML3rAPucs5VOufKnXP5zrmXnXNlzrli4Nf4EzFm1gs4Hfi2\nc267c67aOTcj8DpPA2eYWVKDz/JUC2MQEZHQ11nPrU2ZBvzSOZfjnMsFftEgnmqgFzAgcK77xDnn\ngFogGhhlZpHOufXOuTUHGIdIm9J8GzlYPQXMBDLZYwgJkA5E4nvK6m3A95iBT7I27bGv3oDAsVvM\nrH5b2B7tm3M18DCAcy7bzGbgh7l8DfQDNjjnaho5rh+wvyeYXOdcRf0TM4vDnzhPA1ICmxMDJ+d+\nQIFzbvueL+Kc22xmnwEXmtmr+ETwlv2MSUREQk9nPbc2pXcj8fQOPP4DfmTM+4H3fMg5d69zbrWZ\n3RrYN9rM3gN+6JzbfICxiLQZ9eDJQSnQu7UO/4vgK3vszsP/cjegwbb+7Polcgs+0Wm4r94mfIGU\ndOdct8AtyTk3el8xmdlRwFDgZ2a2NTAnbjJwRaD4ySagfxOFUDYBg5t46TJ2n+i+Z+EWt8fz24Dh\nwGTnXBJwXH2IgfdJNbNuTbzXE/hhmhcDs5xz2U20ExGRLqYznlv3YXMj8WwOfJZi59xtzrlB+GkP\nP6yfa+ece9Y5d0zgWAf87gDjEGlTSvDkYHY9cIJzrrThRudcLfAi8GszSwzMi/shu+YSvAh838z6\nmlkKcHuDY7cA7wN/MrMkMwszs8FmdnwL4rkG+AAYhZ8PMBY4BIjF94Z9hT8B3mtm8WYWY2ZHB459\nBPiRmU0wb0ggboD5+CQx3MxOIzDcshmJ+Hl3O8wsFbhrj8/3DvBAoBhLpJkd1+DY14Dx+J67PX+9\nFRGRrq+znVvrRQfOm/W3MOA54A4zyzC/xMOd9fGY2VmBc6kBhfihmXVmNtzMTggUY6nAny/rWvkd\nibQrJXhy0HLOrXHOzWli9/eAUmAt8CnwLPBYYN/DwHvAAmAee/9KeTUQBSwFtgMv4cfxN8nMYvDz\nD/7unNva4LYOP+TlmsDJ8Wz8BPON+MnflwY+y3/wc+WeBYrxiVZq4OVvCRy3Az/f4LXmYgH+ik8q\n8/CT5t/dY/9V+F9hlwM5wK31O5xz5cDL+OE5e34vIiLSxXWmc+seSvDJWP3tBOAeYA6+avWiwPve\nE2g/FPgwcNws4AHn3HT8/Lt78efIrfhiYz9rRRwi7c78fFERkbZhZncCw5xzV+6zsYiIiIi0KRVZ\nEZE2ExjSeT27qpCJiIiISAfSEE0RaRNmdgN+Ivw7zrmZwY5HJNjMrJ+ZTTezpWa2xMz2qiprZtPM\nbKGZLTKzz83ssAb71ge2zzezpoa8iYiI7EZDNEVERNpBYN3IXs65eWaWCMwFzgusc1nf5ihgmXNu\nu5mdDtztnJsc2LcemOicywtC+CIiEqI0RFNERKQdBCr/bQk8LjazZfg1v5Y2aPN5g0O+APp2aJAi\nItLlaIimiIhIOzOzgcA44Mtmml2PX4aknsMvsjzXzG5sv+hERKQrCbkevPT0dDdw4MBghyEiIh1g\n7ty5ec65jGDHcSDMLAG/fMitzrmiJtpMxSd4xzTYfIxzLtvMugMfmNnyxua3BpK/GwHi4+MnjBgx\nos0/g4iIdC7NnR9DLsEbOHAgc+ZorrmIyMHAzDYEO4YDYWaR+OTuGedco2tDmtmhwCPA6c65/Prt\nzrnswH2Omb0KTAL2SvCccw8BDwFMnDjR6RwpItL1NXd+1BBNERGRdmBmBjyKL6Ly5yba9Mcv6HyV\nc25lg+3xgcIsmFk8cAqwuP2jFhGRUBdyPXgiIiIh4mj8mpCLzGx+YNv/Af0BnHMPAncCacADPh+k\nxjk3EegBvBrYFgE865x7t2PDFxGRUKQET0REpB045z4FbB9tvgl8s5Hta4HD9j5CRESkeV0iwauu\nriYrK4uKiopgh9KuYmJi6Nu3L5GRkcEORUREREQkaHT937QukeBlZWWRmJjIwIEDCQxn6XKcc+Tn\n55OVlUVmZmawwxERERERCRpd/zetSxRZqaioIC0trcv+cQHMjLS0tC7/K4WIiIiIyL7o+r9pXSLB\nA7r0H7fewfAZRURERERa4mC4Nt6fz9hlErxg2rFjBw888ECrjzvjjDPYsWNHO0QkIiIiIiLtpTNf\n/yvBawNN/YFramqaPe7tt9+mW7du7RWWiIiIiIi0g858/d8liqwE2+23386aNWsYO3YskZGRxMTE\nkJKSwvLly1m5ciXnnXcemzZtoqKigltuuYUbb7wRgIEDBzJnzhxKSko4/fTTOeaYY/j888/p06cP\nr7/+OrGxsUH+ZCJyMHLOsa2okiWbCykorSI5NpLk2Ei6xUXtfBwTGYaZUV1bR1F5NYXl1ewI3BeV\nV1NWVcvlk/oH+6NIay15DWKSYPAJwY5ERKRT68zX/0rw2sC9997L4sWLmT9/Ph9//DFnnnkmixcv\n3lnt5rHHHiM1NZXy8nIOP/xwLrzwQtLS0nZ7jVWrVvHcc8/x8MMPc8kll/Dyyy9z5ZVXBuPjiEiI\nc85RVFFDfkkleSVV5JdUUl3niIsMJy46nLioCOKiwgO3CHaUVbFkc1HgVsjSzUXkl1Y1+x5R4WFE\nhhulVbWN7jeDSyf2Iyys68+P6FI+vhfShyjBExHZh858/d/lErxfvLmEpZuL2vQ1R/VO4q6zR7e4\n/aRJk3YrZXrffffx6quvArBp0yZWrVq11x84MzOTsWPHAjBhwgTWr19/4IGLSJdRUlnDtqIK8kuq\nKCj1t+1lVeSXBO5LqygorSSvuIr80kqqa12r3yMy3BjaPZETRnRndO8kRvVOpkdSNEXlNRTu7KWr\n2vm4usYFevQidvbuJcVG0i3O9/IdBHPfu564VCgrCHYUIiKtouv/3XW5BK8ziI+P3/n4448/5sMP\nP2TWrFnExcUxZcqURkudRkdH73wcHh5OeXl5h8QqIsFTUV1LXkklBaU+UatP0nKKKskprmRbUQU5\nxZXkFFU02VMWHxVOakIUqXFRZCREM7JnEmkJ0aQnRJGeEE1a4D4y3Cirqg3caiitrKW8qpbSqhri\noyIY1TuJoT0SiI4I7+BvQTqVuFTIWx3sKEREQk5nuv7vcgleazLttpKYmEhxcXGj+woLC0lJSSEu\nLo7ly5fzxRdfdHB0ItLRyqpqyN5eztaiCnKKKtlWXBFI2nY9zy+poqyJpC0mMoyeSTF0T4xhdO8k\npg7vTo+kaLonRZOeEE1qfBSp8VGkxEURE6mETNpQbCqU5Qc7ChGRVtH1/+66XIIXDGlpaRx99NEc\ncsghxMbG0qNHj537TjvtNB588EFGjhzJ8OHDOeKII4IYqYi0heraOjbvKGdDfhmbtpeRtb2cTQVl\nbNpeTvb2MvJK9p6/lhgdQfekaLonxjC+f8rO3rW0+CjS4qNJDTxOjY8iITrioFjbRzqhuDQoLwDn\n0BhbEZGmdebrf3Ou9fM0gmnixIluzpw5u21btmwZI0eODFJEHetg+qwi7ammto7VuSUsyS5iVU4J\nYQbREeFER4YRHRHmH0eEERFubCmsYEN+GRsLStlYUMbmHRXU1u36f2dEmNEnJZZ+KXH0TYmlX6q/\n75kUQ4+kGLonRRMXpd/T9oeZzXXOTQx2HKGisXNkq3z+d3j/Drh9I8Qkt11gIiJt7GC6Jm7sszZ3\nftQVh4h0aXV1jvzSKrJ3lLN0cxGLNxeyZHMRy7cUUVlTB/jiIkCzhUlS46PolxrHuH4pnHtYHP3T\n4uif6m89kmIIV7VI6QriAgUAygqU4ImIhCgleCIS8qpq6pi3cTuz1xWwtaiCbQ3mu+WWVO7W25YU\nE8Ho3slcfeQADumTzOjeSWSmJxAeZtTWOapq6qisqaWypo7K6jqqauvonhRNUkxkED+hSAeJTfX3\nZQWQmtl8WxER6ZSU4IlIp+CcY1VOCTNX5rImt5SBaXEM7ZHA0O6J9OkWu9d6alnby5ixMpcZK3L5\nfE0+JZU1gO9p654YTfekGIb3SNw5RLJnUgwjeyXRNyW2yflt4WFGbFQ4sVEqXCIHqfoevHItlSAi\nEqqU4IlI0BSWVfPp6jxmrsxl5qpcthT6EsLJsZEUllfvbBcTGcaQ7gkMyUggMSaSz9fksSa3FIA+\n3WI5Z2xvjh+WwVGD00hUT5vI/our78FTJU0RkVClBE9E2kVdndu5HED9+m71j/NLKlmdU8L8TTuo\nc5AYE8ExQ9K55cQMjhuWQe9usewoq2J1Tgmrckp23n+1roCCsiomZaZxxeQBHD8sg8EZ8ao4KdJW\n4hoM0RQRkZCkBE9E2oRzjo0FZXy2Op/P1uQxa00+BaV7LxcQGW6kxkfRp1ss3506hOOGZTC2Xzci\nwsN2a9ctLoqJA1OZODB1r/dRQifSTqKTwcLUgyciEsKU4AVBQkICJSUlwQ5D5IA459hSWMGcDdv5\nbFUen63JI2t7OQA9k2KYOrw74/p3IyMx2q/1FligOynmwNZ4U3In0o7CwrTYuYhIO+jI638leCKy\nT845sneUszi7kMXZRSzKLmRxdiH5gR66xJgIjhqcxo3HDeLoIekMStewSZGQFZeqIisiIiFMCV4b\nuP322+nXrx8333wzAHfffTcRERFMnz6d7du3U11dzT333MO5554b5EhF9lZZU8v8jTvYkF9GYXk1\nheXV7CivorC8ZufzjfmlbC/zRU/Cw4yh3ROYOqI7Y/okc1i/bozpk6x14ES6irg0zcETEdmHznz9\nrwSvDVx66aXceuutO//AL774Iu+99x7f//73SUpKIi8vjyOOOIJzzjlHvRoSdFU1dSzM2sGsNfnM\nWpvP3A3bdy74DRBmkBQbSXKD28mjejCmTzKj+yQzqlcSMZFaRkCky4pNhe3rgx2FiEin1pmv/7te\ngvfO7bB1Udu+Zs8xcPq9Te4eN24cOTk5bN68mdzcXFJSUujZsyc/+MEPmDlzJmFhYWRnZ7Nt2zZ6\n9uzZtrGJ7EN1bR0Lswr5cl0+s9bkM2f9dsqrawEY2SuJaZMHcMSgVEb2SiI5LpKEqIi91pwTkYNI\nXCpkzw12FCIiLafr/910vQQvSC6++GJeeukltm7dyqWXXsozzzxDbm4uc+fOJTIykoEDB1JRURHs\nMOUgUN9D9+W6Ar4I9NCVVfmEbliPBC6Z2JcjB6cxOTONlPioIEcr0nWZWT/gSaAH4ICHnHN/26ON\nAX8DzgDKgGudc/MC+64B7gg0vcc590SHBF4/B8850KgTEZEmddbr/66X4DWTabenSy+9lBtuuIG8\nvDxmzJjBiy++SPfu3YmMjGT69Ols2LAhKHFJ11JcUc07i7eStb2cssoaSqtqKa2soayqhtLKWkoq\na1iVU0xFtR9yOaJnIhdP6MsRg9KYlJlKWkJ0kD+ByEGlBrjNOTfPzBKBuWb2gXNuaYM2pwNDA7fJ\nwD+ByWaWCtwFTMQnh3PN7A3n3PZ2jzouDWqroKoEohPb/e1ERA6Yrv930/USvCAZPXo0xcXF9OnT\nh169ejFt2jTOPvtsxowZw8SJExkxYkSwQ5QQ5Zxj7obtvDB7E28t3LJzeGV8VDhx0RH+PiqC+Ohw\nUuOjuOzw/jsTulT10IkEjXNuC7Al8LjYzJYBfYCGCd65wJPOOQd8YWbdzKwXMAX4wDlXAGBmHwCn\nAc+1e+CxDRY7V4InItKkznr9rwSvDS1atGvsb3p6OrNmzWq0ndbAk5bIL6nklXnZPD97I2tyS4mP\nCue8cb25ZGI/DuvbTfPkREKImQ0ExgFf7rGrD7CpwfOswLamtjf22jcCNwL079//wIONS/P3ZfmQ\nMuDAX09EpAvrjNf/SvBEOomK6loWZRcyb8N2Zq8vYMbKXKprHRMGpPD7Cwdz5qG9iI/WP1mRUGNm\nCcDLwK3OuaK2fn3n3EPAQwATJ050B/yCcYEePK2FJyISknS1KBIkWwrL+WpdAV9v3MG8jdtZurmI\nmjp/bTYgLY6rjxzIZYf3Y2gPDZESCVVmFolP7p5xzr3SSJNsoF+D530D27LxwzQbbv+4faLcw84e\nPCV4IiKhSAmeSAeqqqnjw2XbeO6rjXyyKg+A2MhwDu2bzA3HDWJ8/xTG9e9GuoqhiIS8QIXMR4Fl\nzrk/N9HsDeC7ZvY8vshKoXNui5m9B/zGzFIC7U4BftbuQYMSPBGRENdlEjznXJdfRNzPwZdQtD6v\nlOdnb+KluZvIK6mid3IMt540lJNG9mBEz0QiwsOCHaKItL2jgauARWY2P7Dt/4D+AM65B4G38Usk\nrMYvk3BdYF+Bmf0KmB047pf1BVfaXUwyYH4OnohIJ6br/8a1a4JnZqfh1/cJBx5xzt27x/4BwGNA\nBlAAXOmcy2rt+8TExJCfn09aWlqX/SM758jPzycmJibYocgeauscpVU1lFXWUlZVQ9nOpQtqyS2p\n5PX52Xy2Op/wMOOEEd25YlJ/jhuWQbiKpIh0ac65T4Fm/6EHqmfe3MS+x/DnyI4VFg6xKZqDJyKd\nmq7/m9ZuCZ6ZhQP/AE7GV/+aHVjDp2F56D/iy0M/YWYnAL/F/9rZKn379iUrK4vc3Ny2CL3TiomJ\noW/fvsEOQwJW55Tw2GfreGVe1s515xrTp1sst508jIsn9qNnshJ0EQkBcanqwRORTk3X/01rzx68\nScBq59xagMD8gnPZff2fUcAPA4+nA6/tzxtFRkaSmZl5AKGKtIxzjllr83n0k3V8tDyHqIgwzhvb\nm2E9EneuRRcXFUFcVDhxUeEkREcwKCNBvXUiEhIuf+gLBmXE8+u4NM3BE5FOTdf/TWvPBK+xNXwm\n79FmAXABfhjn+UCimaU55/SzoXQq1bV1/HfhFh75dC2Ls4tIjY/ilhOHctWRA1QQRUS6jLLqWjYW\nlPnFzgtbPWNCREQ6gWAXWfkRcL+ZXQvMxJeFrt2zUZsv4irSiJziCrK3l7OtqIKthRVsKapgW2EF\nW4sqWJ1TSl5JJYMz4vntBWM4f1wfYiLDgx2yiEibykiIIntHBaSlwdaFwQ5HRET2Q3smeE2t7bOT\nc24zvgevfiHYC51zO/Z8oTZfxFUkwDnHjJW5PPLJOj5dnbfbvqjwMLonRdMzKYajBqdx3rjeTBnW\nnTANtxSRLio9IZoFWYUQl6I5eCIiIao9E7zZwFAzy8QndpcBVzRsYGbpQIFzrg6/vk/HVwuTg1Jl\nTS1vzN/MI5+sY8W2YnokRXPbycMY1TuJHkkx9EqOISUuSsmciBxU0hOiKSitoi42jbCaCqgqg6i4\nYIclIiKt0G4JnnOuxsy+C7yHXybhMefcEjP7JTDHOfcGMAX4rZk5/BDNRktFi7SVwrJqnv5yA49/\nvp7c4kpG9EzkTxcfxtmH9SYqQmvRicjBLT0hito6R1l4Egnge/GU4ImIhJR2nYPnnHsbv4hrw213\nNnj8EvBSe8YgArBkcyHPfLmR177OpqyqlmOHpvPnSw7jmCHpXXbtFBGR1kpP9EWjCi2Q4JUXQLd+\nzR4jIiKdS7CLrIi0m4rqWt5auIWnv9jA/E07iI4I4+zDenP9MZmM7JUU7PBERDqd+qrABS6BPqB5\neCIiIUgJnnQ5a3NLeObLjbw0N4vC8moGZcTz/84axUXj+5IcFxns8EREOq36BG9bTTxjQGvhiYiE\nICV40iXkFlfy34WbeWPBZuZt3EFEmHHqIT25cvIAjhiUqmGYIh1pxTuw7C04937Qv72QkhFI8LZW\nB+bdKcETEQk5SvAkZBVVVPPu4q28uWAzn63Oo87BiJ6J/OS04Vw0oS/dE2OCHaIczIq3+eIU0YnB\njqTjFGbDOz+B5W9B91F+eF98erCjklZIio0gKjyMrEqf6GmIpohI6FGCJyHFOcfMVXk8++UGpq/I\npaqmjv6pcXxnyhDOGdubYT0Oootp6bzmPgFv3QoWBv0mw+CpMPhE6HUYhIUHO7q2V1cLXz0M//uV\nf3zS3XDkdyFcQ6JDjZmRlhBFbkkdxCT7IisiIhJSlOBJSNhz3br0hGimTe7POYf1Zmy/bhqCKV5t\ndXCTCudg5h9h+j0w+ASf0K3+CP53j7/FpsKgKX7f6PO6Ru/e5q/hzVthy3wYchKc8UdIzQx2VHIA\n0hOiySuphLg09eCJiIQgJXjSqe0oq+KZLzdq3TrZt0/+BP/7NUQlQHJff+vWL/C4H6QNhl5jWzcn\nrKoU5vwbhpwI3Uc237auFt75Kcx+GA69zM8/C4/0vVklubD2Y1jzP39b8gp89je44gUfV0uU5MDb\nP4LtGyAu1SeLDe/j0iBjOPQ4pGPmvVUWw/TfwJcPQnwGXPRvGH2+5tx1AekJUeQUV/r/tjQHT0Qk\n5CjBk06nrs6xeHMhL8/N4sU5WZRXa906aYZz8NEv4dM/w7DTfVJXmAWFm2DTl1CxY1fb8df4HqaI\nqH2/bvE2eO5S30P1/h1w2GUw5XZIGbh325pKeOUGWPo6HPV9OOkXENbgB4iEDDj0Yn9zzid5L38T\nHp4KFz/ue/Sas+Fz+M91/rMMPAbKt0PBOj98rqJw97YJPX1COvgEf4tL3fdnbQ3nYNkb8M7tULwF\nDr8eTvh/ENutbd9HgiY9IZqlW4ogLc3/jUVEJKQowZNOIbe4kk9W5TJjZS6frMqjoLSKyHDj3LF9\n+OaxmYzoqXXrQk5tDdSUt34YonPg6lo2V805ePd234s04Vo48y+7J1bge5oKs2HBc/DZXyFvFVz6\nVPPFP3KWwzMXQ1keXPAwbF0EXz0Ei16CCdfAcT+GxJ6+bUUhPD8N1n8Cp/wajvpu8zGb+QTsxunw\n3OXw9EVw6m9g8rf27v2qq4PP7/MJbMpAuPIl6Dlm9za1NT7hK8uH7Lmw+kNY8TbMfwYw6DPBD53s\ndzh0G+B7MyP3swDR9vXw9o9h1fvQYwxc8qR/XelSMhKjyS+pwsWmYDlLgx2OiIi0khI8CZp1eaW8\nNHcTM1bmsji7CPBDg44flsHxwzI4dmg6aYGS3RKC3vs/mPcEHPMDOPoWiIzd9zFbFvhhjllzYOI3\nfCKVkNF427paePMW+PopOOJmOPXXjQ8PjE6E7iPg5F/45Oj1m+GhqXD5c9DzkL3br50BL1wFEdFw\n7X+hz3g49BI44jsw8w8w93H4+hmfkB12ObzyTchZ5hPBQy9p+feTMhCufx9e+Ra8+1PYthjO/POu\n3sWyAnjtJlj5Low6F865H2Ia+aEjPMJ/RwkZ/nOOm+a/m81f+2Rv9Ycw8/c+aa6X0AO69d91Sx8G\nfSf54aKNfYc1VTDrfpjxe1845tTfwKRv+feWLic9IZqaOkdlVAoxmoMnIhJyzDkX7BhaZeLEiW7O\nnDnBDkMOwI6yKv720SqemrUBB0zon8Lxw31SN6pXEmFhGoLZoSqKYN1M3yPVd2LbvGZpHvxltJ8X\nVpTtk4hTfwsjzmw8gSjN9xUY5z7uhxRmHu+HO0bGwlHfgyNv3r0nsLYaXv02LH4JjvsJTP2/ls/9\nyp7re9wqiuCCf8HIs3ftm/8cvPE9n+hM+4+Pe08Fa+Hje2Hhi4CDyHi49EnfS7Y/6upg+q/hkz9C\n/yPhkqegcCO8eK0fHnfKPY337rVGWQHkroAdGwO3DbseF2ZBXbVvF5cGfQ+HfpN8wtdnPGyeD//9\nIeQu99/Vaff6eY0dxMzmOufa6D/Mrq8tzpFvLNjM95/7mjnHLSD9q9/Bz7e27AcaERHpMM2dH/Xz\nq3SYqpo6nvpiA/d9tIriimoum9SfH5w0jIxE9dJ1KOcgfzWsfA9WvQcbZu26wD/iZjjxzv0fwldv\n9qNQUwFXvQYlW+Htn8AL0/xSAaf/DtKH+na1NTDnMV91srIEJn/bz3OL7eaHUn70S/j4t74E//E/\ngQnXAc7PR1vxX1/A5JgftC62PhPgxo/h+SvghSth6h1w7G2+l+vj30LmcT7JampOWeoguOAhOPpW\nmPMojJ3mE6H9FRYGJ/4/6D1qBkcAACAASURBVDEKXvsOPHiMn1uX0AO+8W7bJN1xqTDgSH/bU12t\n/643fQlZX8Gmr3yvIYCFg6uF5P5w+Qsw/LQDj0U6vfQE34tcaImkg/+BILlPUGMSEZGWUw+etDvn\nHO8v3cZv317G+vwyjh2azh1njmJ4zy5QIr4p5dth/rOw+BXf25F5nL+lDTmwnpicZTD7ET+XatIN\nrftVfdNXsPhln9htX+e3ZYyEYafAkJN9j9nsh6H7aLjwYegxev9irK6Avx4CvcfDtBf9ttpqH/f0\n30B1ORz5HRh4HHxwJ+Qs8d/N6b9vvFJl1lz48C4/x63bAEjqDRtn+WIpk27Yvxjr43zz+7DwBUgd\nDAVr4LAr4Oy/tawIS3vY/DW8cLX/7s97oO0LpLRUWYEfJrvpS79Y++RvQ1R8UEJRD17rtMU5ctW2\nYk7+y0z+c1wuh391C3z7073nfoqISFCpB0+CZv6mHdz7zjK+WFvA0O4JPH7d4UwZ3j3YYbWf7Lkw\n+zE/dLCmwq+DtukrWPqa35/YCwYeG0j4jm28ImNjtizw87+WvQnh0VBb6QuLTP25r+7YVEES52D9\npzDjdz5Biojx733kzTDs1N2HIGYeC0NP2TVH7aS7/YX9nkVL9mXhC1Cau3uxkfBIOOImOORC+PAX\nfomAz/7me4YuecoP/Wsq8e07Aa55068n9+HdPuk49x8w7srWxbWnyBg4/18+mfroVzDl/3wvYTCr\ntPYeB7cuDP5SA3GpPvEfdkpw45CgSA/Mfc6tDST1mocnIhJSlOBJu5i9voD7PlrFJ6vySI2P4lfn\nHcLlh/cjIryTrl1XVeqHAY65qPXzi6rKfM/Y7Ef8Ys+R8b74xuHX+1+9nfPzttbN9Le102FRoGcr\nub8vez/waH/fbcDuF/dZc3xit/JdiE72882OuAlylvrer9e/44tfnHS3T87qj3XOr7s24/ew8XM/\n3O/U3/oKkM31xAw7Bb4zy89De+9nvlrief+EpF4t+y7q6mDWP/znHnjs3vsTusN5//AFVHKW+u+7\nJb2QZjD0JF/2vyzPv05bMPMFYCbfFLxeuz0FO7mTg15ybCQRYcbW6ji/QWvhiYiEFCV40macc3y+\nJp/7PlrFl+sKSE+I4vbTR3DlEQNIiO7k/6nN+bcfBjjzD35Nr0k37LtMf3W5L53/yZ/9+mQZI/2w\nwUMv3b3aoZkv2pE2GCZe55Ov3BU+2Vv/iZ8Ht+BZ3za5Hww42s+7Wv6WT9JiU+CEO+DwG3bNCxt4\nDHzzI98z+NEv4dlLYMAxcPIv/fDQGb/z86kSe8Ppf4DxV7V8OGd8Olz2rK+A+e7P4J9H+iRv+On7\nPnbNR5C3As5/qPlEpe8Ef2utsLC2S+4a6izJnXQpZvYYcBaQ45zbq2Srmf0YmBZ4GgGMBDKccwVm\nth4oBmqBmo4cphoWZqQlRJFVGfhBTj14IiIhpZNfdUsocM4xfUUOf//far7euIMeSdHcedYoLp/U\nn9ioFqxlFmzO+TXDehziK0m++1M/zPCc+xqfd1JXCwue9/PJirJ8z9nRt8KAo1rW+2Lmy9l3HwGT\nb/S9Xnkr/FDK9Z/A6g9g4fMQ3x1O/pXv7YpOaPx1Rp8PI87y1Sc/vhceCSyYndzPl9wfd6Uv999a\nZn5duQHHwMvXw4tX+4IfffaRlH3+d59Ujj6/9e8p0vU8DtwPPNnYTufcH4A/AJjZ2cAPnHMNu8um\nOufy2jvIxqQnRLOpInCJUL49GCGIiMh+UoInB+TTVXn84b3lLMgqpE+3WO457xAuntiX6IgQSOzq\nbZnvhwue+WefTC1+2S+e/a/j/Vy1Kbf7YY3OwaoP/DywnCW+iMj5D/q5awciLMwXF+k+0vcc1g/p\nTOrdsl638Eh/3GGXwdwnICbZ9yK2Ra9U+hC46lX/XbxwNXxrJsSnNd52y0JYN8MPF1WPmAjOuZlm\nNrCFzS8Hnmu/aFonPSGabaVVEJ2kHjwRkRCjBE/2y/xNO/j9u8v5fE0+fbrF8vsLD+X88X2I7Kxz\n7Jrz9TO++MghF/qeqzEX+bleH94Fn9/nh0Ee+yNY9B/fw5aSCRf92/dStcd8qfohna0Vnbh7YZO2\nEpfq13l79FTfm3fly40PX/3iAT//cMK1bR+DSBdmZnHAaUDDf8AOeN/MHPAv59xDHRlTekI0q7YV\n+3//moMnIhJSlOBJq6zOKeaP763k3SVbSYuP4q6zR3HF5P6h1WPXUHWFT9xGnLX7umdxqXDO332x\nlDdv8eX049L9fLYJ1x58PVS9x8GZf/TFV6b/xq/b1lDRFlj0ki8sE5sSnBhFQtfZwGd7DM88xjmX\nbWbdgQ/MbLlzbmZjB5vZjcCNAP3792+sSaulJ0aRV1KFS0vF1IMnIhJSlOBJi2TvKOevH6zk5XlZ\nxEVF8IOThnH9sZmdv3jKvqx42xdIGTet8f0DjvJrQG34DPpM3L14ysFm/NV+yYdP/uiLwDQsuvLV\nv/yC2JO/Hbz4RELXZewxPNM5lx24zzGzV4FJQKMJXqB37yHw6+C1RUAZCdFU1dZRE5NKZLkSPBGR\nUBLiV+fS3ooqqnlg+hoe+8wvjP2NozP5ztQhpMZ30h6sWf+AeU/5YYTJffbdfv6zkNQHMo9vuk1E\ntB+yKb5K6NaF8Mq34MbpfihpZQnMecz3gqZmBjtCkZBiZsnA8cCVDbbFA2HOueLA41OAX3ZkXPVr\n4VVEJBFZtrIj31pERA6QEjxpVHVtHc9+uZG/fbSKgtIqLhjXh9tOHU6fbi0std/R6urg/Z/7eWDg\n14i76NHmjyna7Mv6H/PDfS+JIF5kDFzypC+68uLVcP0HPkmuKISjvhfs6EQ6FTN7DpgCpJtZFnAX\nEAngnHsw0Ox84H3nXGmDQ3sAr5qf4xsBPOuce7ej4oZdCV5JeDKJZaqiKSISSpTgyW6cc7y/dBu/\ne2c5a/NKOXJQGj8/cySH9EkOdmhNq66A174NS171C1ZHJ/j17A6/3g+xbMqC58HVwdgrOi7WriBl\nIFz4CDxzMbx1qx+22fdw6Dcp2JGJdCrOuctb0OZx/HIKDbetBQ5rn6haJj3Rj9IosiR6VRVDTeX+\nLbkiIiIdTgme7LQ4u5BfvrmUr9YXMKR7Ao9dO5Gpw7tj7VEpsq2U74Dnp8GGT/2acUd9zy9APv85\neOcncOOMxnvn6te+63/U/lWsPNgNPdkvH/Hxb/3zk+4OZjQi0sbqe/AKXGANzrICSOoVxIhERKSl\nlOAJAC/PzeJnrywiKTaCX59/CJdO7EdEZ1/yoDAbnrkI8lbBBY/AoRf77VFxcMqv4KXrYN4Tfm27\nPW36CvJX+wXKZf8c9xPYugi2r4eRZwc7GhFpQylxUYQZ5NXG+w3lSvBEREKFEryDXG2d4/fvLedf\nM9Zy1OA0Hpg2nm5xnbSASkM5y+DpC6GiCK58CQZN2X3/6PNh9qPw0a9g1Hl+2YOG5j8DkXEw+ryO\nirjrCQuDS5+GuhrNYRTpYsLDjNT4aLbWBBI8LZUgIhIylOAdxIorqrn1+fl8tDyHq44YwJ1nj+o8\nC5U7B0XZUJoLpflQlgelebvul73hFye/7m3odejex5vB6b+Dfx3rhxGe8Ydd+6rKYPErPvGLTuy4\nz9QVmUF4ZLCjEJF2kJ4QRXZloLCWFjsXEQkZSvAOUhvzy/jmk7NZk1vKr84dzVVHDgx2SLsUbYHX\nboK10/feFxYBcWnQ81A49x+QMqDp1+l5iB+eOfsRvzh5j9F++7I3oaq46bXvRESEjMRoNpTWJ3jq\nwRMRCRVK8A5CX6zN56an51Ln4MlvTOLoIenBDmmX5W/D6zf7Qikn3gkZI31CF5/u72OSfa9RS039\nOSx+Gd75KVzzpj92/tPQbYAvsCIiIo1KT4hmfm6gcma5evBEREKFEryDiHOO577axJ2vL6Z/WhyP\nXnM4menx7fumOcshazYMP90naU2pKoP374A5j0LPMXDhY5Ax7MDfPy4VTrgD/nsbLH0d+oyHdTNh\nyv/5OWQiItKo9IQotpTW4WITMA3RFBEJGUrwDhIllTXc8eoiXpu/meOGZfD3y8eRHNsBc6fe+bFP\nqCwcBk+FMRfDiDN3n/u2dTG8fD3kLocjv+t77tpyvaUJ18Gcx30COeYiwGDsPpenEhE5qKUnRFNR\nXYdLTVGCJyISQpTgHQSWbC7ku89+zYb8Un50yjBumjKE8LBGhjm+ehNUFMLZf4OEjAN/49J8WP8Z\njJ0GCT1g0Uvw6rd8cZRhp/pkrzALPrgLYrvBla/AkBMP/H33FBbuC648fgZ8+hfIPB669W/79xER\n6ULq18KrjkohWnPwRERChhK8Lsw5x9NfbOBX/11GSlwkz91wBJMHpTXeOH8NLHjWP86eCxc+ApnH\nHlgAK98BVwuTboDe43zPXNZsWPQfWPKqHzIJMOw0XzCluSGcB2rg0TD6Aljyik84RUSkWemJPsGr\niEwmWnPwRERChhK8LqqwvJqfvbKQtxdtZcrwDP508WGkJTQz7PHrp8HC4Ir/wLu3w5PnwJSfwbG3\n7f8aZ8veguR+0Gusf24G/Sb526m/hXUzoKbSz89rTeGU/XX67yBjuNa+ExFpgfQEvyZqaXgyySWb\nghyNiIi0VLtWmTCz08xshZmtNrPbG9nf38ymm9nXZrbQzM5oz3gOFgs27eCsv3/C+0u28bPTR/DY\nNYc3n9zV1viFv4eeAkNPghs/9sMnp/8anr4ASnJaH0RlMaz5H4w4q/HkLTzCD8cccUbHJHcACd1h\nyu1tO79PRKSLygicN4osCcq2BzkaERFpqXZL8MwsHPgHcDowCrjczEbt0ewO4EXn3DjgMuCB9orn\nYDF9RQ6X/GsWdXXwwreO5FvHDyassfl2Da16H0q2wfir/fPoBDj/X3DO/bDxC3jwGF8opTVWfwi1\nlTDy7P37ICIiElSp8VGYQYFLgMpCqK0OdkgiItIC7dmDNwlY7Zxb65yrAp4Hzt2jjQOSAo+Tgc3t\nGE+X9+7irdz45ByGdE/gze8dw4QBKS07cN6TvgjK0FN2bTOD8VfBDf/za889eS58+VDLg1n2JsSl\nQ/8jWvchRESkU4gIDyMlLoq8usByOuXqxRMRCQXtmeD1ARoO2s8KbGvobuBKM8sC3ga+147xdGmv\nz8/m5mfncUifZJ694QhS46NadmDRZlj1ni88Et7Isgk9RsMN02HwCfDBnb4y5r7UVMLK9/3wy/2d\nvyciIkGXnhDFtppAgqdKmiIiISHYKz1fDjzunOsLnAE8ZWZ7xWRmN5rZHDObk5ub2+FBdnYvzN7I\nrS/M5/CBKTx1/eTWrW83/1lwdTDuyqbbRCfAKfdATTnMfmTfr7l2BlQVw8hzWh6HiIh0OukJ0Wyu\njPNPtBaeiEhIaM8ELxvo1+B538C2hq4HXgRwzs0CYoC9auU75x5yzk10zk3MyGiD9dm6kMc/W8dP\nX17EsUMz+Pe1k0iIbkVh1Lo6+PopGHgspA1uvm33kX45g6/+BVVlzbdd9gZEJULmcS2PRUREOp30\nhGg2VsT4J+rBExEJCe2Z4M0GhppZpplF4YuovLFHm43AiQBmNhKf4KmLroX++fEa7n5zKaeM6sHD\nV08gNqqVwyHXfwLb18P4a1rW/uhb/Al+/jNNt6mtgRVv+4XMVa1SRCSkpSdEs64skOBpLTwRkZDQ\nbgmec64G+C7wHrAMXy1ziZn90szqx+7dBtxgZguA54BrnXOuvWLqSv764Up+9+5yzj6sN/+YNp7o\niP2Y6zbvCYjp1vJKl/2PhL6Hw6z7oa628TabvvBJoKpnioiEvPTEKLKr6odoqgdPRCQUtOtC5865\nt/HFUxpuu7PB46XA0e0ZQ1f04uxN/PXDVVw0oS+/u/BQwve1DEJjygp8pcsJ10FkTMuOMfO9eC9c\n6Ydhjj5/7zbL3oTwaBhyUutjEhGRTiU9IZpKoqiLiCVMc/BEREJCsIusSCvNXl/Az19bxLFD07n3\ngjH7l9wBLHwBaqt2rX3XUsPPgLQh8OlfYc/OVudg2Vt+AfPohP2LS0REOo36xc5rolNUZEVEJEQo\nwQsh2TvK+fZTc+mbEsf9l48nIryJP9+m2VC4Zz2bBpzza9/1Hg89D2ldEGHhcNT3YMt8P4evoc1f\nQ1GWhmeKiHQR6YEEryKym+bgiYiECCV4IaKsqoZvPjGHqto6Hr56IslxjSyFUJIDL30DHj0J7j8c\nPr/fFz3ZU/ZcyFkKE1pYXGVPh14G8d3hs7/tvn3Zm2DhvtqmiIiEvPREv6ZqaXiS5uCJiIQIJXgh\noK7OcduLC1ixtYj7Lh/HkO4JezaAuU/A/RN9knXcjyHzWHj/5/DICb5nraF5T0BkPBxy4f4FFBkD\nR3wbVn8IWxfv2r78LRh4DMSl7t/rioh0IWb2mJnlmNniJvZPMbNCM5sfuN3ZYN9pZrbCzFab2e0d\nF/Xu0uJ9D15RWJKGaIqIhAgleCHgvv+t4p3FW/nZ6SOZOrz77jtzV8DjZ8Kb34ceY+Cmz+GEO+Dy\n5+HiJ6B4Kzx8Arz7M6gsgcpiWPQyHHI+RCfuf1ATvwFRCfD5fbviyFup4ZkiIrs8DuxrSMMnzrmx\ngdsvAcwsHPgHcDowCrjczEa1a6RNiIoIIzk2kh0uQT14IiIhol2raMqBe2fRlp0VM795bOauHdUV\n8Omf4ZM/Q1Q8nHM/jLvSV7oEfz/6PBg0BT76BXzxgO/dGzwVqktbvvZdU2JTYMK18MU/fUK5LLDE\n4YgzD+x1RUS6COfcTDMbuB+HTgJWO+fWApjZ88C5wNK2i67l0hOiyK1NgIodfth/uC4dREQ6M/Xg\ndWJLNhfywxcXML5/N359/iFYffJWVwuPnQozfueXKvjuHBh/1a7krqHYbnDWX+Ab7/lEcN6TkDHC\nr2d3oI64yb/nF//01TP7Hg5JvQ/8dUVEDh5HmtkCM3vHzEYHtvUBNjVokxXYFhTpCdFsqwmshVex\nI1hhiIhIC+lnuE4qv6SSG5+cS7e4SB68asLuC5mv+Z+vYnnWX2HidS17wf5HwLc+8fPveo5pPBls\nreS+MOZimPMY1FTASb848NcUETl4zAMGOOdKzOwM4DVgaGtfxMxuBG4E6N+/f9tGCKQnRrO5IN4/\nKcuH+PQ2fw8REWk76sHrhGpq6/jec1+TW1LJQ1dNpHviHguRz3sC4tJh7LTWvXBEFEy6wSd7beWo\n7/nkDjT/TkSkFZxzRc65ksDjt4FIM0sHsoF+DZr2DWxr6nUecs5NdM5NzMjIaPM4MxKi2VQROA+p\n0IqISKenBK8T+sN7K/h8TT6/Pu8QxvRN3n1nSQ6seAfGXu4TtmDrMRpGnAV9JkDa4GBHIyISMsys\npwXG3pvZJPw5OR+YDQw1s0wziwIuA94IVpzpCVFkVwWGaKrQiohIp6chmp3Mfxdu4V8z13LlEf25\neGK/vRsseA7qamDc1R0fXFMu+je42mBHISLSqZjZc8AUIN3MsoC7gEgA59yDwEXATWZWA5QDlznn\nHFBjZt8F3gPCgcecc0uC8BEAPwdvhwssz6PFzkVEOj0leJ3Iqm3F/PilBYzr3407zxq9dwPnfJGU\n/kdCxrCOD7ApnaEnUUSkk3HOXb6P/fcD9zex723g7faIq7XSE6IpILCsjnrwREQ6PQ3R7CSKKqr5\n1lNziYuK4J/TJhAV0cifZuMsyF8N467q+ABFROSglJ4YTTnR1IZFaQ6eiEgIUILXCdTVOW57cQEb\nC8p4YNp4eibHNN5w3lMQlejXtxMREekAGYnRgFEZ1U0JnohICNAQzU7ggY9X88HSbdx51igmZaY2\n3qiiEJa8Codd5tezExER6QBp8X4Yfll4MnEr3oZnL4XEnpDYK3Df29+nD4XI2CBHKyIiSvCC7OMV\nOfzpg5WcO7Y31x09sOmGi16CmnIY34mKq4iISJcXExlOYkwEM9Mv54KoL6AoG7LnQmnu7g0HHgvX\nvhWcIEVEZCcleEG0tbCCW56fz/Aeifz2gjFYc4uPz3sSeoyB3uM6LkARERH8WngfRU/lgitu27Wx\npgpKc6B4K8x+BBa+6EebxCQ3/UIiItLuNAcvSJxz/PzVRVTW1PLAtPHERTWTa29ZAFvm+9675pJA\nERGRdpCeEE1eceXuGyOiILkv9J0IY6f55XLWfxacAEVEZCcleEHy2vxsPlqew49OGc6gjITmG897\nCsKj4dCLOyY4ERGRBtITo8grqWy6Qb9JEBELaz/usJhERKRxSvCCIKe4grvfWMr4/t24LnOHH9LS\nlOpyWPQijDoHYlM6LkgREZGA9IRo8kqqmm4QEQ0DjlSCJyLSCSjB62DOOf7fa4spr67lT2f0IvzR\nE+Efk2FZExPTl73pE0AVVxERkSBJT4imsLyaqpq6phsNmgJ5K6BoS0eFJSIijVCC18HeWriF95Zs\n44cnDyMzLAdcHdRWwwvT4MWroXjb7gfMexJSMmHAMcEJWEREDnrpCdEA5Jc2M0xz0BR/v25Gu8cj\nIiJNU4LXgfJLKrnrjSUc1jeZbx6TCTs2+R1Xvw4n3gkr3oV/HO6TOucgfw2s/wTGXwVh+lOJiEhw\npCf4tfDyipsZptljDMSmapimiEiQaZmEDnTnG0soqajhDxcfRkR4GBRu9DtSM+HY22DkufDm9+GN\n78Gi/0BSH7BwOOyK4AYuIiIHtfRE34PXbKGVsDDIPA7WzvA/Uqrqs4hIUKhbqIO8u3gL/124he+f\nOIRhPRL9xsIs/2tnVLx/nj4ErnkLzvorbJ4PC56DYadCUq/gBS4iIge9jMAQzdzmEjzwwzSLN0Pe\nqnaPSUREGrfPBM/MvmdmKt94ALaXVnHHa0sY3TuJbx0/eNeOHZugW7/dG4eFwcTr4OYvYfJNcMId\nHRusiIjIHurn4DXbgwe75uG1dJhmXS3U7OM1RUSkVVrSg9cDmG1mL5rZaWYac9Fav3xrKTvKqvjD\nRYcRGd7gKy/cBMn9Gj8oqTecfi/0GN0xQYqIiDQhNiqc+Kjw5ufggZ9y0G1AyxO8t38ED0094PhE\nRGSXfSZ4zrk7gKHAo8C1wCoz+42ZDW72QAHgk1W5vPp1Nt+ZOoRRvZN27XAu0IPXP3jBiYiItFB6\nYvS+e/AABh0P6z+F2prm2xVtgXlPQc5SqK5omyBFRKRlc/Cccw7YGrjVACnAS2b2+3aMLeRV1dRx\n1xtLGJgWx81T98iHy7dDdWnTPXgiIiKdSJ9usazYWrzvhoOmQGUhbJnffLuvHoK6asDBjo1tEKGI\niEDL5uDdYmZzgd8DnwFjnHM3AROAC9s5vpD22GfrWJtbyl3njCY6Inz3nfUnsz3n4ImIiHRCp47u\nyYptxSzfWtR8w8zj/f3a6U23qSyBOY/54ZwA29e3SYwiItKyHrxU4ALn3KnOuf8456oBnHN1wFnt\nGl0I21JYzn0freLkUT2YOrz73g0KA2vgqQdPRERCwJmH9iI8zHh9/ubmG8anQ88xfrmEpsx/Bip2\nwKm/8c+V4ImItJmWJHjvAAX1T8wsycwmAzjnlrVXYKHuN28vp7bOcedZoxpvsEMJnoiIhI70hGiO\nHZrOG/M3U1fnmm+ceTxs+hKqyvbeV1cLXzwAfSfBiDMhMk4JnohIG2pJgvdPoKTB85LANmnC52vy\neHPBZm6aMph+qXGNNyrM8ie1uNSODU5ERGQ/nTe2D9k7ypmzYXvzDQdNhdoq2Dhr733L3/IJ3VHf\n9YuhpwyE7evaI1wRkYNSSxI8CxRZAXYOzYxov5BCW3VtHXe/sYS+KbF8+/hmCo0WbvS9d1p1QkRE\nQsTJo3oQGxnOa/Ozm2844EgIi2x8uYTP/+6TuhGBWR4pmerBExFpQy1J8Naa2ffNLDJwuwVY296B\nhaonZ21g5bYS7jxrFDGR4U03bGyRcxERkU4sPjqCU0b34O1FW6iqqWu6YVQ89JsM6/aYh7fxS8ia\nDUfcDGGBc2TKQJ/guX0M+xQRkRZpSYL3beAoIBvIAiYDN7bkxQMLo68ws9Vmdnsj+/9iZvMDt5Vm\ntqM1wXc2OcUV/PWDlUwZnsHJo3o037i5Rc5FREQ6qfPG9mFHWTUzVuY233DQ8bBlIZTm79r2+X0Q\n0w3GTdu1LWUgVJdB6T5eT0REWqQlC53nOOcuc851d871cM5d4ZzL2ddxZhYO/AM4HRgFXG5mu1Uc\ncc79wDk31jk3Fvg78Mr+fYzO4d53llNZU8ddZ4/Gmht6WVUKZfnqwRMR6cLM7DEzyzGzxU3sn2Zm\nC81skZl9bmaHNdi3PrB9vpnN6bio9+2Yoemkxkfte5jmoCmAg/Uz/fP8NbD8v3D49b6Hr17KQH9f\noHl4IiJtoSXr4MWY2c1m9kDgZPWYmT3WgteeBKx2zq11zlUBzwPnNtP+cuC5loXd+cxZX8Ar87K5\n4bhMMtPjm29cmOXvk/u3f2AiInLAzGywmUUHHk8JTF3oto/DHgdOa2b/OuB459wY4FfAQ3vsnxr4\nEXTi/sbdHiLDwzjr0F58uHQbxRXVTTfsPR6iEnfNw/vinxAeCZP2GASUmunvNQ9PRKRNtGSI5lNA\nT+BUYAbQFyhuwXF9gE0NnmcFtu3FzAYAmcD/WvC6nU5tnePO15fQOzmGm6cO2fcB9UskqAdPRCRU\nvAzUmtkQfCLWD3i2uQOcczNpsMxQI/s/d87Vl6P8An9+DQnnju1NZU0d7y3Z1nSj8AjIPNavh1dW\nAF8/DWMugcSeu7dL7gfY/2fvvuOrLO//j7+u7L0TAmEl7D2MKOBe4F5Vwbpaq9Wvba22tVv7tbXa\n8W1rHbVqrdSfiqMOVBQXTlQ2CAiyIQmQhAyy5/X74zqBELLJyUly3s/H4zxOzn3f5z6f3CScfM51\nXZ+PEjwRkS7SngRvuLX210CZtXYecC5uHV5XmgO8aK2ta26nMeZGY8xyY8zyvLyeN0f/5VXZbNhz\ngF+cO4aIkHYUGC3eBLQ/ZwAAIABJREFU5e61Bk9EpLeot9bWAhcDD1hrfwL078LzX4/rO9vAAm8b\nY1YYY1pd9+6L98ipg+MZlBDOq21N00w/2bVAePcuqK2A6bcceUxwGMQMUKsEEZEu0p4Er2H+RZEx\nZjwQC6S043nZuE84Gwz0bGvOHFqZnmmtfdRam2mtzUxOTm7HS3ef2rp6Hnh/M+MGxHDuhHa+1xft\nhoCgIz/FFBGRnqrGGDMXuBZ43bMtuCtObIw5FZfg/bTR5hOstVNx69hvMcac1NLzffEeaYzhwklp\nfLoln9ySypYPzDjF3a/8Dww7HfqNbf44tUoQEeky7UnwHjXGxAO/AhYAG4A/tON5y4ARxph0Y0wI\nLolb0PQgY8xoIB5ophtqz/fSqmx27i/nh2eMbL2wSmPFWe7TyoBW2iiIiEhP8i1gOnCPtXa7MSYd\nt4ThqBhjJgKPAxdaaw+Wm7TWZnvuc4GXcevae5SLpgyg3sLra/a0fFDyKIjyfJg54/stH9fQKkFE\nRI5aqwmeMSYAOGCtLbTWfmStzfBU0/xnWyf2TGX5HrAI+Ap43lq73hhztzHmgkaHzgHmN26m3lvU\neEbvJqTFcsaY9gxqehTvVoEVEZFexFq7wVr7A2vts54PPaOtte35sLNFxpjBuOrRV1trv260PdIY\nE93wNXAW0GwlTl8anhLNuAExrU/TNAbGXwqDZxwazWtO/FAo2QM1FV0cpYiI/2l1wZi1tt4Ycwfw\nfGdObq1dCCxssu3OJo9/05lz9wQvrcxid0EFv7m2jbYITRXtdgvPRUSkVzDGfABcgHvfXAHkGmM+\ntdbe3spzngVOAZKMMVnAXXimdVprHwHuBBKBhz3vIbWeipn9gJc924KAZ6y1b3nnOzs6F01O456F\nX7E9v6zlCtKzf9/2iRpaJRTuhJTRXRafiIg/akdFEN41xvwYeA4oa9horW2xMpg/qK6t54H3tzBp\nYCynje7A6F1dDZTkqMCKiEjvEmutPWCM+Q7wH2vtXcaYta09wVo7t4393wG+08z2bcCkI5/R85w/\naQC/f/MrXlmVzW1njuz8iRq3SlCCJyJyVNqzBu8K4BbgI9ynliuAHtV01Rf+uzKLrMKKjq29AziQ\nA7ZeLRJERHqXIGNMf+ByDhVZ8XupsWFMz0jk1dXZHNVKi4MjeDu6IiwREb/WZoJnrU1v5pbRHcH1\nVNW19Tz4/hYmD4rjlFEdrFhW7OmBpxE8EZHe5G7cmvKt1tplxpgMYLOPY+oRLpqcxo795azJKu78\nSSISISRKrRJERLpAm1M0jTHXNLfdWvufrg+nd3hhxW6yiyq45+LxHRu9g0ZNzlVkRUSkt7DWvgC8\n0OjxNuBS30XUc8yekMqvXl3HK6uymTwornMnMUatEkREukh7pmge2+h2IvAb3EJzv1RVW8dD729h\nyuA4Th7ZiX5DDSN4MWldG5iIiHiNMWagMeZlY0yu5/ZfY8xAX8fVE8SEBTNrXCr/XZFFUXl1508U\nP0QJnohIF2jPFM3vN7rdAEwForwfWs/0/PIscoorua2ja+8aFO2CyBQIDuv64ERExFv+jevlOsBz\ne82zTYDvnzac0upaHvlwW+dP0tALr/d1TRIR6VHaM4LXVBmQ3tWB9AZVtXU8vHgLxwyJ58QRSZ07\nSXGWCqyIiPQ+ydbaf1traz23J4FOTOPom0b2i+bCSQN4csl2cksqO3eS+KFQWwkle7s0NhERf9Nm\ngmeMec0Ys8Bzex3YBLzs/dB6nueW7WbP0YzegafJuRI8EZFeZr8x5ipjTKDndhWw39dB9SQ/PGMk\nNXWWhxdv7dwJGrdKEBGRTmtPH7w/N/q6Fthprc3yUjw9VmVNHQ8t3sKxQ+OZOTyxcyex1o3gjTq7\na4MTERFv+zbwAPBXwAJLgOt8GVBPMzQpksszB/LMF7u44aQM0uLCO3aC+EYJ3pDpXR6fiIi/aM8U\nzV3AF9baD621n+I+xRzq1ah6oLfW7WXfgSp+cPqIzo/eleW56SexqqApItKbWGt3WmsvsNYmW2tT\nrLUXoSqaR/j+aSMA+Pu7neggETsITIBG8EREjlJ7ErwXgPpGj+toVCraX7y2JocBsWHMHNbM2rua\nSnj/Hqgoav0kB1skaIqmiEgfcLuvA+hpBsSF883jB/Piyiy255d17MlBIRAzUL3wRESOUnsSvCBr\n7cG6x56vQ7wXUs9TXF7DR5vzOHdifwICmhm92/YBfPRHWPNsGyfa5e61Bk9EpC/o5HSOvu1/ThlO\nSGAAf33n644/Wa0SRESOWnsSvDxjzMG+d8aYC4F874XU8yxav5eaOsv5kwY0f8CeNe7+67daP5FG\n8ERE+hLV829GcnQo180cymtrc9i490DHntzQKkFERDqtPQneTcAvjDG7jDG7gJ8C3/VuWD3La2tz\nGJIYwYS02OYP2LPa3e/4FCpbeTMr3g2hMRDWwnlERKRHMcaUGGMONHMrwfXDk2Z896QMokKC+L+3\nOziKl5AOpfuguoPTO0VE5KD2NDrfaq09HhgLjLXWzrDWbvF+aD1DfmkVS7bu57yJ/VsurpKzGuKG\nQH0NbFvc8smK1CJBRKQ3sdZGW2tjmrlFW2vbU4naL8VFhHDDSRm8s2Efq3e3sT69sfih7r5wp1fi\nEhHxB+3pg/d7Y0yctbbUWltqjIk3xvyuO4LrCd5ct5e6+lamZ5bmQkkOHHs9hMXB14taPpmanIuI\niJ/49gnpJESG8H9vb2r/kw4meDu8EZKIiF9ozxTNs621Bz9+s9YWAud4L6Se5fU1OYxIiWJUv+jm\nD2hYf5d2DIw40yV49fXNH1u8SyN4IiLiF6JCg7j55GF8vDmfz7e1syd8vJqdi4gcrfYkeIHGmNCG\nB8aYcCC0leP7jL3FlSzdUcB5Ewe0PD2zYf1d6gQYORvK8yFn5ZHHVR6AymKN4ImIiN+4evoQUqJD\nue/NjdTVt6MmTXg8hMaqVYKIyFFoT4L3NPCeMeZ6Y8x3gHeAed4Nq2d448s9WAvnTerf8kE5qyFh\nmCucMuw0MIHNV9Ms9lTQ1AieiIj4ibDgQH529mhW7y5i3pIdbT/BGLVKEBE5Su0psvIH4HfAGGAU\nsAgY4uW4eoTX1+YwbkAMw5KjWj5oz1roP8l9HZEAg49vPsE72CJhcNcHKiIi0kNdPCWNU0cl88dF\nG9nRnubnapUgInJU2jOCB7AP1+/nMuA04CuvRdRD7C4oZ9WuIs6b2EoV7PICt65uwORD20bOgr1f\nQnH24cdqBE9ERPyQMYZ7L5lIcGAAd/x3LfVtTdVMSHdVNFtazy4iIq1qMcEzxow0xtxljNkIPADs\nAoy19lRr7YPdFqGPvL52DwDnTWxlembD+ruGETxw6/AANjepplm0CwJDIDK5C6MUERHp+VJjw/j1\nuWNZur2A//dFGy0Q4odCXRWU7OmW2ERE+prWRvA24kbrzrPWnmCtfQCo656wfO/1tTlMGRzHoISI\nlg/KaSbBSxrp3pyatkso3g2xAyGgvYOmIiIifcdlmQM5aWQy9725kd0F5S0fqFYJIiJHpbVs4xJg\nD7DYGPOYMeZ0oIVSkn3L1rxS1uccaH16JrgRvLghrupXA2PcKN62D6C60RuYmpyLiIgfM8Zw3yUT\nCDCGO15sZaqmEjwRkaPSYoJnrX3FWjsHGA0sBn4IpBhj/mGMOau7AvSF19fswRg4d0Ir0zPB9cBr\nvP6uwchZUFsJ2z86tE1NzkVE/I4x5gljTK4xZl0L+40x5u/GmC3GmLXGmKmN9l1rjNnsuV3bfVF7\nz4C4cH557hg+27afZ5buav6g2EGuIrVaJYiIdEp7qmiWWWufsdaeDwwEVgE/9XpkPmKt5bW1OUwb\nmkBqbFjLB1YUuk8XG0/PbDBkJoREHaqmWVsFpXshVhU0RUT8zJPA7Fb2nw2M8NxuBP4BYIxJAO4C\njgOmAXcZY+JbOklvMufYQZwwPIl7F35FVmEzUzUDg92ShtZG8FY/A09dArXVXotTRKS36tCCMGtt\nobX2UWvt6d4KyNc27SthS24p501qa3rmWnffv5kRvKBQGHaqW4dnrRu9A43giYj4GWvtR0BBK4dc\nCPzHOp8DccaY/sAs4B1rbYG1thDXg7a1RLHXcFU1JwDw85e+xNpmpmq21iohZzW8ditsfQ+2vOu1\nOEVEeitV/GjitTU5BAYYzh6f2vqBBytoNpPggVuHV5LjaZmgFgkiItKsNGB3o8dZnm0tbe8TBiVE\n8LNzxvDx5nyeW7b7yAMS0ptP8CoPwAvXuYrUEUmw5llvhyoi0usowWvEWsvra/cwY1giSVGhrR+8\nZ41L2CITm98/wrNM8etFjZqcK8ETEZGuZYy50Riz3BizPC8vz9fhtNs3pw1mekYid7++gS25JYfv\njB8KZXlQ1Wi7tW7krmgXXPovmHi5WwpR3toAqYiI/1GC18i67APs3F/O+W1VzwQ3RaS59XcNolIg\n7Rj35lO8GzAQ02c+fBURka6RDTT+9G+gZ1tL24/gWTqRaa3NTE7uPb1WAwIMf7liEhEhgdz41ApK\nKmsO7TxYSbNRz7wVT8L6l+C0X8KQ6TBpLtRVu20iInKQErxG1uUUAzBjeAujcg0qD0DB1panZzYY\nORuyV0D2Soju7xaOi4iIHLIAuMZTTfN4oNhauwdYBJxljIn3FFc5y7OtT+kfG84Dc6eyc385d7y4\n9tB6vKatEvaug7d+BsNOg5m3uW2pEyBlHKyZ391hi4j0aErwGskurCAwwJAa00r1TIC9ngIrzbVI\naGzkLMC6ReCaniki4neMMc8CnwGjjDFZxpjrjTE3GWNu8hyyENgGbAEeA/4HwFpbAPwWWOa53e3Z\n1udMH5bIz2aP5s11e/nnR9vcxvh0d1+4HapK3bq7sFi4+FEI8PzpYgxMmgNZyyB/i09iFxHpiYJ8\nHUBPkl1UQWpMGEGBbeS9OQ0FVlqZogmQOtGN3JXsUYEVERE/ZK2d28Z+C9zSwr4ngCe8EVdP850T\n01m9u4g/vrWRiWmxzBieBGFxULAd3viRmzVzzasQ1WQK6oTL4N27YO18OO1XvgleRKSH0QheI1mF\n5QyMD2/7wD1rIHqAW2fXGmM8o3hoBE9ERKQFxhj+8I2JZCRH8b1nV5FTVOGmaa570SVvJ/8U0k86\n8okx/SHjVFjzHNTXd3vcIiI9kRK8RrILK0hrV4LXRoGVxkZ62hZpBE9ERKRFUaFBPHLVMVTX1nPz\n0yupix8KlcUw9EQ46SctP3HSXCjeBbuWdFusIiI9mVcTPGPMbGPMJmPMFmPMz1o45nJjzAZjzHpj\nzDPejKc1NXX17D1QycC4NhK8qlLI39z2+rsGw06HE38EY84/+iBFRET6sOEpUfz5soms2V3EW0UD\n3WyZSx6DgMCWnzT6XAiJUk88EREPryV4xphA4CHgbGAsMNcYM7bJMSOAnwMzrbXjgB96K5627C2u\npN7S9gje3i8B2/4RvKAQOP3OtqdzioiICLPH9+emk4dxy7YZvHDiQjcNszUhETD2Ilj/KlSXd0+Q\nIiI9mDdH8KYBW6y126y11cB84MImx9wAPGStLQSw1uZ6MZ5WZRdVAJAWF9H6gXvWuPu2WiSIiIhI\np/z4rJHMHJ7IL1/dyLId7SgeOmkOVJfApoXeD05EpIfzZoKXBuxu9DjLs62xkcBIY8ynxpjPjTGz\nvRhPq7IKXYLXZpGVPashql/bnyiKiIhIpwQFBvDg3KkMjA/nhv8sZ2teaetPGDITYgdrmqaICL4v\nshIEjABOAeYCjxlj4poeZIy50Riz3BizPC8vzyuBZHsSvP5xbfTA27Om/dMzRUREpFPiI0N48lvT\nCDSGb/17GfmlVS0fHBAAk66Are/DgT3dF6SISA/kzQQvG2hcOnKgZ1tjWcACa22NtXY78DUu4TuM\ntfZRa22mtTYzOTm56e6uCbaonJToUEKDWlnIXV0OeRs1PVNERKQbDE6M4PFrM8ktqeQ785ZTUV3X\n8sET54Cthy9f6L4A21JVAs9dDbkbfR2JiPgRbyZ4y4ARxph0Y0wIMAdY0OSYV3CjdxhjknBTNrd5\nMaYWZRe1o0XCvnXuzUMjeCIiIt1iyuB47p8zhTVZRfzwuVXU1dvmD0waDgOPddM0bQvHdLe1z8NX\nC2DlPF9HIiJ+xGsJnrW2FvgesAj4CnjeWrveGHO3MeYCz2GLgP3GmA3AYuAn1tr93oqpNVmFFaS1\n1SKhocBKe1skiIiIyFGbNS6VX587lkXr9/G7Nza0fOCkOZC7wVPxugdoSOw2vdlzkk4R6fO8ugbP\nWrvQWjvSWjvMWnuPZ9ud1toFnq+ttfZ2a+1Ya+0Ea+18b8bTkvp6y56iSgbGt1FBM2c1RCRCTNNa\nMSIiIuJN3z4hnW/NHMq/P93BE59sb/6gcZdAQDCs8cmfE4fLWe0+GE6dAIXbXQ9dEZFu4OsiKz1C\nXmkV1XX1TAzYCvcMgCfPg8//AQVN3kD2rHHr74zxTaAiIiJ+7FfnjmXWuH789o0NvLVu75EHRCTA\nqNmw9jnI/ar7A2xs5TwICoOL/+kef/2mb+MREb+hBI9DLRIyarZCTRkcyIa3fgZ/nwwPT4f37oad\nSyDvK62/ExER8ZHAAMPfrpjCpIFx3Dp/FUu3N9Mjb8atUF8D/5gJC38C5e3oo5e/GV69Bf46AQq6\noBRAdRmsfcE1YO83DvpNgE1vHf15RUTaQQkeh5qcJwUccBv+53P4wSqYda+bkvnJ3+DfZ0N9rdbf\niYiI+FB4SCD/ujaTtPhwrp+3jA05Bw4/YNCx8P1VcMx1sOxxeGAqfPEo1NUeebKcVfD8NfDgsfDl\ni1CSA1/88+iDXP+ya7x+zLXu8ajZsPvz9iWbIiJHSQkekFVYDkBsXSGExUJQKCRkwPT/getehzu2\nwiWPwcxbYfgZPo5WRETEvyVGhfLU9ccRFRrENU8sZUd+2eEHRCbCeX+Bmz5xa+De/Ak8coLrk2ct\nbP8I/nMRPHoKbP0ATrwdfrgOxl8Kq56GygPNvWz7rZgHSSNh8HT3eORsV4V7y7tHd14RkXZQgodr\nch4fEUxw5X6IbKbPXng8TLwczrwbQiK7P0ARERE5TFpcOE9dfxz11nLVv75g34HKIw/qNw6uWQBX\nPA21FfDUxXD/RJh3PuxbD2f8Bm77Ek6/E6KS4bjvupG31c90PrDcryBrKUy95tCa/QFT3d8XX2ua\npoh4nxI8GvXAK8tvPsETERGRHmd4ShRPfutYCsuqufpfX1BUXn3kQcbAmPPglqUuoYsZCOf+BX74\nJZxwm5u50yDtGBg4DZb+E+rrOxfUinmukuekuYe2BQTAiFmw+V2oq+nceUVE2kkJHm4ELy0uHEpz\nleCJiIj0IhMHxvHYNZnsyC/nW08uo7y6mbV24JZfnHAbfPtNOPZ6CA5r/rjjb3KFVja/3fFgaiph\n7XyXUEYmHb5v1GyoKoZdn3f8vCIiHeD3CZ611tPkPALK8pTgiYiI9DIzhifxwJVTWLO7iO8+tYKq\n2rrOn2zMBRA9AL54pOPP/eo1qCiEqdceuS/jVAgM0TRNEfE6v0/wCstrqKipY2BsMFQUKMETERHp\nhWaNS+W+Syfy8eZ8bn9uDTV1nZxiGRjsRvi2LYbcjR177sp5EDcE0k8+cl9oFAw9UQmeiHid3yd4\n2Z4eeOnh7p4oJXgiIiK90eWZg/jVuWN448s9fGfecsqqWpiu2ZZjroPAULcWr732b4UdH7viKgEt\n/Hk16mzYvwXyt3QuLhGRdlCCV+RaJAwK9ZRY1gieiIhIr/WdEzO495IJfLIlnyse/Yzckmaqa7Yl\nMgkmXAZr5rspl+2xch6YQJhyVcvHjJzl7jWKJyJe5PcJXpZnBC810NPzJjLFh9GIiIjI0Zo7bTCP\nXXMMW3PLuOThJWzNK+34SY77LtSUw8qn2j62ttq1Vhg5G6JTWz4ubjCkjFOCJyJepQSvsILIkEAi\naz2f0GkET0REuogxZrYxZpMxZosx5mfN7P+rMWa15/a1Maao0b66RvsWdG/kvd9po/sx/8bjqaiu\n49J/LGHFzoKOnaD/RBgyE5Y+BnVtTPX8+k1XqO2YZoqrNDVyFuxcAhVFbR8rItIJfp/gNfTAM2X5\nbkPTssYiIiKdYIwJBB4CzgbGAnONMWMbH2Otvc1aO9laOxl4AHip0e6Khn3W2gu6LfA+ZNKgOF76\nnxnEhQdz5WNf8Na6vR07wXE3QfEul8C1ZsU8iEmD4We0fc5RZ4Otgy3vdiwW6V1qKuCl78KeNb6O\nRPyQEryGHnhlua58ceOGpyIiIp03Ddhird1mra0G5gMXtnL8XODZbonMjwxJjOS/N89gTP8Ybn56\nBfOW7Gj/k0edA7GD4PMWWiaUF8CHf4Kt77u1dwGBbZ8z7RiISISvF7U/ju7w2cPtm44q7bP8364n\n4tJHfR2J+CEleEUVDIyPgLJ8Nz3TGF+HJCIifUMasLvR4yzPtiMYY4YA6cD7jTaHGWOWG2M+N8Zc\n5L0w+77EqFCeveF4Th+dwl0L1vPD+asoqaxp+4mBQTDtBtj5Cez98tD24ix46+fw1/Gw+Hcw4iw3\n2tceAYEwYpZrpN7W1M/uUrAN3v4VvP1LN/IkR6e6DD75i/t601tQfxR9GUU6wa8TvJLKGoorakiL\nD4fSXE3PFBERX5kDvGitbfyX4BBrbSZwJfA3Y8yw5p5ojLnRkwguz8vL645Ye6XwkED+eXUmt50x\nkgVrcjjn7x+zclc7KmROuRqCwl3j830b4OWb4P5J8MU/Ycx5cPMS+ObzEJHQ/mBGzoLKIsha2vlv\nqCt99H9g66GyGDa86utoer+lj7o1mcfdBOX5kLXM1xGJn/HrBC+7yH1K5aZo5qmCpoiIdKVsYFCj\nxwM925ozhybTM6212Z77bcAHwJTmnmitfdRam2mtzUxOVqGw1gQGGG49YwTPf3c69fVw2SOf8dDi\nLdTV25afFJEAk+a4Kpn/mO4SoGO/A7euhksehX7jOh7IsNMgIBg2tbG2rzsUbIM1z7pkJCHDrSeU\nzqs8AJ/e70Z1T/2F+3fe+IavoxI/498JnqdFQlp8+KEpmiIiIl1jGTDCGJNujAnBJXFHVMM0xowG\n4oHPGm2LN8aEer5OAmYCG7olaj+QOTSBhbeeyOzxqfxp0Sa++fjn7C1upV/ejO9D/0lwys/htvVw\n9h9cy4POCouBoSccvg7PWtcsfeV/XHGOv0+FJ8+DD/7gqm7WVnX+9Vrz8f9BYDCc8EOYei3sWgJ5\nm7zzWv7g83+43omn/sLVdRh6Amxa6OuoxM8E+ToAX2oYwRsYG+aKrEQpwRMRka5hra01xnwPWAQE\nAk9Ya9cbY+4GlltrG5K9OcB8a23jYaQxwD+NMfW4D2Pvs9YqwetCseHBPDh3CiePTOY3C9Yz+/6P\n+MOlE5k1rpk+donD4MYPujaAkbPhrZ+6BGvvOpfElXqqfEYkwaDjXAXPD+6FD37vpokOmgZDT3RJ\nQ1CoW15Sus9zv9d9XbYfpl4Dk+e2HUPBdlj9LEy70fXvm3wlvP9bl2TOuqdrv19/UF4Anz0Io8+D\nAZ4B99HnwsIfQ/5mSBrh2/jEb/h3gldYQUhQAEnBVVBXrRE8ERHpUtbahcDCJtvubPL4N808bwkw\nwavBCcYYLs8cROaQeH4wfxXffWoFc44dxK/PG0tkqJf/RBo1G976Gbx3N0T3d0nb0Jkw5ASXCDQU\nfSsvcMnfjk9gx8euqEtzwuMhqp/7e+bVWyB+KAyZ3noMH//50OgdQFSKS0hWPwOn3+mSSGm/JQ9A\nVYkbvWsw6myX4G1849B1FvEyv07wsjwtEgIq9rsNSvBERET8TkZyFC/dPJO/vPM1//xoK0u27uev\nV0zimCEdKJzSUfFD4Yb3ITwO4tNbruIdkeCKuYw5zz0uL4Bdn7uvo/q5pCwq5VAyVlkMj54CL1wH\nN33s9jWn6ehdg6nXunWGX70GE77RBd+onyjNc4V3xl9y+LrM2IGQOtFN01SCJ93Er9fgZRV5euCV\n5roNSvBERET8UkhQAD87ezTP3Tidemu57JHP+POiTdTU1XvvRdOmusImHWnRFJEAo89xt4HHQNyg\nw0fawmLh8v+4Kp3/vb7lEv1NR+8aZJzq1heueLLD345f+/RvUFvh1mk2Nfpc2L300N+bIl7m1wne\noSbnnrLSSvBERET82rT0BN689UQumTqQBxdv4ZKHl7Alt8TXYXVM6gQ49y+w/SNY/Psj9xdshzXz\n4ZhvHT56BxAQ4Nbw7fjYFX2Rth3YA8seh4lzml9nN+ocwMLXb3V7aOKf/DbBq6ypI7+0ylNB0/OJ\nSkvTGERERMRvRIcF8+fLJvHIVVPJKizn3L9/wpOfbqe+tXYKPc2Ub7oefh//+fBqneAKu5hAmHlr\n88+dfJXbv1ItE9rl4/+D+lo4+Y7m96dOgNjBsFHVNKV7+G2Cl9NQQbOhRQJARKIPIxIREZGeZPb4\n/iy67SRmDEvkN69t4LwHPuGTzfm+Dqv9zvmTSy5euhEKd7ptBdtd37vMb0FM/+afF9PfVflc/QzU\nVndfvL1R0S43nXXK1ZCQ3vwxxrhiK9sWQ3VZt4Yn/slvE7yswiZNzsPj3Vx0EREREY+U6DCeuO5Y\n/j53Cgcqa7jqX19w7RNL2bj3gK9Da1twuFuPZy28cK3rpXdw9K6Ngh/HXOf+Pvq6jWbs1kK9F9cp\ndpV1/4UHj3XVSLvSR39yCdxJP279uNHnQG0lbF3cta/vTw7scYVsKnvB756P+W2C19ADLy3eU2Ql\nUtMzRURE5EjGGC6YNID3fnQyvzxnDKt2FXLO/R9zx4trWm+Q3hMkZMDF/4CcVa7oSlujdw2Gnw4x\nA1svtlK4A56YBX+b4Nb09dREb818+O93oGAb/L9vwNb3j/6c1WXw/j2w6mnI/LarltmaITNdAZz2\nND0vy+/4yGmJ9NQGAAAgAElEQVTJXvjXWfD67S7p7muKs+HJc+DNO+ChabBhQfd8n9a6QkW11VBT\nAVWlrlJteQFUFHn/9TvJfxO8wgoCAwypMWHuF0kFVkRERKQVoUGB3HBSBh/dcSrfnpnOK6tyOOXP\ni/m/tzdRWNaDpzKOPhdm/MC1PmjP6B1AQCBMvdqNOBXuOHL/ly/CIydC7kaIiIeXvwuPngzbPuzy\n8A9TX9+xaY4rn4KXb3J9Br+/0jWtf2bOkesS28taWPs8PJAJH/0Rxl3cfOXMpgKDYcRZrtBKS5VN\nwSXif5sAj5/upn+2x/6tLrnLWgbL/9X3KqAWZ8O881wrigsegIgkeP5qmH8lFO323utufAP+MBTu\nToDfJcM9qXBvGtw3GP6YDn8YAs9e6eLrYfw3wSuqIDUmjKDAAFdkJTLJ1yGJiIhILxAXEcKvzhvL\nez86mTPHpvLA+1s4/t73uOPFNazPKfZ1eM07/S4Y/w047Vdtj941mHKVm3648qlD26pK4ZX/caOB\nKWPg5k/gxo/gksehohD+cwE8fblL/LpSaR588ld4YArcOwgW3uFGUVqz/AlY8D0Ydhpc+TzED4Fr\nX3Nxz/+mS3g7ImsF/OtMeOkGV5jv24vgG/9yvQzbY9Q5UL4fdn/R/P4DOfDsXAiLc0n1o6fA9o9b\nP+eeNW4UtaoEvv22+17f/CnkrO7Id9a86jJ448fwr1nw9q9h05vu37g7NU7urn7JVXi9cTGc+VvY\n9gE8dBx89jDU1Xbda1oLn/7d/YwkpMMpv3C/N6ffBWfeDWfdA7PvgxN/5EaDHzoOlj7Wo0awje1l\nw7iZmZl2+fLlR32eyx5ZgsHw/E3TXSY+8Qq3GFlERHoMY8wKa22mr+PoLbrqPVI6ZtPeEuZ9toOX\nV2ZTUVPHsUPjuXbGUGaNSyU4sJd/lv705S6JuG097PsSXrweCrfDST+Bk+6AwKBDx9ZUwhePwMd/\ngeoS1zT91F90vkq5tbDzU5eobVgA9TVuqmN8Oqx5xiVCp/0Spl53eBzg1mq9eYcrFnPZPAgOO7Sv\nogievgyyV8Alj7bd0P3AHnjvf9301qh+cPqdMOlK11KiIyoPwB8z4Pib4KzfHb6vqhT+fbYrgnP9\n227Eb/6VbnRu9r2uIX3TfonbP3IjSOFxcNVLkDzSzUp75EQICoEbP2x/8tnUnrXw4rdh/xboPwn2\nrXfXHwMpY2HIDBgyHfqNd2s9g8LdNQ4KP/LforOaJneDph2+v3AnvPEj2PKOi/H8+2HAlKN7zdpq\neON2WPUUjL0ILn7EfX8tKdgOr9/mCugMnOZi6Df26GJop9beH/02wZtx73scn5HIXy4d64ZdT/1l\ny+VtRUTEJ5TgdYwSPN8qLq/hhRW7+c9nO9lVUE5qTBjfPG4wV08fQlxEiK/D65yNb7hEY/ylLsmK\nSoFLHoOhM1t+Ttl+N31x2ePuD/6TfgzH33x4Q/bWVBS5ZGr5E5D/tVu7NulKt3YweZQ7Zu86eOtn\nrl9fyjg4+z5IP8ntW/IgvP1LGH0efOPfLtlpqqoEnrkCdn0GFz4Ek688tK++3iWz2z6E7R+6wiy2\nHqbf4kZtQqPb930056mLXWLy/RWHErb6OnjualfQ5srnYcSZbnvlATf1ddNCmPxN19uwIVHdsMCN\noiZkuOQuNu3Qa+z6wq1XGzkbrvh/RyaGrbHWJcfv/BrCE1wCnHGyW3+WvQJ2LnG33UuhpoWpsgFB\n7t+93zi44qnOJfhtJXeN493wihu1LM2FkbPguO9Cxqkd+77BjQg/7+kBedJP3Mhde5L4hmm7i37u\n1ufN/KF7fuMPFbxACV4TNXX1jPrVm9xy6nB+dFwU/HUsnPc39x+HiIj0GErwOkYJXs9QV29ZvDGX\neZ/t4OPN+USHBvGtE9K5/oR0YsN7WcXuulr46zgo3Qtjzofz/w4RCe177v6t8PavXIISnw6z7nHT\nFFv6w7s4Cz7/B6yY50YABx7rmrGPuxhCIo483lo3zfLtX7r1amPOh6SRrlLo2Ivg0sdbr5BeXQ7z\n57qpfmf9DkIiPUndR1Dhmf6ZNAoyTnGjbgkZ7fu+W7P0MVj4Y7hl6aFk9e1fw5K/w9l/dMlJY/X1\n8OEf4MP7YMBUl7BtftuNMqVlwpXPNf/v0ZDknnUPzPhe+2Ir2w+v3uISzZGz4cKHIbKFFmJ1tbB3\njRvBqqlwFUIb39eUw8r/QNxguPZ1iOpArYv2JneNVRTBZw+5DwXK8yF5tLuWE69w/65t2b8Vnrnc\n/Rxd8CBMuqL98TYo2++u+ZpnIWEYXPQwDD6+4+dpJyV4TewuKOfEPy7mvksmMGdggVsUfMXTMOa8\nLopSRES6ghK8jlGC1/Ns3HuA+9/dzJvr9hIdFsQNJ2bwrZlDiQ7rRYne9o/c6Mj4Szs+KgJundJb\nP4e8jZB+slu/1Hga294vYckDrpWBtTD+Epj+PRgwuX3nr6mAzx50U0NrymHCZXDRI+2bKlhT6Qp2\nbH7bPY5JczFmnOxGBGMGdPz7bU1xthtYOP0uOPF2l8y+9gM49gY4988tP++r191ongmEqmIYfiZc\nPq/l5MVaeO4qV9TluoUw+LjW49r+keuXWL7frTM77qbO/Vs3tuMTNxU2zrP2sT1JXsF2+H+XdCy5\na6ymEta/5D4o2LvWTeOdeo0bxInq5zmo0fdljBuNfP4aV1hozjNHn5RtXQyv3QrFu9005pN+0nXT\nVhtRgtfE59v2M+fRz3nq+mmcyBp4+lK3MLWtH34REelWSvA6Rglez7U+p5i/vbuZdzbsIzY8mBtP\nyuDaGUOJCu36P/x6pLpaN7qy+B6oOgCZ17tWDF/8061fColya/aOvxniBnXuNYqz3Zq98Ze6P9bb\nq7baxZCQAYnDjz6xacs/T3Yji6f92iUz6Se7qZltJQF5m9wayAGT4by/tt2/uaLIDWLUVsNNHx9Z\nULCqxI1YbnoTVj/tKox+4wm3nq2rbP/YJXkJ6S7Ja6moYX29m9L77m/cv91V/+14cteYtbDrc/ji\nHy45tq1ULgU34jd3fsvN6juq8gAs/AmsnQ+DjnPTmuOHdM25PXyW4BljZgP3A4HA49ba+5rsvw74\nE9BQX/RBa+3jrZ2zK968XlyRxY9fWMP7PzqZjOwF8MrN8INVXTP0LiIiXUYJXscowev5vswq5m/v\nfs17G3OJjwjmOydmcPX0IcT0phG9o1FeAIt/75I9WwdRqW4qXea3IDze19F1jw//6K5BWAxE93dF\nVcJivfNae9bA42e6NZPffNGNom5+B7a86xKg+hqXXE+83FWmDI3q+hi2fejWOyZkwLULjkzy9m+F\nV78Hu5bAsNNdoZLOJvnNKdrt1pLWVTXpnef5OigcJs/1zr/B2hfcdFpwSXlbBX06wCcJnjEmEPga\nOBPIApYBc621Gxodcx2Qaa1t5+Tgrnnzuv/dzfz13a/Z+NvZhC19EN65E36edXSLZkVEpMspwesY\nJXi9x+rdRdz/7tcs3pRHdGgQ18wYwrdnppMY1c5CJL1d7kbYv9n1hmtv8ZW+Yu86eGSm6+d2w3sQ\nP9S7r7f83/D6D910xUpPc+6UcTDiDDfVc9BxzRei6UrbPvAkecM8I3mJrrjM5w/D+7+DwFBXLXTy\nld4fQe1uhTvc9NfdX8Ckua5qfxfkHK29P3pzXsA0YIu1dpsniPnAhcCGVp/VDbKLykmODiUsONDN\nKQ8Kd59eiIiIiHSDyYPi+Pe3prEuu5iHP9jCwx9s5YlPdjB32mBuPCmD1FjvVuDzuZTR7uaP+o2D\nWb+HoSd6P7kDOOY6l2QUbIPhZ7hb46qb3SHjFDcF8tk5rlfiOX92lTqzlsHIs93oVnv7M/Y28UPd\nOsiP/uSqy+76DC79Fwz03meX3kzw0oDG7eWzgOYWuV1qjDkJN9p3m7XWiy3pneyiCtLiPD0tyvIh\nMrnvfVogIiIiPd74tFge/uYxbMkt4eEPtjLvsx38v893cukxA7l2xhBGp8b4OkTpasa4lgvd+Xpn\n/m/3vV5Lhp0Kc5+FZ+bAv2e7KbmXPO6mLfb1v8MDg+DUn7tE96Ub3RTZXprgtcdrwLPW2ipjzHeB\necBpTQ8yxtwI3AgwePDgo37RrMIKxqd55tmW5bW84FNERESkGwxPieYvl0/mtjNG8siHW3lheRbP\nLt3FmP4xXDxlABdMSuv7o3rS9w07Da560a2JO/FHneuR15sNmQ43fwLB7WjdcBTa0b2v07KBxisk\nB3KomAoA1tr91toqz8PHgWOaO5G19lFrbaa1NjM5uQN9NJpRX2/ZU1TJwIMjeLn+98MlIiIiPdKg\nhAjuuXgCn/38NP73gnGEBgXw+4UbmX7fe3zz8c95YfluSiprfB2mSOelnwRn/8F///4Oi/VK24TG\nvHn2ZcAIY0w6LrGbA1zZ+ABjTH9r7R7PwwuAr7wYDwB5pVVU19UzML7RFM2uLAcrIiIicpQSo0K5\ndsZQrp0xlO35ZbyyKptXVmfzkxfX8utX13H6mH5cMGkAp4xKJjSoAy0BRKTP81qCZ62tNcZ8D1iE\na5PwhLV2vTHmbmC5tXYB8ANjzAVALVAAXOeteBpkFVYAkBYf7npulOW5NXgiIiIiPVB6UiS3nTmS\nH54xglW7i3h5ZTZvfLmHN9buITosiNnjUrlwchrThyUSGNDH1zKJSJu8Oj5orV0ILGyy7c5GX/8c\n+Lk3Y2gqu8iT4MVFuFKx9bUQ6adDxCIiItJrGGOYOjieqYPjufP8sXy6JZ8Fa3J4c91eXliRRVJU\nKOdN7M8FkwcwZVAcpq8XrhCRZvm6yEq3S/b855cWHw4HPLNDNYInIiIivUhwYACnjErhlFEpVNbU\n8f7GXBaszuGZpbt4cskOhiRGcOGkAVw4JY1hyWoFJeJP/C7Bmz4skenDEt2Dslx3H6UET0REup4x\nZjZwP26pwuPW2vua7L8O+BOHipA9aK193LPvWuBXnu2/s9bO65agpdcJCw7knAn9OWdCfw5U1vDW\nur28ujqbBxZv4e/vb2FCWiwXTUnj/En9SYlWJU6Rvs7vErzDlOW5e43giYhIFzPGBAIPAWfiesEu\nM8YssNZuaHLoc9ba7zV5bgJwF5AJWGCF57mF3RC69GIxYcFcnjmIyzMHsbe4ktfW5PDK6mx++/oG\n7nljAzOHJ3HxlDRmjUslMtS//wwU6av8+ze7LN/dK8ETEZGuNw3YYq3dBmCMmQ9cCDRN8JozC3jH\nWlvgee47wGzgWS/FKn1QamwYN5yUwQ0nZbAlt4RXVrlk7/bn1xARso5Z41K5eEoaM4cnqTiLSB/i\n3wleaS5gICLR15GIiEjfkwbsbvQ4CziumeMuNcacBHwN3Gat3d3Cc9O8Faj0fcNTovnxrFHcfuZI\nlu8s5OVVWby+dg8vr8omJTqUCyYN4NJjBjKmf4yvQxWRo+TfCV5ZnkvuAtQ/RkREfOI14FlrbZUx\n5rvAPOC0jpzAGHMjcCPA4MGDuz5C6VMCAgzT0hOYlp7AXeePY/HGXF5alc28z3bw+CfbmZAWy2WZ\nA7lwUhqxEcG+DldEOiHA1wH4lHrgiYiI92QDgxo9HsihYioAWGv3W2urPA8fB45p73MbneNRa22m\ntTYzOVnvadJ+YcGBnD2hP49dk8kXvziD35w/lrp6y52vrufY37/L959dxUdf51FXb30dqoh0gEbw\nVEFTRES8YxkwwhiTjkvO5gBXNj7AGNPfWuvp2cMFwFeerxcBvzfGxHsen0U3940V/5IQGcJ1M9O5\nbmY667KLeXFFFq+szua1NTkMiA3jjLH9GNkvmhEpUYzsF018ZIivQxaRFijBGzDF11GIiEgfZK2t\nNcZ8D5esBQJPWGvXG2PuBpZbaxcAPzDGXADUAgXAdZ7nFhhjfotLEgHubii4IuJt49NiGZ8Wy8/P\nGc27G3J5YcVu/rsii7LquoPHJEWFMDwlihEp0UwYGMsZY/qRoKRPpEcw1vauYffMzEy7fPnyrjnZ\n7wfClKvg7PvaPlZERLqdMWaFtTbT13H0Fl36HinSiLWWPcWVbM4tZfO+ErbklrI5t5Sv95VQUllL\ngIFjhyYwe3wqZ41LJS0u3Nchi/Rprb0/+u8IXk0FVJdAZJKvIxERERHp0YwxDIgLZ0BcOCePPLS8\nxVrL+pwDvL1+L2+t38v/vraB/31tAxMHxjJrXConjUhmWEokESH++yenSHfz3982NTkXEREROSrG\nmINTOm8/axTb8kpZtH4fb63fy58WbeJPizYBMCA2jIzkKDKSI8lIiiQjOYrR/aNJiQ7z8Xcg0vco\nwYtK8W0cIiIiIn1ERnIUN58Sxc2nDGNPcQUrdxaxLa+UrXmlbMsv46WV2ZRW1R48fsrgOGaPS2XW\nuFSGJkX6MHKRvsOPE7x8d68RPBEREZEu1z82nHMnHr4Wz1pLXkkVW/PKWL6jgEUb9nLvmxu5982N\njE6NZvZ4l+yNTo3GGOOjyEV6N/9N8Epz3b0SPBEREZFuYYwhJSaMlJgwpg9L5Punj2B3QTlvb9jH\nonV7uf+9zfzt3c0MSgjnhOFJTB+WxIxhiSRFhfo6dJFew38TvINr8FRkRURERMRXBiVEcP0J6Vx/\nQjp5JVW8s2Ef72/M5fW1e3h26W4ARvWLZvqwRGYOT2JaegKx4cE+jlqk5/LvBC84EkI031tERESk\nJ0iODuXK4wZz5XGDqa2rZ33OAZZs3c+SrfnMX7aLJ5fsIMDAxIFxnDA8iZnDk5g6JI7QoEBfhy7S\nY/h3ghel6ZkiIiIiPVFQYACTBsUxaVAcN58yjKraOlbvKuLTLfl8unU///hwKw8u3kJYcADHDk3g\nhOFJHJ+RSEZyJNFhGuET/+XfCZ7W34mIiIj0CqFBgRyXkchxGYncDpRU1rB0ewGfbMnn0y353Pvm\nxoPHJkaGMCQxgiGJkQxOiGBoUgRDEyMZlRqtnnzS5/nvT3hpHsQP8XUUIiIiItIJ0WHBnD6mH6eP\n6QfAvgOVrNpVyI795ezcX8bO/eUs3V7AK6uzsdY9xxhIT4pk3IBYxvaPYdwAd0tUERfpQ/w3wSvL\ng4GZvo5CRERERLpAv5gwZo/vf8T2qto6dhdUsC2vlA17DrA+5wArdxby2pqcg8ekxoQxdsChhG/c\ngFgGxoerVYP0Sv6Z4NXXQ3m+pmiKiIiI9HGhQYEMT4lieEoUZ41LPbi9qLyaDTkHDiZ963OK+fDr\nPOrq3XBfdFgQY/vHMHZADBlJkQxOjGRIQgRp8eEEBwb46tsRaZN/JngVBWDrISrF15GIiIiIiA/E\nRYQwY3gSM4YfaplVWVPHpr0lBxO+9TkHeHbpLipr6g8eExhgGBAXxpCESIYkRpCeFElGciTpSVEM\nig8nSMmf+Jh/JnjqgSciIiIiTYQFBx6s3Nmgvt6SW1Ll1vUVlLNrf7nnvozX1+6huKLm4LFBAYbB\niRFkJEWRkRzJmP7RjB8QS0ZyFIEBmu4p3cM/E7zSXHevKZoiIiIi0oqAAENqbBipsWEcl5F4xP7C\nsmq25ZexLa+U7fllbM8vY1teGR9tzqO61o38hQcHumQvLZbxA2IZlxZDRlIU4SHq3yddzz8TvIMj\neJqiKSIiIiKdFx8ZwjGRIRwzJP6w7bV19WzLL2NddjHrsg+wLqeYl1Zm85/Pdh48JiU6lMEJEe6W\nGHHw6yGJkSRFhajIi3SKnyZ4+e5eI3giIiIi4gVBgQGM7BfNyH7RXDLVbauvt+wsKGdddjE795ex\nq6CcnfvL+Xzbfl5u1M4BICo06GD/vvSkSIYmRjI0KZKU6FCiw4KIDA1SsRdplp8meLlgAiE8vu1j\nRURERES6QECAIT3JJWxNVdXWkV1Ywc6Ccnbml7Fjfznb8stYm1XMwi/3UG+PPF9oUADRYUFEhQYR\nFRbE4IQIpgyKZ/LgOMYPiNUUUD/lpwleniuwEqBPPURERETE90KDAslIjiIjOQpGHb6vurae3YXl\n7Mgvo6CsmtKqWkoraymtqqXE8/WByhpPMrgXcNU+R6dGM3lQHJMHxTE8JYrEyFASokKIDAnU9M8+\nzD8TvNI8Tc8UERERkV4hJCiAYclRDEuOavPYvJIqVu8uYvXuQlbvLmLB6hye/mLXEedLjAwhwXNL\njg4lLS6cAQ232DAGxIUTGeqfqUJv55//amVK8ERERESk70mODuXMsf04c2w/wK3725pXyu7CcvaX\nVlNQ5m77G91vzS1l74HKI6aBxoYH0y8m9GAiGB8RQmJkCPGNH0eFuJHByBBCgjQ7rifw3wQvIcPX\nUYiIiIiIeFVAgGFEv2hG9Itu9bjaunr2lVSxp6iC7KIKcooqySmqILekksKyGr7eV0pBWTWF5dWH\nFYNpLDo0iIQolwQmN6oQOrDhPj6c0CCtC/Q2/03wNIInIiIiIgK4qp9pceGkxYWT2cpxdfWW4oqa\ngyOBBWVVbjSw1I0G7vds25pXxgeb8qjy9AIEMAZSY8IYFB9B/7iwI6aEDogNJyY8SOsDj5L/JXjV\nZVBTDlFK8ERExLuMMbOB+4FA4HFr7X1N9t8OfAeoBfKAb1trd3r21QFfeg7dZa29oNsCFxFpQWCA\nOThlsy319Zb80ip2FZSzq6Cc3QUV7r6wnJW7Cnlj7R5qm8wLDQsOICo0iIiQICJCAokMdfcRIYFE\nhQaTGOVeOzHy0PTQxKgQkqJCCQvW6CD4Y4J3sMm5EjwREfEeY0wg8BBwJpAFLDPGLLDWbmh02Cog\n01pbboy5GfgjcIVnX4W1dnK3Bi0i0oUCAgwpMWGkxISROTThiP11ngQwxzMldE9xBbklVZRV1VJe\nXXfwvrSqltwDVZRU1rC/rPqwUcHGYsKC6BcTRmpsGCnRYaTGhtIvxn0dHxFMXEQIseHBxEUE9+lk\n0KsJXlufXDY67lLgReBYa+1yb8ZEaUOCl+LVlxEREb83Ddhird0GYIyZD1wIHEzwrLWLGx3/OXBV\nt0YoIuJDgQGGfjFh9IsJY8rg9j3HWkt5dR0FZdXkl1YdLByTV1pF7oFK9h2oYu+BSrbm5pNbUnXE\nCGGD0KAAYsODiQ13yV5oUAChwQGEBAYQGhRISFAAYcEBJEaFkhoTRr+YUFI8sSZHhfbogjJeS/Da\n+cklxpho4FbgC2/FcpiDI3hJ3fJyIiLit9KA3Y0eZwHHtXL89cCbjR6HGWOW46Zv3metfaXrQxQR\n6V2MMUSGBhEZGsSghIhWj62vt+wvq2bfgUqKK2oorqihqLyGoopq97jcbauqraeqto6qmnoOVNRS\nVVtHdW39wUSyuSQxITKEwABDXb2lrt5SX2+ps+5rayEmPIikKJcUJkeFkhwdSkq0ux/TP4bhKW23\nvOgsb47gtfnJpcdvgT8AP/FiLIeU5bp7TdEUEZEewhhzFZAJnNxo8xBrbbYxJgN43xjzpbV2azPP\nvRG4EWDw4HZ+BC4i4gcCAgzJnqSqs+rrLQXlLknMPVDFPs8oYW6JaysRGACBxhAQYAg0hsAAgzGG\n4ooa8koqySupYsu+EvJKq6ipc4nizacM46ezR3fVt3kEbyZ4bX5yaYyZCgyy1r5hjOmeBG/shZA6\nAaL7d8vLiYiI38oGBjV6PNCz7TDGmDOAXwInW2urGrZba7M999uMMR8AU4AjEjxr7aPAowCZmZkt\nFC8XEZHOCAgwJEWFkhQVyrgBnT9Pvaf6aF5pFVFebiDvs8mjxpgA4C/Aj9px7I3GmOXGmOV5eXlH\n98Lh8ZB2DAT6X30ZERHpVsuAEcaYdGNMCDAHWND4AGPMFOCfwAXW2txG2+ONMaGer5OAmRw5A0ZE\nRHqJgABDfGQII/tFMyAu3Luv5cVzt/XJZTQwHvjAGLMDOB5YYIw5ovWGtfZRa22mtTYzOVlTK0VE\npOez1tYC3wMWAV8Bz1tr1xtj7jbGNLQ8+BMQBbxgjFltjGlIAMcAy40xa4DFuDV4SvBERKRN3hzG\nOvjJJS6xmwNc2bDTWlsMHKx04pl+8mOvV9EUERHpJtbahcDCJtvubPT1GS08bwkwwbvRiYhIX+S1\nEbx2fnIpIiIiIiIiXcSrC9Ha+uSyyfZTvBmLiIiIiIhIX9dzO/SJiIiIiIhIhyjBExERERER6SOU\n4ImIiIiIiPQRSvBERERERET6CCV4IiIiIiIifYQSPBERERERkT7CWGt9HUOHGGPygJ3tODQJyG9h\nXyxQ3MX7vHVeb+zr7mvTW/a1dl18EU9P2tfXf2aO5rl9/dp46/epvYZYa5O74Dx+oQe/R/aWfZ29\nLt6Kpyft8+efmbb2+/O16QvXxRev2RXvkS2/P1pr++QNWN7Kvke7ep+3zuulfd16bXrRvhavSw+M\ntcdcmx4Wpy9+f/v0tfHW75Nuvr3p57Zrr0sP/D56zLXpC/t0bfr2z0xPuzZdcfPXKZqveWGft87r\nrVh7Siw9aV9belKsPena9KQ4ffH7641z9oV90nv1pJ+jnvRz21f+BtD/dR3f1579Xf2afWFfa3pa\nnD3p2hy1XjdFs72MMcuttZm+jqMn0rVpnq5Ly3RtWqZr0zxdl55N/z7N03Vpma5Ny3Rtmqfr0jJv\nX5u+PIL3qK8D6MF0bZqn69IyXZuW6do0T9elZ9O/T/N0XVqma9MyXZvm6bq0zKvXps+O4ImIiIiI\niPibvjyCJyIiIiIi4lf6ZIJnjJltjNlkjNlijPmZr+PxJWPME8aYXGPMukbbEowx7xhjNnvu430Z\noy8YYwYZYxYbYzYYY9YbY271bNe1MSbMGLPUGLPGc23+17M93Rjzhef36jljTIivY/UFY0ygMWaV\nMeZ1z2NdF8AYs8MY86UxZrUxZrlnm9//PvU0en88RO+PzdP7Y8v0/tg6vT82zxfvj30uwTPGBAIP\nAWcDY4G5xpixvo3Kp54EZjfZ9jPgPWvtCOA9z2N/Uwv8yFo7FjgeuMXzc6JrA1XAadbaScBkYLYx\n5njgD/hlalsAAAU+SURBVMBfrbXDgULgeh/G6Eu3Al81eqzrcsip1trJjRaO6/epB9H74xGeRO+P\nzdH7Y8v0/tg6vT+2rFvfH/tcggdMA7ZYa7dZa6uB+cCFPo7JZ6y1HwEFTTZfCMzzfD0PuKhbg+oB\nrLV7rLUrPV+X4P5DSkPXBuuUeh4Ge24WOA140bPdL6+NMWYgcC7wuOexQdelNX7/+9TD6P2xEb0/\nNk/vjy3T+2PL9P7YYV79feqLCV4asLvR4yzPNjmkn7V2j+frvUA/Xwbja8aYocAU4At0bYCD0yxW\nA7nAO8BWoMhaW+s5xF9/r/4G3AHUex4nouvSwAJvG2NWGPP/27ubUKnKOI7j3x9Xg0tGllYIJpdI\nCCKTiKByIUItQtoUaRhIBIGLqEXRyyaI3LSIstoUFS0sEMpyFYlKCAVFZL5Qq7gtxHxZWAQhIf8W\nc8RR7+0qzb1nPPP9wDDPeWY4PPNwzv3N85znzM2TTZ3n03AxH2fmMdvHfLyQ+Tgt83F6c56P8wa5\nM11+qqqSjOxPqSZZAHwKPFNVf/YmnHpGuW+q6jSwMslCYDtwS8tNal2StcCxqvohyeq22zOEVlXV\n4STXAzuT/NL/4iifT7o8jfoxaz5OzXy8kPk4oznPxy5ewTsM3Ni3vbSp01lHkywBaJ6PtdyeViSZ\nTy+8tlbVZ021fdOnqk4Ce4C7gYVJzkwKjeJ5dS/wYJJJekvb1gBvYr8AUFWHm+dj9L703IXn07Ax\nH2fmMYv5eDHMx3OYj/+hjXzs4gDve2B588s9VwDrgR0tt2nY7AA2NuWNwBcttqUVzdrw94Gfq+r1\nvpfsm+S6ZmaSJOPAffTuwdgDPNy8beT6pqperKqlVTVB7+/K7qrawIj3C0CSK5NcdaYM3A8cxPNp\n2JiPMxv5Y9Z8nJ75ODXzcXpt5WMn/9F5kgforQUeAz6oqs0tN6k1ST4BVgOLgaPAy8DnwDZgGfAb\n8EhVnX+jeaclWQXsBQ5wdr34S/TuMxj1vllB74bfMXqTQNuq6pUkN9GbmbsW+BF4rKpOtdfS9jRL\nUJ6tqrX2CzR9sL3ZnAd8XFWbkyxixM+nYWM+nmU+Ts18nJ75ODPz8Vxt5WMnB3iSJEmSNIq6uERT\nkiRJkkaSAzxJkiRJ6ggHeJIkSZLUEQ7wJEmSJKkjHOBJkiRJUkc4wJPmUJLTSfb1PV4Y4L4nkhwc\n1P4kSZpLZqQ0GPNmfoukAfq7qla23QhJkoaQGSkNgFfwpCGQZDLJa0kOJPkuyc1N/USS3Un2J9mV\nZFlTf0OS7Ul+ah73NLsaS/JekkNJvkoy3tqHkiRpAMxI6dI4wJPm1vh5y0/W9b32R1XdBrwNvNHU\nvQV8VFUrgK3AlqZ+C/B1Vd0O3AEcauqXA+9U1a3ASeChWf48kiQNihkpDUCqqu02SCMjyV9VtWCK\n+klgTVX9mmQ+8HtVLUpyAlhSVf809UeqanGS48DSqjrVt48JYGdVLW+2nwfmV9Wrs//JJEn6f8xI\naTC8gicNj5qmfClO9ZVP4322kqRuMCOli+QATxoe6/qev23K3wDrm/IGYG9T3gVsAkgyluTquWqk\nJEktMCOli+TMhTS3xpPs69v+sqrO/Az0NUn205thfLSpewr4MMlzwHHg8ab+aeDdJE/Qm4XcBByZ\n9dZLkjR7zEhpALwHTxoCzf0Fd1bVibbbIknSMDEjpUvjEk1JkiRJ6giv4EmSJElSR3gFT5IkSZI6\nwgGeJEmSJHWEAzxJkiRJ6ggHeJIkSZLUEQ7wJEmSJKkjHOBJkiRJUkf8C4gRlVDVCq6HAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuNxlzT8KNk0",
        "colab_type": "text"
      },
      "source": [
        "# GradCam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt3adYm7KM02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90eaT1ByPDI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZOawRViRYfO",
        "colab_type": "code",
        "outputId": "002de44a-c947-4a41-f76c-e700469b7005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(filepath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/saved_models/cifar10_ResNet38v2_model.{epoch:03d}.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEXKoNwFRq7N",
        "colab_type": "code",
        "outputId": "947e2ed5-e5db-4b8c-bff5-05789901476e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t      tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t      tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-2.0.0  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tNpnwPuRw2e",
        "colab_type": "code",
        "outputId": "9ff295b6-afc3-461c-9068-f37755630445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%cd content/saved_models/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'content/saved_models/'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj9u2E1ZTANv",
        "colab_type": "code",
        "outputId": "4850ecd3-8768-4cc8-b635-98c15ff731ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd saved_models/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/saved_models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfVdyolHR1Yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCeHsz6xQ5r8",
        "colab_type": "code",
        "outputId": "80b8a989-12da-4b16-8f1e-af9f0edc6a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "ResNet38V2 = load_model(filepath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-091182373083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mResNet38V2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/saved_models/cifar10_ResNet38v2_model.{epoch:03d}.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v93V8JVNqlsZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LB0lxjyKZK1",
        "colab_type": "code",
        "outputId": "3d98ca11-4877-4e64-82c3-d6bfbe9baa6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t      tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t      tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-2.0.0  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2HUQHmKZ7-",
        "colab_type": "code",
        "outputId": "feacfa38-4209-4f26-fd27-5c2cf708b79f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(filepath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/saved_models/cifar10_ResNet38v2_model.{epoch:03d}.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6oUSjqWK9rt",
        "colab_type": "code",
        "outputId": "7f94554b-c6ec-444e-90f5-7badcaea9a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!cd saved_models/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: saved_models/: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLX7eGSKLVCN",
        "colab_type": "code",
        "outputId": "ddf4eec1-be25-400f-dcc0-e4217be598fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nljO_WYELWUN",
        "colab_type": "code",
        "outputId": "7ded072a-0b38-4ae9-f980-2b76e4385eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrusMqQLLdJd",
        "colab_type": "code",
        "outputId": "88c73e75-2d4a-494c-af38-be478a2f65ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdsU_n2qLewe",
        "colab_type": "code",
        "outputId": "bc67b989-0e31-40d2-80f7-349a45b96ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!cd /content/saved_models\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3WYrj-uLmTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1b-mF0ULtvt",
        "colab_type": "code",
        "outputId": "4c0dae9f-b1a9-4a7b-e8ff-fdd512fd83e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!cd saved_models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: saved_models: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vyZaqDqL0q9",
        "colab_type": "code",
        "outputId": "6fe128a6-bc2e-4a17-aa77-d67159077336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t      tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t      tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-2.0.0  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRJAn9Y4L3Ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}