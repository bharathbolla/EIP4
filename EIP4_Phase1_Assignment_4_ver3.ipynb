{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP4_Phase1_Assignment_4_ver3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharathbolla/EIP4/blob/assignment_4/EIP4_Phase1_Assignment_4_ver3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8SeRSLZimz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "9786bb08-38cd-4b88-a004-cb4265d88202"
      },
      "source": [
        "import keras\n",
        "#print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORnoLoAyiqQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "d962700b-2177-4fa6-8bca-eb60e2a75945"
      },
      "source": [
        "\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=9848c95144a94f52f53cc78871cde0fe4e3bdbfbbdde9a04538ed0cd8db7c675\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU4ulPetizd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "100fWT9Gi3Px",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4e549465-b603-4ded-91bf-658cbd9f84ef"
      },
      "source": [
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.7 GB  | Proc size: 346.0 MB\n",
            "GPU RAM Free: 7611MB | Used: 0MB | Util   0% | Total 7611MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "najpwTCPi6cj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "8013c015-1921-477a-fa89-d09e45ab0529"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Dec  8 17:25:50 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXKpjGGdi7wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, Dropout\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfFkFhX7jA4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zzN-vCMjC7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvDFhC8gjFcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5rDiwNwjHfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "dd70f030-9fec-47b3-9323-f887a938a14f"
      },
      "source": [
        "n = 4\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 2\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D52mBtEMj0Ug",
        "colab_type": "text"
      },
      "source": [
        "## Droput Added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATK1fseSjLj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Id1GIjvjvlJ",
        "colab_type": "text"
      },
      "source": [
        "## Resnet38V2 two with 32 filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zatLffGjmyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 32\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhi8Tag1kDeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1bf45a8-f786-4f3d-e021-113b9570a91e"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "#else:\n",
        "    #model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 128),\n",
        "                                 samples_per_epoch = x_train.shape[0], nb_epoch = 50, \n",
        "                                 callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], #Added Rohan's Learning rate scheduler\n",
        "                                 validation_data = (x_test, y_test), verbose=1)\n",
        "\n",
        "                                            \n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 32)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   1056        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 32)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9248        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 32)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 128)  4224        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 128)  4224        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 128)  0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 128)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 32)   4128        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 32)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9248        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 32)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  4224        dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 128)  0           add_1[0][0]                      \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 128)  0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 32)   4128        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 32)   0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 32)   9248        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 32)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  4224        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 128)  0           add_2[0][0]                      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 128)  0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 32)   4128        dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 32)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 32)   9248        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 32)   0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 128)  4224        dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 128)  0           add_3[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 128)  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 128)  16512       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 16, 16, 128)  0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 128)  147584      dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 16, 16, 128)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 256)  33024       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 256)  33024       dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 256)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 16, 16, 256)  0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 128)  32896       dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 128)  0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 128)  147584      dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 128)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 256)  33024       dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 256)  0           add_5[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 256)  1024        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 256)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 256)  0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 128)  32896       dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 128)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 128)  0           activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 128)  147584      dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 128)  512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 128)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 128)  0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 256)  33024       dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 256)  0           add_6[0][0]                      \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 256)  1024        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 256)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 16, 16, 256)  0           activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 128)  32896       dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 128)  512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 128)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 128)  0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 128)  147584      dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 128)  512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 128)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 16, 16, 128)  0           activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 256)  33024       dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 256)  0           add_7[0][0]                      \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 256)  1024        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 256)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 256)  0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 256)    65792       dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 256)    1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 256)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 8, 8, 256)    0           activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 256)    590080      dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 256)    1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 256)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 8, 8, 256)    0           activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 512)    131584      add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 512)    131584      dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 512)    0           conv2d_31[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 512)    2048        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 512)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 8, 8, 512)    0           activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 256)    131328      dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 8, 8, 256)    0           activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 256)    590080      dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 256)    1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 256)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 8, 8, 256)    0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 512)    131584      dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 512)    0           add_9[0][0]                      \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 512)    2048        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 512)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 8, 8, 512)    0           activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 256)    131328      dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 256)    1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 256)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 8, 8, 256)    0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 256)    590080      dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 256)    1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 256)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 8, 8, 256)    0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 512)    131584      dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 512)    0           add_10[0][0]                     \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 512)    2048        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 512)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 8, 8, 512)    0           activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 256)    131328      dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 256)    1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 256)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 8, 8, 256)    0           activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 256)    590080      dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 256)    1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 256)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 8, 8, 256)    0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 512)    131584      dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 512)    0           add_11[0][0]                     \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 512)    2048        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 512)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           5130        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,454,026\n",
            "Trainable params: 4,440,138\n",
            "Non-trainable params: 13,888\n",
            "__________________________________________________________________________________________________\n",
            "ResNet38v2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 186s 478ms/step - loss: 2.0623 - acc: 0.4838 - val_loss: 2.0728 - val_acc: 0.4696\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 1.3324 - acc: 0.6399 - val_loss: 2.0003 - val_acc: 0.4715\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 171s 439ms/step - loss: 1.1588 - acc: 0.6883 - val_loss: 1.4409 - val_acc: 0.6026\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 171s 440ms/step - loss: 1.0373 - acc: 0.7254 - val_loss: 1.2421 - val_acc: 0.6563\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 171s 440ms/step - loss: 0.9554 - acc: 0.7529 - val_loss: 1.8268 - val_acc: 0.5173\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 171s 439ms/step - loss: 0.8747 - acc: 0.7808 - val_loss: 1.1624 - val_acc: 0.6898\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.8168 - acc: 0.7977 - val_loss: 0.9391 - val_acc: 0.7659\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.7636 - acc: 0.8130 - val_loss: 0.8189 - val_acc: 0.7958\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.7227 - acc: 0.8254 - val_loss: 0.8419 - val_acc: 0.7871\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.6831 - acc: 0.8395 - val_loss: 0.8959 - val_acc: 0.7804\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.6476 - acc: 0.8482 - val_loss: 0.8742 - val_acc: 0.7752\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.6181 - acc: 0.8578 - val_loss: 0.9813 - val_acc: 0.7586\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.5873 - acc: 0.8661 - val_loss: 0.7933 - val_acc: 0.8077\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 171s 440ms/step - loss: 0.5548 - acc: 0.8783 - val_loss: 0.7077 - val_acc: 0.8288\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.5349 - acc: 0.8840 - val_loss: 0.7103 - val_acc: 0.8302\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.5153 - acc: 0.8907 - val_loss: 0.8331 - val_acc: 0.7919\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.4887 - acc: 0.8983 - val_loss: 0.7828 - val_acc: 0.8175\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.4692 - acc: 0.9045 - val_loss: 0.6765 - val_acc: 0.8443\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.4509 - acc: 0.9100 - val_loss: 0.7073 - val_acc: 0.8427\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.4376 - acc: 0.9135 - val_loss: 0.6701 - val_acc: 0.8434\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.4149 - acc: 0.9217 - val_loss: 0.6444 - val_acc: 0.8578\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3980 - acc: 0.9265 - val_loss: 0.6892 - val_acc: 0.8449\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3858 - acc: 0.9310 - val_loss: 0.6714 - val_acc: 0.8534\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3756 - acc: 0.9334 - val_loss: 0.6136 - val_acc: 0.8642\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3634 - acc: 0.9369 - val_loss: 0.6106 - val_acc: 0.8734\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3534 - acc: 0.9403 - val_loss: 0.6696 - val_acc: 0.8605\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3443 - acc: 0.9424 - val_loss: 0.6670 - val_acc: 0.8643\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3289 - acc: 0.9472 - val_loss: 0.6801 - val_acc: 0.8591\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3197 - acc: 0.9504 - val_loss: 0.6649 - val_acc: 0.8646\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.3107 - acc: 0.9538 - val_loss: 0.7022 - val_acc: 0.8582\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.3032 - acc: 0.9561 - val_loss: 0.6556 - val_acc: 0.8656\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2956 - acc: 0.9574 - val_loss: 0.7817 - val_acc: 0.8466\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2917 - acc: 0.9591 - val_loss: 0.8164 - val_acc: 0.8312\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2855 - acc: 0.9599 - val_loss: 0.6886 - val_acc: 0.8653\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2797 - acc: 0.9618 - val_loss: 0.6556 - val_acc: 0.8673\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.2732 - acc: 0.9642 - val_loss: 0.6526 - val_acc: 0.8744\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2658 - acc: 0.9672 - val_loss: 0.7056 - val_acc: 0.8573\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2602 - acc: 0.9680 - val_loss: 0.6603 - val_acc: 0.8714\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2575 - acc: 0.9685 - val_loss: 0.6532 - val_acc: 0.8763\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2479 - acc: 0.9711 - val_loss: 0.6377 - val_acc: 0.8781\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2466 - acc: 0.9710 - val_loss: 0.6800 - val_acc: 0.8704\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2433 - acc: 0.9716 - val_loss: 0.6873 - val_acc: 0.8644\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2368 - acc: 0.9740 - val_loss: 0.6629 - val_acc: 0.8720\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.2311 - acc: 0.9761 - val_loss: 0.6527 - val_acc: 0.8728\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2330 - acc: 0.9743 - val_loss: 0.7218 - val_acc: 0.8686\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2301 - acc: 0.9755 - val_loss: 0.6681 - val_acc: 0.8709\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2217 - acc: 0.9785 - val_loss: 0.6989 - val_acc: 0.8730\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.2217 - acc: 0.9773 - val_loss: 0.6273 - val_acc: 0.8816\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 172s 440ms/step - loss: 0.2218 - acc: 0.9773 - val_loss: 0.6662 - val_acc: 0.8759\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 172s 441ms/step - loss: 0.2140 - acc: 0.9800 - val_loss: 0.6876 - val_acc: 0.8687\n",
            "Model took 8604.61 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7tKBJ4slZIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuNxlzT8KNk0",
        "colab_type": "text"
      },
      "source": [
        "# GradCam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt3adYm7KM02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90eaT1ByPDI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZOawRViRYfO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "002de44a-c947-4a41-f76c-e700469b7005"
      },
      "source": [
        "print(filepath)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/saved_models/cifar10_ResNet38v2_model.{epoch:03d}.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEXKoNwFRq7N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "947e2ed5-e5db-4b8c-bff5-05789901476e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t      tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t      tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-2.0.0  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tNpnwPuRw2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9ff295b6-afc3-461c-9068-f37755630445"
      },
      "source": [
        "%cd content/saved_models/"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'content/saved_models/'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj9u2E1ZTANv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4850ecd3-8768-4cc8-b635-98c15ff731ec"
      },
      "source": [
        "%cd saved_models/"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/saved_models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfVdyolHR1Yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCeHsz6xQ5r8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "80b8a989-12da-4b16-8f1e-af9f0edc6a4a"
      },
      "source": [
        "ResNet38V2 = load_model(filepath)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-091182373083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mResNet38V2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/saved_models/cifar10_ResNet38v2_model.{epoch:03d}.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v93V8JVNqlsZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LB0lxjyKZK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3d98ca11-4877-4e64-82c3-d6bfbe9baa6c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t      tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t      tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-2.0.0  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2HUQHmKZ7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "feacfa38-4209-4f26-fd27-5c2cf708b79f"
      },
      "source": [
        "print(filepath)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/saved_models/cifar10_ResNet38v2_model.{epoch:03d}.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6oUSjqWK9rt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f94554b-c6ec-444e-90f5-7badcaea9a72"
      },
      "source": [
        "!cd saved_models/"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: saved_models/: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLX7eGSKLVCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ddf4eec1-be25-400f-dcc0-e4217be598fd"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nljO_WYELWUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ded072a-0b38-4ae9-f980-2b76e4385eea"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrusMqQLLdJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88c73e75-2d4a-494c-af38-be478a2f65ef"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdsU_n2qLewe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc67b989-0e31-40d2-80f7-349a45b96ac3"
      },
      "source": [
        "!cd /content/saved_models\n",
        "!pwd"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3WYrj-uLmTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1b-mF0ULtvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c0dae9f-b1a9-4a7b-e8ff-fdd512fd83e5"
      },
      "source": [
        "!cd saved_models"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: saved_models: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vyZaqDqL0q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6fe128a6-bc2e-4a17-aa77-d67159077336"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t      tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t      tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-2.0.0  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRJAn9Y4L3Ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}